1. INTRODUCTION

2. PRELIMINARIES  
2.1 Formula Descriptions  
2.2 Interpretation of Adversarial Examples  
2.3 Transferability of Adversarial Examples  
2.4 Taxonomy of Adversarial Examples  
2.5 Metrics on Imperceptibility in Texts  
2.6 Datasets in Texts  

3. ADVERSARIAL ATTACKS FOR CLASSIFICATION IN TEXTS  
3.1 Char-level Attacks  
3.2 Word-level Attacks  
3.3 Sentence-level Attacks  
3.4 Multi-level Attacks  

4. ADVERSARIAL TECHNIQUES FOR OTHER NLP TASKS  
4.1 Attack on Reading Comprehension Systems  
4.2 Attack on Natural Language Inference Models  
4.3 Attack on Machine Translation Models  
4.4 Attack on Question and Answer Systems  
4.5 Summary of Adversarial Attacks  

5. DEFENSES AGAINST ADVERSARIAL ATTACKS IN TEXTS  
5.1 Detecting Misspellings and Unknown Words  
5.2 Model Enhancement  
5.3 Theoretical Analysis  

6. ADVERSARIAL EXAMPLES IN CHINESE-BASED MODELS  
6.1 Attack  
6.2 Defense  

7. DISCUSSIONS  
7.1 Generation of Adversarial Examples  
7.2 Defense Methods Against Adversarial Attacks  
7.3 Further Work  

8. CONCLUSION