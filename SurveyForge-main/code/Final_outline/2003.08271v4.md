1 Introduction
2 Background
2.1 Language Representation Learning
2.2 Neural Contextual Encoders
2.3 Why Pre-training?
2.4 A Brief History of PTMs for NLP
3 Overview of PTMs
3.1 Pre-training Tasks
3.2 Taxonomy of PTMs
3.3 Model Analysis
4 Extensions of PTMs
4.1 Knowledge-Enriched PTMs
4.2 Multilingual and Language-Specific PTMs
4.3 Multi-Modal PTMs
4.4 Domain-Specific and Task-Specific PTMs
4.5 Model Compression
5 Adapting PTMs to Downstream Tasks
5.1 Transfer Learning
5.2 How to Transfer?
5.3 Fine-Tuning Strategies
6 Resources of PTMs
7 Applications
7.1 General Evaluation Benchmark
7.2 Question Answering
7.3 Sentiment Analysis
7.4 Named Entity Recognition
7.5 Machine Translation
7.6 Summarization
7.7 Adversarial Attacks and Defenses
8 Future Directions
9 Conclusion