CONTENTS

1. Introduction

2. Self-Supervised Learning (SSL)
2.1 Why Self-Supervised Learning?
2.2 What is Self-Supervised Learning?
2.3 Types of Self-Supervised Learning

3. T-PTLM Core Concepts
3.1 Pre-training
3.2 Types of Pre-training Methods
3.3 Pre-training Tasks
3.4 Embeddings

4. Taxonomy
4.1 Pre-training Corpus-based
4.2 Architecture
4.3 SSL
4.4 Extensions

5. Downstream Adaptation Methods
5.1 Feature-based
5.2 Fine-tuning
5.3 Prompt-based Tuning

6. Evaluation
6.1 Intrinsic Evaluation
6.2 Extrinsic Evaluation

7. Useful Libraries

8. Discussions and Future Directions
8.1 Better Pre-training Methods
8.2 Sample Efficient Pre-training Tasks
8.3 Efficient Models
8.4 Better Position Encoding Mechanisms
8.5 Improving Existing T-PTLMs
8.6 Beyond Vanilla Fine-tuning
8.7 Benchmarks
8.8 Compact Models
8.9 Robustness to Noise
8.10 Novel Adaptation Methods
8.11 Privacy Issues
8.12 Mitigating Bias
8.13 Mitigating Fine-Tuning Instabilities

9. Conclusion