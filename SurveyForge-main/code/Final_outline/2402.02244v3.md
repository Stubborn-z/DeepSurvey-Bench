1 Introduction  
2 Length Extrapolation  
3 Attention Approximation  
4 Attention-free Transformers  
5 Model Compression  
6 Hardware-aware Transformers  
7 Conclusion and Future Directions