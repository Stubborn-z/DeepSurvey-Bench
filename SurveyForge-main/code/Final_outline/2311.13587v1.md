1. Introduction

2. Methods  
2.1. Literature search strategy  
2.2. Eligibility criteria  
2.3. Data extraction  
2.4. Taxonomy definition  

3. Results  
3.1. Strategy for efficient loading/unloading of the models to GPU  
3.2. Strategy for ensuring optimal allocation of resources when deploying multiple models on GPU  
3.3. Techniques allowing for function-as-a-service model serving  

4. Discussion and Reflection  

5. Conclusion and Future Work