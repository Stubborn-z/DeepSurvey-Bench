1 INTRODUCTION

2 DEEP LEARNING BASED DEPTH COMPLETION  
2.1 Problem Formulation  
2.2 Taxonomy  

3 UNGUIDED DEPTH COMPLETION  
3.1 Sparsity-Aware CNNs  
3.2 Normalized CNNs  
3.3 Training with Auxiliary Images  
3.4 Discussion  

4 RGB GUIDED DEPTH COMPLETION  
4.1 Early Fusion Models  
4.2 Late Fusion Models  
4.3 Explicit 3D Representation Models  
4.4 Residual Depth Models  
4.5 SPN-based Models  

5 LEARNING OBJECTIVES FOR TRAINING MODELS  
5.1 Depth Consistency  
5.2 Structural Loss Functions  
5.3 Smoothness Regularization  
5.4 Multi-view Geometric Constraints  
5.5 Adversarial Loss  

6 DATASETS AND EVALUATION METRICS  
6.1 Real-world Datasets  
6.2 Real-world Datasets  
6.3 Synthetic Datasets  
6.4 Evaluation Metrics  

7 EXPERIMENTAL ANALYSES  
7.1 Main Characteristics of Existing Methods  
7.2 Unguided and Guided Methods  
7.3 Comparison of RGB Guided Methods  

8 OPEN CHALLENGES AND FUTURE DIRECTIONS  
8.1 Depth Mixing Problem  
8.2 Flawed Ground Truth  
8.3 Lightweight Networks  
8.4 Un-/self-supervised Frameworks  
8.5 Loss Functions and Evaluation Metrics  
8.6 Domain Adaptation  
8.7 Transformer-based Network Structures  
8.8 Visualization and Interpretability  
8.9 Robustness to Different Sensors  

9 CONCLUSION