1 Introduction
2 Feature Extraction
2.1 Feature Extraction
2.2 Feature Representation
3 Model Architecture
3.1 Single-stream versus Dual-stream
3.2 Encoder-only versus Encoder-decoder
4 Pre-training Objectives
4.1 Masked Language Modeling
4.2 Prefix Language Modeling
4.3 Masked Vision Modeling
4.4 Vision-Language Matching
4.5 Vision-Language Contrastive Learning
4.6 Word-Region Alignment
4.7 Frame Order Modeling
4.8 Particular Pre-training Objectives
5 Pre-training Datasets
5.1 Datasets for Image-language Pre-training
5.2 Datasets for Video-language Pre-training
6 Downstream Tasks
7 SOTA VLP models
7.1 Image-Text VLP models
7.2 Video-Text VLP models
8 Conclusion and New Frontiers