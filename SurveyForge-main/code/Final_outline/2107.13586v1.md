Contents  
1 Two Sea Changes in NLP  
2 A Formal Description of Prompting  
2.1 Supervised Learning in NLP  
2.2 Prompting Basics  
2.3 Design Considerations for Prompting  
3 Pre-trained Language Models  
3.1 Training Objectives  
3.2 Noising Functions  
3.3 Directionality of Representations  
3.4 Typical Pre-training Methods  
4 Prompt Engineering  
4.1 Prompt Shape  
4.2 Manual Template Engineering  
4.3 Automated Template Learning  
5 Answer Engineering  
5.1 Answer Shape  
5.2 Answer Space Design Methods  
6 Multi-Prompt Learning  
6.1 Prompt Ensembling  
6.2 Prompt Augmentation  
6.3 Prompt Composition  
6.4 Prompt Decomposition  
7 Training Strategies for Prompting Methods  
7.1 Training Settings  
7.2 Parameter Update Methods  
8 Applications  
8.1 Knowledge Probing  
8.2 Classification-based Tasks  
8.3 Information Extraction  
8.4 “Reasoning” in NLP  
8.5 Question Answering  
8.6 Text Generation  
8.7 Automatic Evaluation of Text Generation  
8.8 Multi-modal Learning  
8.9 Meta-Applications  
8.10 Resources  
9 Prompt-relevant Topics  
10 Challenges  
10.1 Prompt Design  
10.2 Answer Engineering  
10.3 Selection of Tuning Strategy  
10.4 Multiple Prompt Learning  
10.5 Selection of Pre-trained Models  
10.6 Theoretical and Empirical Analysis of Prompting  
10.7 Transferability of Prompts  
10.8 Combination of Different Paradigms  
10.9 Calibration of Prompting Methods  
11 Meta Analysis  
11.1 Timeline  
11.2 Trend Analysis  
12 Conclusion