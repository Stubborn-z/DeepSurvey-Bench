1 Introduction

2 The Spark of Code Intelligence
2.1 Code Features Through Structural Views
2.2 Overview of Core Tasks in Code Intelligence

3 An Odyssey of Pre-train and Fine-tune
3.1 Pre-trained Language Models for Code
3.2 Task-specific Adaptation of CodePTMs
3.3 Understanding and Analyzing CodePTMs

4 The LLM Era: A New Frontier
4.1 Large Language Models for Code
4.2 Learning with Execution Feedback
4.3 Advancements in NL2Code

5 Synergies in Machine Intelligence
5.1 Binding Code Generation with LLM Reasoning
5.2 Code Training Elicits Mathematical Capabilities
5.3 Alternative Formats for Solving NLP Tasks

6 Real-World Applications
6.1 Boosting Software Development Workflows
6.2 Facilitating Data-Driven Decision-Making
6.3 Building Code-Empowered Agents
6.4 Advancing AI4Science Research

7 Opportunities and Future Directions
7.1 Beyond Transformer Architecture
7.2 Renaissance in Utilizing Code Features
7.3 Repo-Level Code Understanding and Generation
7.4 Towards Holistic and Reliable Evaluations
7.5 Interleaved Planning and Code-Driven Reasoning
7.6 A Closer Look at Tokenizer Dynamics
7.7 Efficient Methods for CodeLLMs
7.8 Further Expansion of Multilingual Capability
7.9 Copyright Challenges Faced by Coding Assistants

8 Conclusion