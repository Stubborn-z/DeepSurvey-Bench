1 Introduction

2 Preliminaries about PLMs  
2.1 Language Models  
2.2 Pre-training and Fine-tuning

3 Definitions of Memorization  
3.1 Eidetic memorization  
3.2 Differential privacy  
3.3 Counterfactual memorization  
3.4 Approximate memorization  
3.5 Revisiting model inversion

4 Training Data Extraction Attacks  
4.1 Candidate generation  
4.2 Membership inference

5 Training Data Extraction Defenses  
5.1 Pre-processing  
5.2 Training  
5.3 Post-processing

6 Empirical Findings  
6.1 Larger models memorize more  
6.2 Duplicate strings are memorized  
6.3 Longer prompts extract more

7 Conclusion & Future Directions  
7.1 Is memorization always evil?  
7.2 Toward broader research fields  
7.3 Evaluation schema