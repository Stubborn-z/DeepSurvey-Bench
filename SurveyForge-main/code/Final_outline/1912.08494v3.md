1 Introduction  
2 Background: Sentence-level Neural Machine Translation  
2.1 Neural encoder-decoder architectures  
2.2 Training  
2.3 Decoding  
2.4 Evaluation  
3 Document-level Neural Machine Translation  
3.1 Modelling document-level context  
3.2 Learning with document-level context  
3.3 Decoding with document-level context  
3.4 Shared Tasks in WMT19 and WNGT 2019  
3.5 Summary  
4 Evaluation  
4.1 Automatic Evaluation of Specific Discourse Phenomena  
4.2 Evaluation Test Sets  
5 Conclusions and Future Directions