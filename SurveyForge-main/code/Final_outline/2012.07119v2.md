1 Introduction  
2 Definition & Importance of Neural Network Interpretability  
3 Related Work  
4 Approaches  
4.1 Self-Interpretable System  
4.2 Representation Analysis  
4.3 Re-approximation with Interpretable Models  
5 How to Evaluate an Interpretable System?  
6 Challenges  
6.1 Robust Interpretation  
6.2 Sparsity of Analysis  
7 Conclusion