1 INTRODUCTION  
1.1 Transformer  
1.2 Lighter and Faster Transformers  

2 TRANSFORMER  
2.1 Attention Mechanism  
2.2 Encoder  
2.3 Decoder  
2.4 Complexity  

3 GENERAL APPROACHES  

4 SPECIALIZED APPROACHES  
4.1 Sparse Attention  
4.2 Factorized Attention  
4.3 Architectural Change  

5 SHORTCOMINGS  

6 BROADER IMPACT OF EFFICIENT TRANSFORMER  

7 FUTURE RESEARCH DIRECTIONS  
7.1 Efficiency and Affordability  
7.2 Generalization Performance  

8 CONCLUSION