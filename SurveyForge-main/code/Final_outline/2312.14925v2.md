Contents

2 Preliminaries
2.1 Reinforcement Learning
2.2 Preference-Based MDPs
2.3 Reward Learning
2.4 Reinforcement Learning from Human Feedback
2.5 Active Learning

3 Feedback
3.1 Attributes of Feedback Types
3.2 Common Classes
3.3 Initialization
3.4 Choice of Feedback Type
3.5 Combination of Feedback Types

4 Label Collection
4.1 Active Learning
4.2 Challenges of Human Labeling

5 Reward Model Training
5.1 Human Feedback Model
5.2 Utility Learning
5.3 Evaluating Learned Reward Functions
5.4 Reward Model Inputs
5.5 Increasing Feedback Efficiency

6 Policy Learning
6.1 Adaptation of RL Algorithms
6.2 Framing RLHF for Generative Models as a Bandit Problem
6.3 Direct Policy Optimization

7 Theory
7.1 Policy Learning
7.2 Preference-Based vs. Reward-Based Learning
7.3 Nash Learning from Human Feedback

8 Applications and Benchmarks
8.1 Applications
8.2 Supporting Libraries
8.3 Benchmarks
8.4 Datasets
8.5 Evaluation

9 Discussion and Conclusion