1 INTRODUCTION

2 PRELIMINARIES AND TAXONOMIES  
2.1 Problem Settings  
2.2 Theoretical Foundation of Random Features  
2.3 Commonly used Kernels in Random Features  
2.4 Taxonomy of Random Features Based Algorithms  

3 DATA-INDEPENDENT ALGORITHMS  
3.1 Monte Carlo Sampling Based Approaches  
3.2 Quasi-Monte Carlo Sampling  
3.3 Quadrature Based Methods  

4 DATA-DEPENDENT ALGORITHMS  
4.1 Leverage Score Based Sampling  
4.2 Re-weighted Random Features  
4.3 Kernel Learning by Random Features  

5 THEORETICAL ANALYSIS  
5.1 Approximation Error  
5.2 Risk and Generalization Property  
5.3 Results for Nonlinear Component Analysis  

6 EXPERIMENTS  
6.1 Experimental Settings  
6.2 Results for the Gaussian Kernel  

7 TRENDS: HIGH-DIMENSIONAL RANDOM FEATURES IN OVER-PARAMETERIZED SETTINGS  
7.1 Results on High Dimensional Random Features in Over-parameterized Setting  
7.2 Discussion on Random Features and DNNs  

8 CONCLUSION