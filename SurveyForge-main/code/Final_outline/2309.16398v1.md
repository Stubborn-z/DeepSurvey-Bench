1 Introduction  
1.1 Contributions of this survey  

2 Survey methodology  

3 Preliminaries  
3.1 Differential Privacy (DP)  
3.2 Deep neural networks and stochastic gradient descent (SGD)  
3.3 Privacy threats for deep learning models  
3.4 DP algorithms for deep learning  

4 Auditing and Evaluation  
4.1 Attack-based Evaluation  
4.2 Evaluation of subgroups: bias and fairness  

5 Improving the privacy-utility trade-off of DP-DL  

6 Beyond membership and attribute inference: Applying DP-DL to protect against other threats  

7 Differentially private generative models  

8 Specific applications of DP-DL  

9 Discussion and future directions  

10 Conclusion