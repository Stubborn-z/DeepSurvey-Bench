1 INTRODUCTION

2 TAXONOMY

3 SPECIFIC OR UNIVERSAL SPEEDUP

3.1 Unstructured Pruning

3.2 Structured Pruning

3.3 Semi-structured Pruning

4 WHEN TO PRUNE

4.1 Pruning Before Training

4.2 Pruning During Training

4.3 Pruning After Training

4.4 Run-time Pruning

5 PRUNING CRITERIA

5.1 Magnitude-based Pruning

5.2 $l_{p}$ Norm

5.3 Sensitivity and/or Saliency

5.4 Loss Change

6 LEARN TO PRUNE

6.1 Sparsity Regularization based Pruning

6.2 Meta-Learning based Pruning

6.3 Graph Neural Network based Pruning

6.4 Reinforcement Learning based Pruning

7 A COMPREHENSIVE COMPARATIVE ANALYSIS

7.1 Unstructured vs. Structured Pruning

7.2 One-shot vs. Iterative Pruning

7.3 Data-free vs. Data-driven Pruning

7.4 Pruning on Initialized vs. Pre-trained Weights

7.5 Global vs. Local Pruning

7.6 Training from Scratch vs. Fine-tuning

7.7 Original Task vs. Transfer Pruning

7.8 Static vs. Dynamic Pruning

7.9 Layer-wise Weight Density Analysis

7.10 Pruning with Different Levels of Supervision

8 FUSION OF PRUNING AND OTHER COMPRESSION TECHNIQUES

9 SUGGESTIONS AND FUTURE DIRECTIONS

9.1 Recommendations on Pruning Method Selection

9.2 Future Directions

10 CONCLUSION