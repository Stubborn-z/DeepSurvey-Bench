1 INTRODUCTION

2 RELATED WORK
2.1 Crowdsourcing Surveys
2.2 Large Language Models
2.3 Impact of Large Language Models on Crowdsourcing Studies
2.4 Prompt Injection as a Remedy

3 PROMPT INJECTION IN LARGE LANGUAGE MODELS
3.1 Prompt Structure
3.2 Injecting Attack Prompts

4 CASE STUDY â€“ DAILY-LIFE SCENARIO RECOMMENDATION
4.1 Task Description
4.2 Details in Attack Prompt Construction and Injection
4.3 Evaluation

5 RESULTS
5.1 Effectiveness of Attack Prompts
5.2 Length of Attack Prompts

6 SOFTWARE

7 DISCUSSION
7.1 Alternative Approaches for Discerning or Mitigating LLM-generated Responses
7.2 Diversity of Opinions among Crowdsourcing Workers
7.3 Influence of LLMs on the Trustworthiness of Crowdsourcing Surveys
7.4 Limitations

8 CONCLUSION