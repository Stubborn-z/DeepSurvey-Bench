1 Introduction  
2 Background  
2.1 Stochastic Gradient Descent  
2.2 Data and Model Parallelism  
2.3 Centralized and Decentralized Architectures  
2.4 Synchronous and Asynchronous Updates  
3 Algorithm Optimization  
3.1 Communication Rounds  
3.2 Gradients Compression  
3.3 Computation-Communication Overlap  
4 Network Level Optimization  
4.1 Logical Architectures  
4.2 Message Level Libraries  
4.3 Network Protocols  
5 Conclusion Remarks