1 INTRODUCTION  
2 BACKGROUND  
2.1 2D and 3D Data, Rendering and Inverse Rendering  
2.2 Implicit Scene Representations  
2.3 Differentiable Neural Rendering  
2.4 INR-based Novel View Synthesis  
2.5 Dataset  
2.6 Evaluation Metrics  
3 OVERVIEW OF DEEP GENERATIVE 3D-AWARE IMAGE SYNTHESIS  
3.1 Goal and Challenge  
3.2 Comparisons between Two Primary Categories  
3.3 Relationships with INR-based Novel View Synthesis  
4 3D CONTROL OF 2D GENERATIVE MODELS  
4.1 Exploring 3D Control in 2D Latent Spaces  
4.2 Incorporating 3D Parameters as Controls  
4.3 Introducing 3D Prior Knowledge as Constraints  
5 3D-AWARE GENERATIVE MODELS  
5.1 Unconditional 3D-aware GANs  
5.2 Unconditional 3D-aware Diffusion Models  
5.3 Conditional 3D Generative Models  
6 DISCUSSION  
7 CONCLUSION