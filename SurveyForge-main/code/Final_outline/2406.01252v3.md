1 Introduction  
2 Overview  
2.1 Scope of Automated Alignment  
2.2 Taxonomy  
3 Aligning Through Inductive Bias  
3.1 Inductive Bias from Features of LLMs  
3.2 Inductive Bias from Organization of LLMs  
4 Aligning Through Behavior Imitation  
4.1 Instruction Construction  
4.2 Strong-to-Weak Distillation  
4.3 Weak-to-Strong Alignment  
5 Aligning Through Model Feedback  
5.1 Scalar Reward  
5.2 Binary Verifier  
5.3 Text Critic  
6 Aligning Through Environment Feedback  
6.1 Social Interactions  
6.2 Human Shared-Values  
6.3 Tool Execution Feedback  
6.4 Embodied Environment  
7 Underlying Mechanism of Automated Alignment  
7.1 What is the underlying mechanism of current alignment?  
7.2 Why does self-feedback work?  
7.3 Why is weak-to-strong feasible?  
8 Conclusions