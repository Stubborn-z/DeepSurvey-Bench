1 Introduction

2 Theoretical Background  
2.1 Physically-based Rendering  
2.2 Geometry and Space  
2.3 Materials  
2.4 Illumination  

3 Single Image Inverse Appearance Reconstruction  
3.1 Intrinsic Image Formation Models  
3.2 Semantic Priors  

4 Datasets  
4.1 Objects  
4.2 Scenes  

5 Learning Formulation  
5.1 Weak-Supervision: Learn from Relative Human Judgments  
5.2 Full-Supervision: Learn from Labeled Data  
5.3 Self-Supervision: Learn from the Image Formation Model  
5.4 Priors  

6 Deep Neural Network Architectures  
6.1 Pairwise Comparison  
6.2 Image-to-Image Translation  

7 Evaluation  
7.1 Pixel-wise Error Metrics  
7.2 Human Disagreement Metrics  

8 Discussion  
8.1 Outperforming Learning Strategies  
8.2 Training and Testing Data  
8.3 Quantitative Errors as Indicator of Performance  
8.4 The Influence of the Material Model  

9 Research Opportunities and Future Directions  
9.1 Enhancing Generalization  
9.2 Evaluation Frameworks  
9.3 Beyond Lambert  

10 Conclusions