1 INTRODUCTION  
2 FOUNDATIONS  
2.1 Self-Attention in Transformers  
2.2 Self-Supervised Pre-training  
2.3 Transformer Model  
2.4 Bidirectional Representations  
3 SELF-ATTENTION & TRANSFORMERS IN VISION  
3.1 Single-head Self-Attention  
3.2 Multi-head Self-Attention (Transformers)  
3.3 Transformers for Object Detection  
3.4 Transformers for Segmentation  
3.5 Transformers for Image and Scene Generation  
3.6 Transformers for Low-level Vision  
3.7 Transformers for Multi-Modal Tasks  
3.8 Video Understanding  
3.9 Transformers in Low-shot Learning  
3.10 Transformers for Clustering  
3.11 Transformers for 3D Analysis  
4 OPEN CHALLENGES & FUTURE DIRECTIONS  
4.1 High Computational Cost  
4.2 Large Data Requirements  
4.3 Vision Tailored Transformer Designs  
4.4 Neural Architecture Search for ViTs  
4.5 Interpretability of Transformers  
4.6 Hardware Efficient Designs  
4.7 Towards Integrating All Modalities  
5 CONCLUSION