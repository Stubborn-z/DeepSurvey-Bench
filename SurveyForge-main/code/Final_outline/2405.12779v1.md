1 Introduction
2 Foundations
2.1 Self-Attention in Transformers
2.2 (Self) Supervised Pre-training
2.3 Transformer Model
3 Datasets
4 Tasks and Transformers
4.1 Touch-Centric Tasks and Tactile-Only Transformers
4.2 Visuo-Tactile Tasks and Visuo-Tactile Transformers
5 Open Challenges and Future Directions
5.1 High Computational Cost
5.2 Large Data Requirement
5.3 Touch-Tailored Transformer Design
5.4 Hardware Efficient Design
5.5 Towards Integrating All Modalities
6 Conclusion