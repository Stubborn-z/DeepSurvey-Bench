INTRODUCTION
1.1 Survey Overview  
1.2 Synopsis of StyleGAN Applications  
1.3 Training datasets  

STYLEGAN ARCHITECTURES FOR GENERATION OF FACES
2.1 Generative Adversarial Networks  
2.2 Progressive growing GANs (PGGAN)  
2.3 StyleGAN  
2.4 StyleGAN2  
2.5 StyleGAN3  

MEASURING SIMILARITY OF FACES
3.1 Adversarial Loss  
3.2 L2 Loss  
3.3 LPIPS Loss  
3.4 Identity Preservation Loss  
3.5 Fr√©chet Inception Distance FID  

LATENT SPACES OF STYLEGAN
4.1 Z and Z+ spaces  
4.2 W space  
4.3 W+ space  
4.4 s space  

INVERSION TO LATENT SPACES OF STYLEGAN
5.1 Major groups of inversion methods  
5.2 Evaluating GAN Inversions  
5.3 Inversion Encoders  
5.4 Fine-tuning of the StyleGAN generator  

EDITING FACE IMAGES WITH STYLEGAN
6.1 Global semantic directions  
6.2 Single image semantic directions  

CROSS DOMAIN FACE STYLIZATION
7.1 Fine-tuning generator to the target style domain  
7.2 Layer swapping  
7.3 Blending for Stylized Face Generation  
7.4 CLIP-Guided Domain Adaptation of StyleGAN  

FACE RESTORATION WITH STYLEGAN
8.1 GAN Prior Embedded Network for Blind Face Restoration in the Wild  
8.2 GFP-GAN: Towards Real-World Blind Face Restoration with Generative Facial Prior  
8.3 MyStyle: A Personalized Generative Prior  
8.4 VAEs with Codebooks - Alternative Approaches  

DEEPFAKES
9.1 Face Reenactment  
9.2 Face Replacement and Face Transfer  

ALTERNATIVE FACE GENERATION AND EDITING APPROACHES
10.1 3D-Consistent Generative Adversarial Networks  
10.2 Diffusion Models  

CONCLUSION