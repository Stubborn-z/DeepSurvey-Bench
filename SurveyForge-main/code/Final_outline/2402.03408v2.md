1 Introduction  
2 Background  
2.1 Task Definition  
2.2 LLM Services Invocation Framework  
3 Input Abstract  
4 Semantic Cache  
5 Solution Design  
6 Output Enhancement  
7 Conclusion and Challenges