1. Introduction  
2. Reasons for Explainability and Demanding Domains  
2.1 Reasons for Explainability  
2.2 Domains Demanding Explainability  
3. Concepts of Explainability  
3.1 Problem Definition and Dimensions  
3.2 Five Ways to Gain Interpretability  
3.3 Interpretable Model Types  
3.4 General-Purpose Techniques for Interpretability by Design  
3.5 The Explanation  
3.6 Assessment of Explainability  
4. Interpretable Model Learning  
4.1 Interpretable by Nature  
4.2 Interpretable by Design  
5. Surrogate Models  
5.1 Global Surrogates  
5.2 Local Surrogates  
6. Explanation Generation  
6.1 Global Explanation Generation  
6.2 Local Explanation Generation  
7. Data and Explainability  
7.1 Data Quality  
7.2 Data Visualization  
7.3 Ontologies  
8. Discussion and Open Challenges  
9. Conclusion