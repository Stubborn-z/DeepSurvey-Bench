1 Introduction  
1.1 Self-attention  
1.2 Masked self-attention  
1.3 Multi-head attention  

2 Attention based deep learning architectures  
2.1 Single-channel model  
2.2 Multi-channel model  
2.3 Skip-layer model  
2.4 Bottom-up/top-down model  
2.5 Skip-layer model with multi-scale saliency single network  

3 Attention and deep learning in machine vision: Broad categories  
3.1 Attention-based CNNs  
3.2 CNN transformer pipelines  
3.3 Hybrid transformers  

4 Major research algorithms, issues, and trends  

5 Conclusion