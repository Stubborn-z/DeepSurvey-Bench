1 INTRODUCTION

2 ATTENTION BASICS

3 ATTENTION MODEL

4 TAXONOMY OF ATTENTION
4.1 Number of sequences
4.3 Number of positions
4.4 Number of representations

5 NETWORK ARCHITECTURES WITH ATTENTION
5.1 Encoder-Decoder
5.2 Transformer
5.3 Memory Networks
5.4 Graph Attention Networks (GAT)

6 APPLICATIONS
6.1 Natural Language Processing (NLP)
6.2 Computer Vision (CV)
6.3 Multi-Modal Tasks
6.4 Recommender Systems
6.5 Graph-based Systems

7 ATTENTION FOR INTERPRETABILITY

8 CONCLUSION