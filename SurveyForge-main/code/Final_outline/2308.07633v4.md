1 Introduction  
2 Metrics and Benchmarks  
2.1 Metrics  
2.2 Benchmarks and Datasets  
3 Quantization  
3.1 Quantization-Aware Training  
3.2 Post-Training Quantization  
4 Pruning  
4.1 Unstructured Pruning  
4.2 Structured Pruning  
4.3 Semi-Structured Pruning  
5 Knowledge Distillation  
5.1 Black-box KD  
5.2 White-box KD  
6 Low-Rank Factorization  
7 Challenges and Future Directions  
7.1 More Advanced Methods  
7.2 Scaling Up Model Compression Methods from Other Models  
7.3 LLM Inference and Deployment  
7.4 The Effect of Scaling Law  
7.5 AutoML for LLM Compression  
7.6 Explainability of LLM Compression  
8 Conclusion