Chapter 1  
Introduction  
1.1 Outline  
1.2 The Learning Framework  
1.3 Assumptions in Semi-Supervised Learning  

Chapter 2  
Possibility and Impossibility of Semi-Supervised Learning  
2.1 Impossibility Results  
2.2 On the Possibility of Semi-Supervised Learning  

Chapter 3  
Learning without Assumptions  
3.1 Reweighing the Labeled Data by the True Marginal  
3.2 Picking the Center of the Version Space  
3.3 Combining Multiple Hypothesis Spaces  

Chapter 4  
Learning under Weak Assumptions  
4.1 A General Framework to Encode Weak Assumptions  
4.2 Assuming that the Feature Space can be Split  

Chapter 5  
Learning under Strong Assumptions  
5.1 Assuming the Model is Identifiable  
5.2 Assuming Classes are Clustered and Separated  
5.3 Assuming Classes are Clustered but not Necessarily Separated  
5.4 Assuming Regression is Smooth Along a Manifold  

Chapter 6  
Learning in the Transductive Setting  
6.1 Transductive Learning Bounds  
6.2 Safe Transductive Learning  

Chapter 7  
Discussion and Conclusion  
7.1 On the Limits of Assumption Free SSL  
7.2 How Good Can Constant Improvement Be?  
7.3 The Amount of Unlabeled Data We Need  
7.4 Using Assumptions in Semi-Supervised Learning