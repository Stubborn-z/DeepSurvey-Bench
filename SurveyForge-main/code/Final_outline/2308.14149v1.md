1 INTRODUCTION

2 GPT AND GPT-LIKE MODELS  
2.1 History of Large Language Foundation Models  
2.2 Open Language Foundation Models  
2.3 Evaluation Models  
2.4 Evaluation Prompts  

3 PRE-TRAINING AND FINE-TUNING DATA  
3.1 Pre-training Data  
3.2 Fine-tuning / Instruction Tuning Data  

4 DEPLOYMENT AND FINE-TUNING TECHNIQUES  
4.1 Efficient Deployment  
4.2 Efficient Fine-tuning  

5 OPEN-SOURCE TOOLS  

6 BENCHMARK EVALUATIONS  
6.1 Evaluation Methods  
6.2 Zero-shot Evaluation  
6.3 Few-shot evaluation  

7 HUMAN EVALUATION  
7.1 Evaluation Setup  
7.2 Evaluation Process  
7.3 Results and Analysis  

8 MULTIMODAL GPT MODELS AND EVALUATION  
8.1 History of Multimodal Foundation Models  
8.2 Models Summary  
8.3 Benchmark Evaluations  

9 SCIENTIFIC GPT MODELS AND EVALUATION  
9.1 Model Summary  
9.2 Benchmark Evaluations  

10 MISCS  
10.1 Chinese GPT Models  
10.2 ChatGPT-like Models on Different Applications  
10.3 Tool Learning with Foundation Models  

11 CONCLUSION AND FUTURE DIRECTIONS  
11.1 Limitations  
11.2 Challenges and Future Directions