ARTICLE INFO

1. Introduction

2. Background

2.1. Contrastive Language-Image Pre-training

2.2. Variants of CLIP

2.3. Medical image-text dataset

3. CLIP in medical image-text pre-training

3.1. Challenges of CLIP pre-training

3.2. Multi-scale contrast

3.3. Data-efficient contrast for image-text alignment

3.4. Explicit knowledge enhancement

3.5. Others

3.6. Summary

4. CLIP-driven applications

4.1. Classification

4.2. Dense prediction

4.3. Cross-modal tasks

4.4. Summary

5. Comparative analysis

6. Discussions and future directions

7. Conclusion