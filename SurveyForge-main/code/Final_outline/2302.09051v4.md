1 Introduction  
1.1 Structure of the paper  
1.2 Contribution  
1.3 Survey methodology  

2 Core concepts & architectures  
2.1 Definitions  
2.2 Question answering typical pipeline  
2.3 Modular approaches before transformers  
2.4 LLM with transformers breakthrough  

3 Analyzing: complexity, skills, tasks, and limits  
3.1 What are complex questions?  
3.2 Skills  
3.3 Tasks  
3.4 LLM limits  

4 Evaluating: metrics, cost functions, datasets  
4.1 Metrics & performance SOTA  
4.2 Cost functions  
4.3 Datasets  

5 Solving with training  
5.1 Training dataset quality  
5.2 Type of LLM training  
5.3 Pre-training techniques  
5.4 Supervised learning & fine-tuning  
5.5 Parameter-efficient tuning (PEFT) of a frozen PLM  
5.6 Techniques for improving training  

6 Solving with hybridization (architecture composition)  

7 Solving with prompting  
7.1 Designing my question (prompting)  
7.2 Problem solving strategies  
7.3 Enhancing knowledge or skills Prompt can be engineered in order to enhance  

8 Solving with reinforcement (experience loop, knowledge capitalization)  
8.1 Reinforcement learning methods  
8.2 Human-in-the-loop (RLHF)  

9 Discussion: limitations and research topics for solving more complex QA and problems  
9.1 Hallucination & credibility  
9.2 Compute, scaling... Costs  
9.3 Data availability & quality  
9.4 Data multi-sensitivity usage & protection  
9.5 Decomposition of very complex QA and explainability  

10 Conclusion