1 Introduction

2 Problem: setting and assumptions

3 Deterministic foundation: Extra gradient and others

4 Stochastic methods: different setups and assumptions
4.1 General case
4.2 Finite-sum case
4.3 Cocoercivity assumption
4.4 High-probability convergence

5 Recent advances
5.1 Saddle point problems with different constants of strong convexity and strong concavity
5.2 Adaptive methods for VI and SPP
5.3 Quasi-Newton and tensor methods for VI and SPP
5.4 Convergence in terms of the gradient norm for SPP
5.5 Decentralized VI and SPP