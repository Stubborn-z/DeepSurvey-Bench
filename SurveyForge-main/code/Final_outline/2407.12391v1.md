I. INTRODUCTION  
II. BACKGROUND  
A. Overview of Transformer-based LLM Architecture  
B. Overview of LLM Inference  
III. MEMORY MANAGEMENT AND CACHING  
IV. COMPUTATION TASK SCHEDULING  
V. LLMs IN THE CLOUD  
VI. EMERGING RESEARCH FIELDS