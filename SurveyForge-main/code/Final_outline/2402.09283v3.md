1 Introduction
2 Attacks
2.1 Inference-Time Attacks
2.2 Training-Time Attacks
3 Defenses
3.1 LLM Safety Alignment
3.2 Inference Guidance
3.3 Input and Output Filters
4 Evaluations
4.1 Evaluation Datasets
4.2 Evaluation Metrics
5 Conclusion