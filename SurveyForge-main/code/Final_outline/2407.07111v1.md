INTRODUCTION
BACKGROUND
2.1 Mathematical Framework
2.2 Image Diffusion Models
2.3 Video Generation and Motion Representation
DIFFUSION MODEL-BASED VIDEO EDITING
3.1 Network and Training Paradigm
3.2 Attention Feature Injection
3.3 Diffusion Latent Manipulation
3.4 Canonical Representation
3.5 Novel Conditioning
BENCHMARKING
4.1 Video Editing Dataset
4.2 Evaluation Metrics
4.3 Comparative Analysis
CHALLENGES AND EMERGING TRENDS
CONCLUSION