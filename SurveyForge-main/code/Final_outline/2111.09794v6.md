1. Introduction  
2. Related Work: Surveys in Reinforcement Learning Subfields  
3. Formalizing Zero-shot Generalization in Reinforcement Learning  
3.1 Background: Generalization in Supervised Learning  
3.2 Background: Reinforcement Learning  
3.3 Contextual Markov Decision Processes  
3.4 Training and Testing Contexts  
3.5 Real World Examples of This Formalism  
3.6 Additional Assumptions for More Feasible Generalization  
3.7 Remarks and Discussion  
4. Benchmarks for Zero-shot Generalization in Reinforcement Learning  
4.1 Environments  
4.2 Evaluation Protocols for ZSG  
4.3 Discussion  
5. Methods for Zero-shot Generalization in Reinforcement Learning  
5.1 Increasing Similarity Between Training and Testing  
5.2 Handling Differences Between Training and Testing  
5.3 RL-Specific Problems and Improvements  
5.4 Discussion  
6. Discussion and Future Work  
6.1 Generalization Beyond Zero-Shot Policy Transfer  
6.2 Real World Reinforcement Learning Generalization  
6.3 Multi-Dimensional Evaluation of Generalization  
6.4 Tackling Stronger Types of Variation  
6.5 Understanding Generalization in Reinforcement Learning  
6.6 Future Work on Methods for Zero-shot Generalization  
7. Conclusion