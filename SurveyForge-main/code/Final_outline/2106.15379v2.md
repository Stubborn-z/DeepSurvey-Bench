Relaxed MVU, and landmark MVU for big data.

1. Introduction

Required Background for the Reader

2. Unified Framework for Spectral Methods

2.1. Learning Eigenfunctions

2.2. Unified Framework as Kernel PCA

2.3. Summary of Kernels in Spectral Methods

2.4. Generalized Embedding

3. Background on Semidefinite Programming

3.1. Unconstrained Optimization

3.2. Equality Constrained Optimization

3.3. Inequality Constrained Optimization

3.4. Semidefinite Programming

4. Kernel Learning for Transduction

5. Maximum Variance Unfolding (or Semidefinite Embedding)

5.1. Intuitions and Comparison with Kernel PCA

5.2. Local Isometry

5.3. Centering

5.4. Positive Semidefiniteness

5.5. Manifold Unfolding

5.6. Spectral Embedding

6. Supervised Maximum Variance Unfolding

6.1. Supervised MVU Using $k\mathbf{NN}$ within Classes

6.2. Supervised MVU by Class-wise Unfolding

6.3. Supervised MVU by Fisher Criterion

6.4. Supervised MVU by Colored MVU

7. Out-of-sample Extension of MVU

7.1. Out-of-sample Extension Using Eigenfunctions

7.2. Out-of-sample Extension Using Kernel Mapping

8. Other Variants of Maximum Variance Unfolding

8.1. Action Respecting Embedding

8.2. Relaxed Maximum Variance Unfolding

8.3. Landmark Maximum Variance Unfolding for Big Data

8.4. Other Improvements over Maximum Variance Unfolding and Kernel Learning

9. Conclusion