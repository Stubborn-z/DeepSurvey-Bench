1. Introduction

2. Background  
2.1 LLM-generated Text Detection Task  
2.2 LLMs Text Generation and Confusion Sources  
2.3 Why Do We Need to Detect Text Generated by LLMs?

3. Related Works and Our Investigation  
3.1 Related Works  
3.2 Systematic Investigation and Implementation

4. Data  
4.1 Training  
4.2 Evaluation Benchmarks  
4.3 Data Challenges

5. Advances in Detector Research  
5.1 Watermarking Technology  
5.2 Statistics-Based Methods  
5.3 Neural-Based Methods  
5.4 Human-Assisted Methods

6. Evaluation Metrics

7. Important Issues of LLM-generated Text Detection  
7.1 Out of Distribution Challenges  
7.2 Potential Attacks  
7.3 Real-World Data Issues  
7.4 Impact of Model Size on Detectors  
7.5 Lack of Effective Evaluation Framework

8. Future Research Directions  
8.1 Building Robust Detectors with Attacks  
8.2 Enhancing the Efficacy of Zero-shot Detectors  
8.3 Optimizing Detectors for Low-resource Environments  
8.4 Detection for Not Purely LLM-Generated Text  
8.5 Constructing Detectors Amidst Data Ambiguity  
8.6 Developing Effective Evaluation Framework Aligned With Real-World  
8.7 Constructing Detectors with Misinformation Discrimination Capabilities

9. Conclusion