1. Introduction
2. The Basic Preference-based Multi-Armed Bandit Problem
2.1 Learning Protocol
2.2 Learning Tasks
2.3 Performance Measures
2.4 Algorithm Classes
3. Learning from Coherent Pairwise Comparisons
3.1 Axiomatic Approaches
3.2 Regularity Through Latent Utility Functions
3.3 Regularity Through Statistical Models
4. Learning from Non-coherent Pairwise Comparisons
4.1 Alternative Target Concepts
4.2 Algorithms for Non-coherent Preference Relations
5. Further Extensions
5.1 Adversarial Dueling Bandits
5.2 Contextual Dueling Bandits
5.3 Dueling Bandits on Posets
5.4 Graphical Dueling Bandits
5.5 Dueling Bandits with Dependent Arms
5.6 Partial Monitoring Games
5.7 Dueling Bandits for Qualitative Feedback
5.8 Combinatorial Pure Exploration for Dueling Bandits
6. Multi-Dueling Bandits
6.1 Learning Protocol
6.2 Feedback Mechanisms
6.3 Learning Tasks
6.4 Performance Measures
6.5 Algorithmic Approaches
6.6 Related Frameworks
7. Applications
8. Summary and Perspectives