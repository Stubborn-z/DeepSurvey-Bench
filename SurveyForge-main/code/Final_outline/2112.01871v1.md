I. Introduction  
A. Overview  
B. Paper Structure  

II. Active Inference Common Ground  
A. From Bayesian Inference to the Free Energy Principle  
B. Generative Models  
C. Perception and Action  

III. State-Estimation  
A. State-estimation minimizes the prediction error  

IV. Control  

V. Planning  
A. Discrete-time optimization under the Markov assumption  
B. Expected Free Energy  
C. Finding the Optimal Plan  

VI. Learning  
A. Discrete-state-space  
B. Deep Active Inference  

VII. Hierarchical Representation  

VIII. Robotic Experiments  
A. Estimation  
B. Adaptive Control  
C. Fault-tolerant Control  
D. Planning  
E. Complex Cognition  

IX. Connections with Other Frameworks  
A. Relationship with Classical Controllers  
B. Relationship to Reinforcement Learning  

X. Benefits and Challenges  
A. Unified Framework  
B. Functional Biological Plausibility  
C. Variational Bayesian Inference  

XI. Summary