1 Motivation

2 Research Questions

3 Methodology

4 Background

5 Document Vectorization

6 A Primer of Neural Net Models for NLP

7 A Neural Probabilistic Language Model

8 Hierarchical Probabilistic Neural Network Language Model

9 A Hierarchical Neural Autoencoder for Paragraphs and Documents

10 Linguistic Regularities in Continuous Space Word Representations

11 Better Word Representations with Recursive Neural Networks for Morphology

12 Efficient Estimation of Word Representations in Vector Space

13 Distributed Representations of Words and Phrases and their Compositionality

14 Glove: Global Vectors for Word Representation

15 Discussion