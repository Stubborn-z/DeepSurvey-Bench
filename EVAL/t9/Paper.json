{
  "authors": [
    "Hanqing Zhang",
    "Haolin Song",
    "Shaoyu Li",
    "Ming Zhou",
    "Dawei Song"
  ],
  "literature_review_title": "A Survey of Controllable Text Generation Using Transformer-based Pre-trained Language Models",
  "year": "2022",
  "date": "2022-01-14",
  "category": "cs.CL",
  "abstract": "Controllable Text Generation (CTG) is emerging area in the field of natural\nlanguage generation (NLG). It is regarded as crucial for the development of\nadvanced text generation technologies that better meet the specific constraints\nin practical applications. In recent years, methods using large-scale\npre-trained language models (PLMs), in particular the widely used\ntransformer-based PLMs, have become a new paradigm of NLG, allowing generation\nof more diverse and fluent text. However, due to the limited level of\ninterpretability of deep neural networks, the controllability of these methods\nneed to be guaranteed. To this end, controllable text generation using\ntransformer-based PLMs has become a rapidly growing yet challenging new\nresearch hotspot. A diverse range of approaches have emerged in the recent 3-4\nyears, targeting different CTG tasks that require different types of controlled\nconstraints. In this paper, we present a systematic critical review on the\ncommon tasks, main approaches, and evaluation methods in this area. Finally, we\ndiscuss the challenges that the field is facing, and put forward various\npromising future directions. To the best of our knowledge, this is the first\nsurvey paper to summarize the state-of-the-art CTG techniques from the\nperspective of Transformer-based PLMs. We hope it can help researchers and\npractitioners in the related fields to quickly track the academic and\ntechnological frontier, providing them with a landscape of the area and a\nroadmap for future research.",
  "structure": [
    {
      "section_title": "Introduction/Pre-section",
      "level": "1",
      "content": "\\documentclass[acmsmall]{acmart} % \\providecommand\\BibTeX{{% \\normalfont B\\kern-0.5em{\\scshape i\\kern-0.25em b\\kern-0.8em\\TeX}}} acmcopyright 2023 2023 xxx multirow \\usepackage[normalem]{ulem} subfigure \\uline{\\ul}{} JACM 37 4 111 8 document A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models Hanqing Zhang zhanghanqing@bit.edu.cn % \\institution{Beijing Institute of Technology Beijing China 100089 } HaoLin Song hlsong@bit.edu.cn % \\institution{Beijing Institute of Technology Beijing China 100089 } Shaoyu Li lishaoyuxl@foxmail.com % \\institution{Beijing Institute of Technology Beijing China 100089 } Ming Zhou zhouming@chuangxin.com % \\institution{Langboat Technology Beijing China 100089 } Dawei Song Corresponding Author. Also with The Open University, UK. % \\institution{Beijing Institute of Technology Beijing China 100089 } \\shortauthors{Zhang, et al.} CCSXML <ccs2012> <concept> <concept_id>10010520.10010553.10010562</concept_id> <concept_desc>Computer systems organization~Embedded systems</concept_desc> <concept_significance>500</concept_significance> </concept> <concept> <concept_id>10010520.10010575.10010755</concept_id> <concept_desc>Computer systems organization~Redundancy</concept_desc> <concept_significance>300</concept_significance> </concept> <concept> <concept_id>10010520.10010553.10010554</concept_id> <concept_desc>Computer systems organization~Robotics</concept_desc> <concept_significance>100</concept_significance> </concept> <concept> <concept_id>10003033.10003083.10003095</concept_id> <concept_desc>Networks~Network reliability</concept_desc> <concept_significance>100</concept_significance> </concept> </ccs2012> CCSXML \\ccsdesc[500]{General and reference~Surveys and overviews} \\ccsdesc[500]{Computing methodologies~Natural language processing} controllable text generation, pre-trained language models, transformer, controllability, systematic review \\maketitle",
      "origin_cites_number": 0
    },
    {
      "section_title": "Introduction",
      "level": "1",
      "content": "Natural language generation (NLG) is regarded as complementary to natural-language understanding (NLU), an essential branch of natural language processing (NLP). Contrary to the task of NLU, which aims to disambiguate an input text to produce a single normalized representation of the ideas expressed in the text, NLG mainly focuses on transforming the potential representations into specific, self-consistent natural language text~nlu_nlg. In other words, NLU aims to develop an intelligent machine that can read and understand human language, while NLG enables computers to write like humans. As an embodiment of advanced artificial intelligence, NLG technologies play a crucial role in a range of applications, such as dialogue systems, advertising, marketing, story generation, and data augmentation. %figure环境 Making text generation controllable is an important and fundamental issue in NLG. Some concrete examples are shown in Figure~intro_example. Generally speaking, a NLG system should be able to reliably generate texts that meet certain controllable constraints that are imposed by the targeted applications and users. In general, these constraints are task-specific. For example, the task of story generation always needs to control the storyline and the ending. In the task of dialogue response generation, controlling the emotion~emotion_dialogue_generation, persona~zhang2018personalizing and politeness, etc., is often required. For generation-based data augmentation~bias_correction, it is necessary to ensure the data distribution balance in different domains. Moreover, for ethical development~ai_dangers of AI applications, it is crucial to avoid generating mindless and offensive content such as gender bias, racial discrimination, and toxic words. Therefore, the controllability of a NLG system is crucial for it to generate a significant practical value in real applications. In recent years, the development of deep learning (DL) has given rise to a series of studies on DL-driven controllable text generation (CTG), which has brought genuine breakthroughs in this field. Early approaches are based on sequential models and style embedding~rnn_style,li2016persona, and achieved some promising progress. After that, there is a surge of methods based on deep generative models, such as Variational Autoencoders (VAEs)~thematic_poetry,icml_ctg_vae,LSOR_DCGM,chinses_lyric,unsupervised_GVD,wang2019topic, Generative Adversarial Nets (GANs)~SentiGAN,DAS, and Energy-based Models~ebm_ctg,energy_based_generative_adversarial_network,bhattacharyya-etal-2021-energy,engine_ebm_acl2020. Deep-learning based methods are capable of an end-to-end learning in a data-driven way to learn low-dimensional dense vectors that implicitly represent the linguistic features of text. Such representation is also useful to avoid the bias of hand-crafted features, and has shown great potential in text generation. However, the success of the above DL-based methods relies heavily on large-scale datasets, posing a challenge for supervised and cross-domain text generation tasks. Since 2018, large-scale pre-trained Language models (PLMs) such as BERT~bert, RoBERTa~roberta, GPT~gpt2, T5~t5 and mBART~mbart, have gradually become a new paradigm of NLP. Owing to its use of large corpora and unsupervised learning based on the Transformer structure, PLMs are believed to have learned a great deal of semantic and syntactic knowledge from the data, and only fine-tuning is required for downstream tasks to get the state-of-the-art (SOTA) performance. In terms of NLG, PLMs have learned from a large number of corpus materials to model the distribution of natural language to a large extent, so that they are able to generate texts of unprecedented quality~ebm_ctg. Moreover, a large-scale PLM itself can be viewed as a well-informed knowledge base, making it possible to generate text without the need for external domain knowledge. Nevertheless, PLMs are neural network based, which essentially are still black boxes, lacking a good level of interpretability. Those models always generate texts according to the latent representation of the context. Thus it is difficult to control them to generate content as what the human want (i.e., controllability issues). How to improve the interpretability and controllability of the PLM-based models for generating text has become a hot research topic. In the above application and research contexts, PLMs-based methods are becoming the mainstream of controllable text generation (CTG) research and are expected to bring milestone progress. As a rapidly growing yet challenging research field, there is an urgent need for a comprehensive critical review of the current literature to draw a landscape of the area and set out a roadmap for promising future directions. There are some existing surveys on CTG ~survey_ctg, but it lacks (1) a systematic review of representative application tasks, main approaches, and evaluation methodologies of CTG; (2) a tracking of the latest large-scale PLM-based CTG approaches. In this paper, we provide an introduction to the main tasks and evaluation metrics related to CTG, a dedicated and comprehensive literature review on CTG approaches using PLMs, and finally, an outlook on the possible future research directions. We hope that this survey paper will help researchers and practitioners to quickly capture the overall picture as well as detailed cutting-edge methods in PLM-based CTG, and promote the further development of this promising area. The remainder of the paper is organized as follows: Section~Introduction_PLM gives a brief introduction to the two critical aspects of the area, i.e., the fundamental concepts of CTG and PLMs. Then, we divide the main approaches to PLM-based CTG into three categories and discuss them in more detail in Section~approach. Section~evaluation summarizes the relevant evaluation methodologies and metrics for CTG. In Section~Challenges_and_Future_Direction, we discuss the challenges that the field is facing and put forward a number of promising future directions. Finally, we conclude the paper in Section~conclusion. All the literature appearing in this paper is filtered following two rules. First, we tend to select the latest papers that appeared within 3-4 years, ensuring the timeliness of the surveyed works. Second, we preferably select the works that are influential in the NLP community, e.g., the papers published in the leading conferences or journals in the NLP field, such as ACL, EMNLP, NAACL and TACL; and the works that are highly cited or have received widespread attention in the open source community.",
      "origin_cites_number": 16
    },
    {
      "section_title": "An Introduction to Controllable Text Generation and Pre-trained Language Models",
      "level": "1",
      "content": "This paper is closely related to two key aspects: controllable text generation and pre-trained language models, which will be briefly introduced in this section.",
      "origin_cites_number": 0
    },
    {
      "section_title": "Controllable Text Generation",
      "level": "2",
      "content": "Controllable text generation (CTG) refers to the task of generating text according to the given controlled element~survey_ctg. As shown in Figure ~fig:ipo_ctg, a typical CTG system consists of three components: the controlled element, including a controlled condition (e.g., a positive sentiment) and a source text (which can be vacant or just a text prompt in some applications) as input (I); the generative model (e.g., a PLM-based model) as the process (P), and the generated text satisfying the input control condition, as output (O). Take sentiment control as an example. If we want to generate a sentence with a positive emotion, then the condition ``positive sentiment'' and corresponding prompt ``I am always'' are taken as the control element and input to a PLM-based generative model. The output sentence's sentiment disposition would satisfy the controlled element, such as ``I am always happy to see you''. %figure环境 Depending on different applications, the attributes of control conditions can be in different forms and connotations. They could range from text attribution (such as sentiment, topic, and keywords); author style and speaker identity of the person writing the text (such as gender and age); text genre and formats (such as poems, couplets); ordering of events (such as storylines); to structured data description (such as table-to-text and Knowledge Graph (KG)-to-text generation). All the above task types can be formalized mathematically in a unified form as follows. Given a vocabulary $V$, the goal of CTG is to generate a target text $Y = \\{y_1, y_2, \\dots, y_n \\} $, where $y_n \\in V$, with respect to a control element denoted as $C$. Then CTG can be formally described as: equation P(Y|C) = p(y_1, y_2, \\dots, y_n | C) equation The specific expression of $C$ may vary according to different tasks. We divide the commonly used control conditions into three categories, i.e., semantic, structural, and lexical constraints, as shown in Figure~fig:control_type. The sentence $Y$ generated by a CTG model is expected to satisfy the constraint conditions while conforming to the general natural language characteristics, such as fluency, rationality and readability, to the greatest extent. %figure环境 \\subsection {Tasks and Applications Involving CTG} Controllability is the fundamental problem of text generation, which is indeed required by almost all text generation scenes. Here, we only focus on those with explicitly controlled conditions and goals. Table ~ctg_task summarizes typical tasks and applications involving CTG, with a description of the input/output, controlled aspects, and representative references. They are explained in more detail below: itemize \\item Attribute-based Generation: Attribute-based CTG aims to generate natural language sentences that satisfy specific attributes such as topic, emotion, and keywords. Precisely controlling the various attributes of sentences is an essential requirement of intelligent writing. By combining multiple control attributes, the system can, in theory, create interpretable and controllable paragraphs or articles. Thus, attribute-controlled text generation has always been the focus of attention in the field of text generation. \\item Dialogue Generation: The goal of dialogue systems is to build an agent who can mimic human conversations using natural language. Generative dialogue models often have higher requirements in consistency, semantics, and interactiveness~huang2020challenges. Therefore, the constraints on emotion, the speaker's personal style, dialogue intent/action, etc., are used to control the dialogue responses and improve the interactivity of dialogue systems. \\item Storytelling: Storytelling requires the model to generate texts with a complete narrative logic, which needs a higher level of control on long text generation. Storylines and story endings are often regarded as controlled conditions, and the model needs to produce stories with fluent text and sound plots according to the given controlled conditions. \\item Data to Text: The main goal of data-to-text generation is to convert non-linguistic structured data (e.g., a table or a graph) into natural language text, which can be applied in tasks like weather forecast, healthcare~ferreira2019neural, and so on. The controllability of data-to-text tasks is to ensure that the generated text contains information manifested in the original structure data. \\item Data Augmentation: Neural networks heavily rely on a large amount of labeled data. Nowadays, the importance of data augmentation is becoming more conspicuous, given the significant cost of data collection and cleaning. Since recent neural network models are capable of generating near-realistic text, it is possible to utilize them to expand existing datasets and even create new data. Identifying and replacing some entities in the given text or generating new sentences according to given attributes through CTG has become an efficient way for data augmentation. \\item Debiasing: Biased training data may cause a model to learn incorrect knowledge, and accordingly produce biased results. Therefore, text debiasing has attracted increasing attention. Debiasing by rewriting the biased text or changing the data distribution of CTG-generated text has been shown feasible. The major controllable aspects in this task include gender, race, and toxicity. \\item Format Control Tasks: There are also CTG tasks that need to control the format of the generated text, such as text length and rhythm. For example, the task of generating traditional Chinese poetry and couplet has strict requirements in format, including the number of words, structure, etc. itemize",
      "origin_cites_number": 26
    },
    {
      "section_title": "Transformer-based Pre-trained Language Models",
      "level": "2",
      "content": "table*[] \\renewcommand1.5 An overview of the characteristics of typical PLMs. \"MLM\" means \"Mask Language Model\"; \"NSP\" means \"Next Sentence Prediction\"; \"SLM\" means \"Standard Language Mode\"; \"CTR\" means \"Corrupted Text Reconstruction\"; \"FTR\" means \"Full Text Reconstruction\"; \"PLM\" means \"Permutation Language Modeling\"; and \"TLM\" means \"Translation Language Modeling\". The detailed definition of the pre-training task can be seen in literature~\\cite{pretrain_prompt_survery.} \\linewidth{!}{ tabular{|c|c|c|c|c|} \\hline Name & Model Type & Infrastructures &Pre-training Task &Main Application \\\\ \\hline BERT~bert & AE & Encoder & MLM+NSP & NLU \\\\ \\hline XLNET~Xlnet & AR & Transformer-XL & PLM & NLU \\\\ \\hline GPT2~gpt2,GPT3~gpt3 & AR & Decoder & SLM &NLG \\\\ \\hline T5~t5 & Seq2Seq & Encoder+ Decoder & CTR &NLG+NLU \\\\ \\hline mBART~mbart & Seq2Seq & Encoder+ Decoder & FTR &NLG \\\\ \\hline UniLM~UniLM & tabular[c]{@{}l@{}}AE+AR+Seq2Seqtabular& Encoder+Decoder & SLM+CTR+NSP &NLG+NLU \\\\ \\hline ERNIE-T~ERNIE &AE &Encoder &CTR+NSP &NLU \\\\ \\hline XLMXLM &Seq2Seq & Encoder+ Decoder &TLM & NLG \\\\ \\hline Bloomscao2022bloom & AR & Decoder & SLM & NLG \\\\ \\hline PaLMchowdhery2022palm & AR & Decoder & SLM & NLG \\\\ \\hline LLaMAtouvron2023llama & AR & Decoder & SLM & NLG \\\\ \\hline tabular } table* Recent years have witnessed the emergence and successful applications of large scale pre-trained language models (PLMs). They are regarded as a revolutionary breakthrough in deep learning and NLP. During the pre-training stage, the use of large-scale unlabeled data can provide a strong support to an increased model scale and a better grasp of the diverse knowledge (e.g., linguistic knowledge, commonsense, facts, expertise, etc.) in the data. State-of-the-art (SOTA) performance has been achieved in downstream tasks by fine-tuning the PLMs based on only a small amount of supervised data. The early work related to PLMs can be traced back to NNLM~nnlm, word2Vector~word2vector, and ELMo~ELMo. More recently, the pre-trained models based on Transformer~attention_is_all_your_need, a purely attention-based deep neural network, have greatly improved the performance in almost all NLP tasks and become the mainstream. Nowadays, the representative PLM infrastructures are mainly based on Transformer~attention_is_all_your_need or its variants such as Transformer-XL~transformer_xl, Longformer~longformer and Reformer~reformer. Thus this paper is focused on Transformer-based PLMs. The objectives of model learning mainly include masked language modeling (MLM), corrupted text reconstruction (CTR), etc. In order for a good understanding of them, we give a summary of the representative PLMs in Table~PLMs according to their data construction modes, model infrastructures, pre-training tasks, and main applications. Here, we roughly divide the existing PLMs into the following three categories and provide a brief introduction to each of them. Auto-Encoding (AE) Models: This type of PLMs is constructed based on destroying the input text in some way, such as masking some words of a sentence and then trying to reconstruct the original text. Typical examples of this type include BERT, ROBERTA, and ERNIE. Because these models aim to build bidirectional encoding representations of the entire sentences, their infrastructures often correspond to the encoder part of Transformer, which does not contain any masked attention mechanism, and all input can be accessed at each location. They can then be fine-tuned in downstream tasks and have achieved excellent results. The natural applications are sentence classification and sequence labeling, etc., which are more inclined to natural language understanding (NLU) tasks. Auto-Regressive (AR) Models: The main task of AR models is to predict the next word based on what has been read in the text. This is the same as the classical language modeling approach. A representative of the AR models is the GPT family. Unlike the aforementioned AE language models, the infrastructures of AR are composed of the decoder part of Transformer, and a masking mechanism is used in the training phase so that the attention calculations can only see the content before a word. While it is possible to fine-tune such a PLM and achieve excellent results on many downstream tasks, it is most natural application is NLG tasks. Seq2seq Models: The sequence-to-sequence (Seq2Seq) models use both the encoder and decoder of Transformer for better model flexibility. Currently, the most representative models of this type include T5 t5 and mBART mbart. In principle, almost all pre-trained tasks used in AE and AR models can be adapted to the seq2seq models. Relevant research~t5 has found that seq2seq models can achieve better performance. Moreover, a seq2seq model unifies the NLU and NLG tasks so that they can be solved under the same framework. It can be fine-tuned on a variety of NLG tasks such as translation and summarization, as well as NLU tasks that can be converted into a text2text form~t5, including sentence classification, semantic similarity matching, etc. Summary: Theoretically speaking, Auto-Encoder (AE) and Sequence-to-Sequence (Seq2Seq) models utilize bidirectional attention in Transformer, while Auto-Regressive (AR) language models rely on causal attention. Bi-attention models have been found to encounter low-rank problems~low_rank, which may limit their expressive ability to some extent. On the other hand, causal attention possesses greater theoretical expressive power. Therefore, for complex tasks like logical reasoning, or in the scene where the language model is expected to serve as a backbone for Artificial Generative Intelligence (AGI), AR models with a significant number of parameters (e.g., GPT-3~gpt3, GPT-4, etc.) are a preferable choice. However, AR models also come with potential limitations for tasks such as fill-in-the-blank, content comparison, and text summarization, which often require the model to look back, analyze multiple pieces of content, or engage in extensive re-reading~gpt3. Therefore, AE and Seq2Seq models are often better choices for these tasks. When it comes to controlled text generation using PLMs, most methods exploit the generative model, including AR and Seq2seq models, as the basis, and guide them to generate the desired text. Generally, CTG tasks always treat the PLMs as a conditional generation model, and its formulation is consistent with the standard language model: equation P(x_n|X_{1:n-1}) = p(x_n |x_1, x_2, \\dots, x_{n-1} ). equation Based on the pre-trained language model manifested above, the goal of conditional text generation can be formulated as: equation P(X|C) =\\displaystyle\\prod_{i = 1}^{n}p(x_i | x_{<i},C ), equation where $C$ denotes the controlled conditions, which will be integrated into the PLM in a specific form, and $X$ is the generated text that incorporates the knowledge encoded in the PLM and complies with the control conditions. In the next section, we will review the main approaches to CTG using Transformer-based PLMs.",
      "origin_cites_number": 28
    },
    {
      "section_title": "Main Approaches to PLM-based CTG",
      "level": "1",
      "content": "From a generative point of view, PLMs have learned a variety of knowledge from a large-scale corpus that can help produce more fluent and a richer variety of text. This provides an effective way for natural language generation. However, the existing PLMs are essentially still black-box models like other deep neural networks, lacking interpretability and controllability of the text generation process. How to make good use of PLMs in text generation while realizing the controllability of the generative model has recently become a hot research topic. In this section, we provide a comprehensive review of the main approaches in this area from the perspective of the Transformer-based PLMs are used for CTG. figure*[htbp] \\centering %使图片居中显示 \\includegraphics[width=0.8\\textwidth]{approaches.jpg} %中括号中的参数是设置图片充满文档的大小，你也可以使用小数来缩小图片的尺寸。 An overview of the PLM-based CTG approaches. According to the way how the control signal works with the pre-trained language model, we have roughly divided the existing methods into three categories, each of which is further divided into eight subclasses. %caption是用来给图片加上图题的 %这是添加标签，方便在文章中引用图片。 figure*%figure环境",
      "origin_cites_number": 0
    },
    {
      "section_title": "Overview",
      "level": "2",
      "content": "The core idea of PLM-based CTG is to give the model a control signal in an explicit or implicit way to drive the generation of text satisfying the control conditions. According to the way how the control signal works, we have roughly divided the existing methods into three categories, each of which is further divided into several subclasses. An overview is given in Figure~overview_ctg. The most direct way is to fine-tune the PLMs, which can perform the CTG task at a lower cost. The second way is to retrain or refactor the PLMs for CTG. In principle, this method could produce better results but may consume more computing resources and also face the problem of lacking labeled data. As the parameter size of PLMs increase rapidly, even fine-tuning has become resource-intensive. To tackle the problems, the third category of text generation methods, namely post-processing, that work on the decoder time, named post-processing, have emerged. In the post-processing methods, PLMs are always fixed, and the control signal works on the decoding-stage. Such methods not only require less computation resources for training, but also can guarantee a better quality of the generated text to some extent. As a consequence, increasing attention from the academic community has been paid to this direction in recent years. In the following sections, we will review the recent literature related to these three types of method in more detail.",
      "origin_cites_number": 0
    },
    {
      "section_title": "Fine-tuning",
      "level": "2",
      "content": "This type of method aims to fine-tune part or all of the parameters of a PLM to produce text that satisfies the specific controlled conditions. As discussed in Section 2.3, \"PLM + fine-tuning\" has become a new paradigm in the general field of NLP. First, a large amount of training data (usually unlabelled samples) and model parameters are used to learn general knowledge from the data and encode the learned knowledge into a PLM. Then a domain/task-adapted model will be obtained to achieve the competitive performance by fine-tuning the PLM based on a small amount of labeled data for the specific downstream task. This paradigm is also applicable to CTG, and a large number of related studies have been carried out. Recent work has found that fine-tuning PLMs on the target data, such as AMR-to-text~dart,plm_amr,t2t_plm for dialogue generation, can establish a new level of performance. While the conventional fine-tuning method is relatively concise and easy to understand, we focus on more advanced methods below. Adapted Module: This method first constructs a task-related adapted network module around a PLM, and then it is trained with the PLM on the target dataset just like usual fine-tuning. Auxiliary Tuning~auxiliary_tuning introduces an extra condition modeling module based on the original PLM, which takes $X(x_n; C)$, the concatenation of control condition $C$ and training text $x_n$, as input, and outputs logits in the vocabulary space. The auxiliary model is trained by adding its logits to the PLM's logits and maximizing the likelihood of the target task's output. In structAdapter, an adapter module is added after the feed-forward sub-layer of each layer on both the encoder and decoder of the PLM, which can encode the graph structure into the PLMs without contaminating its original distributional knowledge. During the training stage, the PLM's parameters are frozen, and only the injected adapter is trainable. Avoiding the catastrophic forgetting problem while maintaining the topological structure of the graph, the model achieves the SOTA performance on two AMR-to-text benchmarks. On the controlled dialogue generation task, the idea of an adapted module is also applied. In ~aaai2021_Adapter_Bot, an adapter-bot for dialogue generation is proposed. The model builds a series of lightweight adapters on top of a PLM for dialogue generation, namely, DialoGPT~zhang2019dialogpt. The model allows for a high-level control and continuous integration of various control conditions for different conversational requirements (e.g., emotions, personas, text styles, etc.). In summary, the adaptive modules essentially aim to bridge the gap between the controlled attributes and the PLMs, while guiding the language model to generate text that meets the corresponding control conditions. Prompt: A more effective way for the use PLMs is to keep the training objective of the fine-tuning phase consistent with the original task from which the PLMs are derived~gao-etal-2021-making. This idea gives rise to the so-called prompt-based approaches. Take a sentiment classification task for example. Suppose we need to recognize the sentiment of a sentence, e.g., \"I am always happy to see you\". Different from the traditional approaches that encode the sentence into a set of vectors and then classify their sentiment through a fully connected layer, the prompt-based method will construct a set of templates, for example: (\"I am always happy to see you, \\textbf{the sentiment of the sentence is [MASK]\"}), and then ask the model to predict the token [mask] according to the original training task for constructing the PLM. For sentiment-controlled text generation, the template could be regarded as the control prompts to instruct the PLM to generate desired texts. A specific illustration of prompt learning can be seen in Figure~fig:prompt_learning. The prompt-based approach has gone through various stages, from manual template construction~TACL2020, to automated search for discrete tokens~AutoPrompt, and to continuous virtual token representations~p_tuning,prefix_tuning. Keeping most parameters of the PLM fixed in most cases and retaining generative capacity of the original PLMs, these methods have achieved great success in zero/few-shot scenarios. From the CTG point of view, the prompt-based approach still applies. In~prefix_tuning, a method named “prefix tuning” is proposed, which freezes the PLM's parameters and back-propagates the error to optimize a small continuous task-specific vector called \"prefix\". The learned prefix, also called \"prompt\", can guide the PLM to generate the required text, thus enhancing the controllability to a certain extent. The approach achieves impressive results on some generative tasks such as data-to-text. An extension of the model, namely P-tuning~p_tuning, serves a similar purpose. Different from prefix-tuning~prefix_tuning, P-tuning does not place a prompt with the \"prefix\" in the input, but constructs a suitable template to prompt the PLM, and the template is composed of continuous virtual tokens obtained through gradient descent. Based on prefix-tuning, ~qian-etal-2022-controllable leverage contrastive learning to train attribute-specific vectors. Different from the vanilla prefix tuning, where each prefix is trained independently under the attribute-specific corpus, they take into consideration the relationship among attribute prefixes and train multiple prefixes simultaneously, thereby boosting the control performance. DisCup~DisCup-2022 provides a new prompt-based alternative for attribute-controllable generation, which uses the attribute-discriminator to assist prompt-tuning. This allows the learned control-prompt to absorb the information of inter-attribute knowledge, achieving the state-of-the-art attribute control performance. In view of the promising effect and the parameter-efficient structure features of the prompt-tuning in CTG, prompt-based multi-attribute control approaches have been proposed. For example, Tailor~tail_prompt explores two strategies, including a non-training method based on the concatenation of single-attribute prompts and a training method using an attribute-connector, for prompt-based multi-attribute CTG. In order to tackle the problem that the distance between the prompt and the next predicted token correlates negatively with the prompt’s influence power, inverse_prompt propose a method called Inverse Prompt. The main idea is to use generated text candidates from the PLM to inversely predict the prompt (topic, Poetry name, etc.) during beam search, so as to enhance the relevance between the prompt and the generated text and achieve a better controllability. However, the generation process requires the reverse prediction for each candidate token, leading to an increased computation cost. According to our actual tests based on the provided source code, it takes up to around 10 minutes to generate a seven-word rhyming poem, making it difficult to be applied in real application scenarios. More recently, in order to address the challenge of fine-grained CTG, an encoder-decoder architecture based on a pair of GPT-2 models is introduced~non_residual_prompt, namely non-residual prompting. It enables intermediate text prompts at arbitrary time steps of the generative PLM. Specifically, the proposed method uses an auxiliary prompt encoder, composed of a trainable GPT-2, to guide another generative language models towards certain constraints, including themes, sentiment, keywords, etc. The generative language model (i.e., GPT-2) is always fixed during generation, and the different prompt instructions can be used at different time steps, enabling fine-grained CTG. Non-residual prompt trends to be versatile and shows promise towards the unified controllable text generation. However, we hold a critical opinion on it, as it lacks a systematic comparison with the natural encoder-encoder architectures such as T5~t5 and Bart~mbart, and its training process is complex so that it is not parameter-efficient. To summarize, most of the prompt-based methods show a certain degree of versatility. From the CTG perspective, this kind of method essentially uses the characteristics of PLM in its pre-training stage to guide the PLM to generate constrained text by selecting an appropriate prompt in the fine-tuning stage, so as to achieve the purpose of controllability. Reinforcement Learning (RL) inspired Approaches: The core motivation of this type of method is to feed back whether or how the control conditions are achieved as a reward to the fine-tuning of the PLM. ~ft_human_preference use reinforcement learning to fine-tune the PLMs, with a reward model trained from human preferences. First, it initializes a policy $\\pi = \\rho$, where $\\rho$ denotes a PLM such as GPT2. Given a dataset $D\\in (X,Y)$, the goal is to fine-tune $\\pi$ so that it can approximate the distribution of the data $D$. This is done using RL by optimizing the expectation of the reward: equation E_{\\pi}[r]=E_{x \\sim D, y \\sim \\pi(\\cdot \\mid x)}[r(\\pi(x), y)]. equation Then the reward model $r$ is trained based on the sample $(x,y_0,y_1,y_2,y_3)$ via $x \\in D$, and $y_i$ is generated from $p(y_i|x)$. Human labelers are required to choose the human-preferred sentence from $(y_0,y_1,y_2,y_3)$. To prevent $\\pi$ from moving too far away from the original PLM $p$ for ensuring the fluency of the generated text to the greatest extent, a penalty item is added to the reward function during the actual process of fine-tuning $\\pi$: equation R(x, y)=r(x, y)-\\beta KL (\\pi,p), equation where $R(x, y)$ is the re-defined reward function, $\\beta$ is the regular coefficient, and $KL (\\pi,p)$ aims to ensure that the two distributions are as close as possible. data_boost propose a data augmentation approach, which uses reinforcement learning to guide the GPT-2 model to generate texts towards a specified conditional direction (i.e., the target class). Specifically, an additional RL stage is added between the softmax and argmax functions of GPT2, and then the parameter of the PLM's hidden states $\\theta$ is updated towards the target label according to the signal of the RL reward. The generated texts are regarded as augmentation data to help improve the classification performance. Moreover, lshf_nips2020 use an RL-based approach on the task of English summarization, which fine-tunes the PLM by combining with human feedbacks. The reinforcement learning is also applied for controllable story generation. tambwekar2018controllable designs a reward-shaping technique that produces intermediate rewards at all different time steps, which are then back-propagated into a language model in order to guide the generation of plot points towards a given goal. It should be noted that the above work is carried out on a language model based on LSTM, but its principles are applicable to the subject described in this article, so that we have included it here. In summary, the idea of applying reinforcement learning to PLM-based CTG is natural. The central challenge is to ensure that the PLM is optimized towards the RL's rewards while maintaining the fluency of the generated text. To address this challenge, the key is to achieve a better balance between these two aspects. Instruction Tuning: Recently, a new PLM-based CTG paradigm, namely instruction tuning, has become popular. Instruction tuning provides an avenue to align the language models with user intents, i.e., controlling language models to generate the content that complies with human instructions. Google Research proposes FLAN~flan, which stands for Finetuned Language Net. It involves fine-tuning a large language model on a mixture of more than 60 NLP datasets, where each task is expressed through natural language instructions. The results demonstrate that language models are capable of performing tasks described purely through human instructions and can generalize to previously unseen tasks through instruction tuning. Continuing the work of FLAN, ~chung2022scaling further explore scaling up the number of tasks and model size beyond what FLAN has achieved. They fine-tune the language models on the dataset mixed with chain-of-thought data, showcasing the strong few-shot performance of instruction tuning. InstructGPT~instructgpt, a most notable recent work, utilizes instruction tuning to control the language model and generate desired human-like content. It starts with collecting a dataset of labeled demonstrations of the desired model behavior, which are then used as instructions to fine-tune GPT-3. This allows for controlling the model to generate answers that align with human expectations. In term of the optimization algorithm, InstructGPT leverages reinforcement learning from human feedback~lshf_nips2020, ft_human_preference, as discussed in the previous section. The results demonstrate that fine-tuning with human feedback is a promising approach to aligning language models with human intents, leading to an improved performance in truthfulness and a reduction of toxic output. In summary, instruction tuning enables PLMs to understand human intents in a natural language format, offering a promising approach for more general and effective CTG. However, instruction tuning requires careful design of human-labeled prompts. How to fully and safely align the human instructions with PLMs remains an open problem~instructgpt, which demands a further exploration.",
      "origin_cites_number": 28
    },
    {
      "section_title": "Retraining/Refactoring",
      "level": "2",
      "content": "According to the characteristics of a specific downstream task, it is also feasible to change the original architecture of PLMs or retrain a large conditional language model from scratch. This kind of approach is promising to substantially improve the quality and controllability of text generation, but is limited by increased computing resource consumption and the lack of sufficient labeled data. CTRL~CTRL is an early attempt in this direction. It trains a language model conditioned on a variety of control codes. The network model used in this approach is also the commonly used Transformer, and a piece of control code (domain, style, topics, dates, entities, relationships between entities, etc.) is added in front of the text corpus. That is, it transforms the original language model $p\\left(x_{i} \\mid x_{<i}\\right)$ into $p\\left(x_{i} \\mid x_{<i}, c\\right)$. A language model with 1.63 billion parameters is retrained on a 140Gb corpus. Another contribution of this work is to propose a new top-k sampling algorithm: equation p_{i}=\\exp \\left(x_{i /(T \\cdot I(i \\in g))\\right.}{\\sum_{j} \\exp \\left(x_{j} /(T \\cdot I(j \\in g))\\right.} \\quad I(c)=\\theta \\text { if } c \\text { is True else 1}, equation where $g$ is a list of generated tokens, $p_i$ is the probability distribution for the next token, and the introduction of $I(c)$ reduces the probability of words that have already appeared. point_insertion propose POINTER, an insertion-based method for hard-constrained (i.e., making the specific words appear in generated text) text generation. Different from the auto-regressive method, such as GPT-2, this method modifies the structure of the Transformer so that it can generate text in a progressive manner. Specifically, given certain lexical constraints, POINTER first generates the constrained words to satisfy the control conditions, then more detailed words are inserted at a finer granularity between those words. The above process iterates until the entire sentence is completed. This kind of method can ensure the generated sentences meet the lexical constraints. However, the model needs to be trained from scratch on the large-scale corpus, and the fluency of the generated sentences is not as good as the auto-regressive model in most cases. Similar to the afore-mentioned insertion-based method~point_insertion, a lexically constrained text generation framework called Constrained BART (CBART) is proposed~CBART. This approach also adopts the progressive insertion/replacement for text generation, yet without modifying the Transformer's architecture. Concretely, based on the pre-trained model BART, it divides the generation process into two steps. First, a token-level classifier is added on BART's encoder to predict where to replace and insert. Then, the predicted results are regarded as signals to guide the decoder to refine multiple tokens of the input in one step by inserting or replacing tokens before specific positions. Different from the normal way of generating texts step by step, the decoder predicts all tokens in parallel so as to accelerate the inference. Although CBART does not need to reconstruct the architecture of PLMs, the training and inference processes are different from the original pre-training tasks, which can lead to a negative impact on the quality of text generation. CoCon (Content-Conditioner)~CoCon introduces a conditional control module in addition to the original PLM, which can realize the precise control of the generated text at the word- and phrase-levels. In terms of model architecture, the approach injects a control block into the GPT model and provides the control code as a separate input. In order to tackle the problem of lacking labeled data, it adopts self-supervised learning and constructs four different loss functions, including Self Reconstruction Loss, Null Content Loss, Cycle Reconstruction Loss, and Adversarial Loss. The core of these self-supervised losses is to use one part of a piece of text as a control condition, leaving the rest for the model to refactor, so that the model can learn to generate specific text conditioned on the control code. The experimental results show that CoCon can incorporate the condition content into the generated texts and control the high-level text attributes in a more flexible way. Similar to CoCon's idea of injecting an additional controlled module to an existing PLM, metion_flag propose a Mention Flags (MF) module, which is injected into the decoder of Transformer, to achieve a higher level of constraint satisfaction. The MF is designed to trace whether a lexical constraint has been realized in the decoder's output. It is formally represented as mentioned status embedding injected into the decoder of Transformer, to provide a signal to encourage the generative model to satisfy all constraints before generation. This type of approach is also used for the task of controlled dialogue generation. aaai2020_presonalized_dialogue_generation propose a PLM-based method to build a personalized dialogue agent. The whole framework is in an encoder-encoder (Transformer) fashion, and its initial parameters inherit from an existing PLM model. The personalized information is represented as attribute embedding, which is added into the encoder to capture rich persona-related features when modeling dialogue histories. Further, an attention routing network is added to the decoder to incorporate the target persona in the decoding process while maintaining the trade-off of the historical dialogue information dynamically. To solve the problem of lacking labeled data in conditional dialogue generation, a multi-task learning framework is proposed~nanal2021_multi-task, which utilizes both conditional labeled dialogue data and non-dialogue text data. Based on a condition-aware Transformer block (reconstructed from the original Transformer), three sub-tasks are designed based on the existing PLM, namely, conditional text generation based on labeled dialogue data, conditional conversation encoder, and conditional dialogue generation task based on non-dialogue text to optimize the model simultaneously. Persona and topic-controlled experiments are conducted under the scenario of dialogue generation, and the results show that this approach achieved a then-state-of-the-art performance. In summary, the refactoring or retraining approaches are more convenient to use, but may lose the original PLM's versatility to some extent. As for the methods that need retraining, they may face the dual challenges of increased computation cost and the lack of large-scale labeled data.",
      "origin_cites_number": 8
    },
    {
      "section_title": "Post-Processing",
      "level": "2",
      "content": "When the number of parameters of a PLM increases, the model has memorized more and more knowledge and patterns, allowing it to achieve competitive results even without fine-tuning in many NLP tasks~gpt3. In the realm of controlled text generation, the idea of fixing the PLM's parameters first and re-ranking the generated text in a post-processing manner becomes achievable and promising. Figure~fig:post_process, illustrates the use of a post-process module for sentiment-control text generation. %figure环境 The most realistic idea about the post-processing method is to use some standard decoding algorithms in text generation, e.g., the Greedy search, constraint beam search~beam_search, Top-k sampling~top_k, Nucleus sample~Nucleus, etc. The approaches discussed below can be seen as an extension of them for CTG tasks. They are grouped into two categories: guided strategies and trainable strategies. Guided Strategies: This type of method decouples the PLMs for text generation and the post-processing module, and the post-processing module guides the PLM to generate conditioned text only in the inference stage. A representative method of this type is PPLM~pplm. It first trains an attribute discriminant model and then uses it to guide the PLM to generate the corresponding text. In this work, the attribute model is a simple classifier, consisting of a user-specified bag of words or a single learning layer whose parameters are 100,000 times less than the PLM. During the text sampling process, it requires a forward and backward process in which the gradient from the attribute model drives the hidden activation of the PLM to guide the target text generation. PPLM does not need to change the structure or retrain the PLM, and it is able to achieve a significant improvement in attribute alignment. However, it causes a slight decrease in text fluency measured with the metric of PPL (Perplexity~liu-etal-2021-dexperts, GeDi). MEGATRON-CNTR~MEGATRON-CNTRL is a controllable story generation framework that combines external knowledge and PLM. Given a story context, a predictor is used to get a set of keywords for the next sentence. Then, a knowledge retriever is introduced to get external knowledge-enhanced sentences from an external knowledge base according to the keywords. Next, a ranker is trained to choose the most relevant knowledge-enhanced sentences, which are later fed into the generator of PLM (GPT-2) with the story context to get the next sentence. The entire process is repeated until completing a story. Human evaluation results show that up to 91.5\\% of the generated stories are successfully controlled by the keywords. In this framework, GPT-2 is independent of the other modules, and generates context-relevant sentences using the introductory text provided by MEGATRON-CNTR's component as input, without any adaptation in training. ~pair_emnlp2020 propose a content-controlled text generation framework, namely FAIR. It uses the BERT~bert model to automatically construct a content plan, including keyword assignments and their corresponding sentence-level positions. After that, the BART~mbart model is applied, without structure modification, to fill the masked tokens appearing in the generated text template. Finally, an iterative refinement algorithm that works within the sequence-to-sequence (seq2seq) models is designed to improve generation quality with flexible editing. The reported experimental results show that FAIR can significantly improve the relevance and coherence between the key phrases and the generated texts. Additionally, a series of discriminator-guided approaches have been developed, which train an attribute discriminator to help PLM select text for the specific attributes at the decoding stage. Adversarial Search~DAS, inspired by GAN (Generative Adversarial Network), trains the discriminator to distinguish human-created text from the machine-generated text. The discriminator predicts a label for each token instead of for the entire sequence. Its logit probability is added to the score to guide sampling towards the human-written style. For the tokenizer with 10 thousand words, decoding using a discriminator to classify each token is time-consuming. Aimed at solving this problem, GeDi~GeDi trains a small class-conditional language model (CC-LM) as generative discriminators to guide the generation from large PLMs (GPT-2 and GPT-3). Specifically, a CC-LM is trained and formulated as the following equation: equation P_{\\theta}\\left(x_{1: T} \\mid c\\right)=\\prod_{t=1}^{T} P_{\\theta}\\left(x_{t} \\mid x_{<t}, c\\right), equation where $c$ is the control code, $T$ is the length of generated text. GeDi assumes that there is a CC-LM with the desired control code $c$ and an undesired or anti-control code $c$, and then uses the contrast between $ P_{\\theta}\\left(x_{1: T} \\mid c\\right)$ and $P_{\\theta}\\left(x_{1: T} \\mid c\\right)$ to guide sampling from the original PLM. A contrast mechanism is designed to compute the probability that every candidate token $x_t$ belongs to the desired class, given by $P_{\\theta}(C\\mid x_t, x <t)$: equation P_{\\theta}\\left(c \\mid x_{1: t}\\right)=P(c) \\prod_{j=1^{t} P_{\\theta}\\left(x_{j} \\mid x_{<j}, c\\right)}{\\sum_{c^{\\prime} \\in\\{c, c\\}} \\prod_{j=1}^{t} P\\left(c^{\\prime}\\right) P_{\\theta}\\left(x_{j} \\mid x_{<j}, c^{\\prime}\\right)}, equation where $P(c)$ and $P(c^{\\prime})$ are biased parameters which could be learnt or set manually as a hyper-parameter. During the generation step for a token $x_t$, Equation~conditional_contrast is multiplied with the conditional probability $ P_{L M}\\left(x_{t} \\mid x_{<t}\\right)$ of the original PLM via the Bayes rule: equation P_{w}\\left(x_{t} \\mid x_{<t}, c\\right) \\propto P_{L M}\\left(x_{t} \\mid x_{<t}\\right) P_{\\theta}\\left(c \\mid x_{t}, x_{<t}\\right), equation where $P_{w}\\left(x_{t} \\mid x_{<t}, c\\right)$ is regarded as the final probability for text generation. Since the calculation of the Equation~conditional_contrast only needs two parallel forward passes of CC-LM, the generation efficiency is greatly improved. Inspired by the GEDI~GeDi, a series of similar approaches have emerged. DEXPERTS~liu-etal-2021-dexperts re-ranks the predictions of the PLM based on expert (and anti-expert) opinions during the decoding stage to steer the language model towards generation of the desired text. FUDGE~FUDGE learns an attribute predictor that operates on a partial sequence to adjust the original PLM's probabilities, and achieves an improved performance on the tasks of couplet completion in poetry, topic control in language generation, and formality change in machine translation. Plug-and-Blend~lin2021plug extends the GEDI model to controlled story generation by introducing a planner module. More recently, word_simility_emnlp2021_findings propose a simple yet efficient plug-and-play decoding method, namely K2T, which even does not need a discriminator. Specifically, given a topic or keyword which is considered a hard constraint, K2T adds a shift to the probability distribution over the vocabulary towards the words which are semantically similar to the target constraint word. The shift is calculated based on word embedding. Although the K2T is intuitive, the shift added to the probability distribution of vocabulary may be too rough and cause the generated texts to fall short in fluency. mireshghallah-etal-2022-mix propose a score-based controllable text generation framework, namely Mix and Match, which regards the task of generating attribute-specific text as a Metropolis-Hastings sampling process. Specifically, the proposal samples are first produced by the MLM model(i.e., BERT). Then, an energy-based model, which is a linear combination of scores conditioning context from the different black-box experts that represent fluency, the control attribute and faithfulness, respectively, is used to accept/reject the proposal sample. Those two steps are iterated until the desired texts are obtained. The framework is training-free, without any fine-tuning or structural assumptions. Nevertheless, Mix and Match is an iteration-based method. It takes almost 11 seconds to generate a sequence of length 20, which reduces the practical value. Similarly, COLD Decoding~COLD_Decoding, an energy-based and iterative CTG approach, formulates the controlled text generation task as sampling from an energy-based model using Langevin Dynamics, without the need for any task-specific fine-tuning. Like the Mix and Match method mentioned earlier, COLD Decoding also suffers from the efficiency issue in text generation. To sum up, the idea of \"guided strategies\" is simple and flexible. The main advantage of this approach lies in the separation of the post-processing module from the model. When the number of parameters of the PLM increases, such advantage becomes more apparent. However, post-process requires multiple iterations to achieve better control performance, resulting in excessive time costs. Trainable Strategies: The Trainable Strategies also work in the inference phase, but different from the Guided Strategies, the extra processing module needs to be trained jointly with PLM whose parameters are fixed. Compared to the prompt-based approaches, the module controls PLM's generation process noninvasively, without disturbing the model's original textual stream. An Energy Based Model (EBM)~ebm_ctg is proposed to guide the PLM to generate desired text. The generative model is formalized as follows: equation P_{\\theta}(x) \\propto P_{L M}(x) \\exp \\left(-E_{\\theta}(x)\\right), equation where $P_{L M}(x)$ is a local normalized language model whose parameters are frozen during training, and $E_{\\theta}(x)$ is an energy function that is aimed at steering the joint model $P_{\\theta}(x)$ towards the desired data distribution. The Noise Contrastive Estimation (NCE) algorithm is used to train the model to cope with the intractability issue of the energy model. Experiments show that the proposed method yields a lower perplexity compared with locally normalized baselines on the task of generating human-like text. The use of large-scale PLM makes this method possible, because the quality of the generated text from the joint model relies heavily on the quality of the underlying language model. Furthermore, since RL-based methods may lead to the problem of \"degeneration\" in the sense of producing poor examples that improve the average reward but forgo the coherence and fluency, a distributional approach for controlled text generation~gdc was proposed to solve the problem. It uses the Energy-based Model (EBM) to represent the point-wise and distributional constraints in one go: equation p(x) \\doteq P(x){Z}, equation equation Z \\doteq \\sum_{x} P(x), equation equation P(x) = a(x) e^{\\sum_{i} \\lambda_{i} \\phi_{i}(x)}, equation where $p(x)$ is the desired normalized distribution, $Z$ is the normalized term, $\\phi_{i}(x)$ represents the constraint judgment function (point-wise it means 0 or 1, distributional-wise it may be a continuous value between 0 and 1), and $\\lambda_{i}$ is the corresponding coefficient estimated by using Self Normalized Importance Sampling (SNIS), $a(x)$ is the original PLM. As it is hard to calculate $p(x)$ directly, a method similar to variational inference is adopted to approximate the distribution, by first initializing a policy $\\pi = a(x)$, and then minimizing the cross entropy between the policy $\\pi$ and the desired normalized distribution $p(x)$: equation C E\\left(p, \\pi_{\\theta}\\right)=-\\sum_{x} p(x) \\log \\pi_(x). equation The optimization process adopts the KL-Adaptive distributional policy gradient (DPG) algorithm to make $\\pi$ approximate the model $p(x)$ that satisfies the constraints. The method unifies the point-wise and distributional-wise constraints in a single framework, and the experimental results show its superiority in satisfying the constraints while avoiding degeneration. However, this approach suffers from the high computational cost, which needs to be addressed in the future. Generally speaking, Trainable Strategies require the post-process module to be jointly trained on the basis of PLM, and realize controllable text generation by adjusting the original probability distribution of PLM to the desired data distribution using the trained post-process module. This type of method build upon the probability modeling theory and thus has a good theoretical basis, yet they are still at the early stage and need to improve the issues related to computational efficiency and text quality. table*[] \\renewcommand1.5 A summary of the surveyed CTG methods, which are divided into three main categories and eight sub-categories. We list the main characteristics for each categories from a macro perspective, and representative references for each sub-category. \\linewidth{!}{ tabular{|c|l|c|l|} \\hline Method & 1{c|}{Main characteristics} & 1{c|}{Subcategory} & 1{c|}{Typical References} \\\\ \\hline 4{*}{Fine-tuning} & 3{*}{ tabular[c]{@{}l@{}} standard training;\\\\ efficient inference;\\\\ higher text quality; \\\\ weaker controllability tabular} & Adapted Module & auxiliary_tuning,structAdapter,aaai2021_Adapter_Bot \\\\ 3-4 & & Prompt & tabular[c]{@{}l@{}}TACL2020,AutoPrompt,p_tuning, qian-etal-2022-controllable \\\\ prefix_tuning, DisCup-2022,non_residual_prompt,tail_prompt tabular \\\\ 3-4 & & Reinforce Learning & tabular[c]{@{}l@{}} ft_human_preference, lshf_nips2020,data_boost,tambwekar2018controllable,instructgpt tabular \\\\ 3-4 & & Instruction Tuning & tabular[c]{@{}l@{}} instructgpt tabular \\\\ \\hline 2{*}{Refact/Retrain} & 2{*}{tabular[c]{@{}l@{}} computationally expensive training;\\\\ higher text quality; better controllability tabular} & Retrain & CTRL,point_insertion \\\\ 3-4 & & Refact & tabular[c]{@{}l@{}} point_insertion,CoCon,metion_flag,CBART,aaai2020_presonalized_dialogue_generation,nanal2021_multi-task tabular \\\\ \\hline 2{*}{Post-Process} & 2{*}{tabular[c]{@{}l@{}} efficient training and inefficient inference;\\\\ lower text quality; better controllability tabular} & Guided Strategy & tabular[c]{@{}l@{}} pplm,MEGATRON-CNTRL,DAS,GeDi,liu-etal-2021-dexperts,FUDGE \\\\ lin2021plug, word_simility_emnlp2021_findings, mireshghallah-etal-2022-mix, COLD_Decoding tabular \\\\ 3-4 & & Trainbale Strategy & ebm_ctg,gdc \\\\ \\hline tabular } table*",
      "origin_cites_number": 32
    },
    {
      "section_title": "Summary",
      "level": "2",
      "content": "In this section, we divide the current PLM-based CTG approaches into three categories according to the way how PLMs are used. For each category, we analyze its main principles, process, and methods. A summary of the surveyed CTG models is shown in Table~Approach summary . \"Fine-tuning\" is a more general type of method that has been widely used in both NLU and NLG tasks. How to make full use of the power of PLMs in specific tasks is still a hot research topic for future research. The retraining or refactoring approaches typically involve high training costs and the lack of large-scale labeled data. To overcome these limitations, combining the general pre-trained models with semi-supervised or self-supervised learning to build a pre-trained model dedicated to CTG, would be a feasible direction for future research. The emergence of post-processing methods is rooted on the powerful text-generation capabilities of PLMs. This kind of method generally assumes that the PLMs can produce high-quality text, and then use a post-processing module as a filter to screen the desired type of text. Since the post-process modular is usually decoupled from the PLMs, most current decoding-time approaches (post-process) are still computationally expensive (i.e., with longer inference time or additional parameters), and the quality of generated text can be low. However, it has some promising advantages, because the parameters of the PLMs do not need to be retrained, thus greatly saving computing resources for the model training stage. In recent years, the scale of pre-trained models has been getting larger, and their mastery of language knowledge is getting more comprehensive. At the same time, the sheer size of parameters makes the PLMs resource-intensive to fine-tune and retrain. The above-mentioned trends coincide perfectly with the advantages of the \"post-process\" methods. Thus it has a great potential for future research and development.",
      "origin_cites_number": 0
    },
    {
      "section_title": "Evaluation Methods",
      "level": "1",
      "content": "The performance of a NLG model is reflected by suitable evaluation metrics. CTG is slightly different from the general NLG tasks due to the need to fulfilling the controlled elements. Therefore, CTG is concerned about not only the quality of the generated text but also the satisfaction with the controlled elements. As a consequence, we usually use both general and CTG-specific metrics to evaluate a CTG model.",
      "origin_cites_number": 0
    },
    {
      "section_title": "General NLG Evaluation Metrics",
      "level": "2",
      "content": "For any CTG model, it is essential to evaluate the quality of generated text in general aspects such as: 1) fluency: how fluent the language in the output text is celikyilmaz2018deep, du2017learning, 2) factuality: to what extent the generated text reflects the facts described in the context Nucleus, welleck2019neural, 3) grammar: how grammatically correct the generated text is, 4) diversity: whether the generated text is of a diverse range of types or styles. The ways of measuring these general evaluation aspects can be divided into three categories based on who perform the assessment: human beings or the machine (as shown in Figure~fig1). figure*[h] \\centering \\includegraphics[width=0.8\\textwidth]{evaluation.pdf} A categorization of general NLG evaluation methods. figure*",
      "origin_cites_number": 2
    },
    {
      "section_title": "Human-Centric Evaluation Metrics",
      "level": "3",
      "content": "Human beings create Natural Language as a crucial form of human communication. So humans are the best evaluators of the natural language texts generated by NLG systems. We call the evaluation metrics that involve human assessors only as human-centric evaluation metrics, and they can be roughly divided into two types: Direct evaluation In this type, human assessors judge the quality of the generated texts directly. A simple way is to make a binary decision, i.e., good or bad, and a more complex way is to use finer-grained decisions: e.g., Likert scale as shown in Figure fig4a, and RankME in Figure fig4b, etc. ~novikova2018rankme, celikyilmaz2018deep, Nucleus. Indirect evaluation Different from the direct evaluation, indirect evaluation is done by measuring the effect of the generated text on downstream tasks, from either a user's perspective (such as whether or not it leads to an improved decision-making or text comprehension accuracy ~gkatzia2015snapshot, typically through a User Task Success evaluation), or from a system's perspective ~aziz2012pet,denkowski2014learning, such as the performance of a dialogue system through the System Purpose Success evaluation.",
      "origin_cites_number": 5
    },
    {
      "section_title": "Automatic Evaluation Metrics",
      "level": "3",
      "content": "Automatic evaluation metrics for NLG usually compare the similarity of the NLG model generated texts $G$ to the corresponding reference texts $R$ (i.e., human-written texts) in the benchmarking datasets. We divide the similarity measures into three categories: lexical-based, syntactic-based, and semantic-based. Lexical-based Metrics The lexical-based metrics measure the similarities between basic lexical units (e.g., words or phrases) across the pair of sentences, which are then aggregated into an overall sentence-level similarity. BLEU~papineni2002bleu is a commonly used metric in natural language processing tasks to evaluate the similarity between the generated text from an NLG model and the corresponding reference text. Specifically, BLEU counts the n-gram matches in the generated text against the reference text. For convenience, we use BLEU-n to represent BLEU with respect to n-grams, as follows. equation BLEU-n=\\sum_{t \\in G\\sum_{n-gram\\in t}Count_{match}(n-gram)}{\\sum_{t \\in G}\\sum_{n-gram \\in t}Count(n-gram)}, equation where $t$ is a piece of generated text to be compared, and match means that an n-gram in $t$ also appears in the reference text. The larger BLEU-n, the better quality of the generated text. Self-BLEU zhu2018texygen is proposed as a metric to measure the diversity of the generated text. Since BLEU can measure the similarity of two different texts, self-BLEU calculates the BLEU score between each pair of generated texts, and takes the averaged BLEU score to represent the diversity of all generated texts. The generated texts with a higher diversity has a lower self-BLEU score. ROUGE~lin2004rouge is the abbreviation of Recall-Oriented Understanding for Gisting Evaluation. It compares the generated text with a group of reference texts, counts the number of overlapping basic units (n-grams), and obtains the corresponding score to measure the similarity between the automatically generated texts and the reference texts. The formula of $ROUGE$ is as follows: equation ROUGE-n=\\sum_{t \\in G\\sum_{n-gram\\in t}Count_{match}(n-gram)}{\\sum_{t \\in R}\\sum_{n-gram \\in t}Count(n-gram)}, equation Comparing the Equations equ15 and equ16, the only difference between BLEU-n and ROUGE-n lies in the denominator. BLEU-n is focused on precision and the denominator is the total number of n-grams in the generated texts. ROUGE-n is recall-oriented, so the denominator is the total number of n-grams in the reference texts. A larger ROUGE-n indicates a better recall-oriented quality. Perplexity (PPL) is a metric to measure how well a probabilistic language model predicts a sample. Essentially, a probabilistic language model is a probability distribution over a given text, i.e., probability of the $(n+1)-th$ word given the first $n$ words of the text. For the task of NLG, a language model is trained on the reference texts, and is used to predict the generated text. The higher prediction probability indicates the better quality of the generated text. In practice, PPL takes the reciprocal form as follows: equation PPL=\\sqrt[n]{\\prod_{i=1}^{n}1{p(w_{i}\\mid w_{1}w_{2}...w_{i-1})}}, equation where $n$ is the number of words in the generated text, $w_{i}$ is the $i-th$ word in it, and $p(w_{i})$ is the probability of $w_{i}$ in the language model trained with reference texts. Generally speaking, The smaller the PPL value, the better fluency of the generated text. However, the lower PPL also implies more repetitions. Hence, another criterion is that the closer the PPL value of the generated text is to the human-written text, the better the fluency~Nucleus. In addition, a variant of PPL called Reverse PPL~shi2020dispersedhas also been used to measure the diversity of the generated text, by training a language probability model on the generated texts and calculating the PPL score on the reference texts. A smaller Reverse PPL means that the generated texts are quite different from the reference texts, indicating a higher diversity. Distinct-n~li2016diversity is an n-gram based metric and applies to some scenes (such as dialogue and advertisement generation), where the diversity of generated texts is pursued. The greater the Distinct-n value, the higher the diversity. It is formulated as follows: equation Distinct-n=Count(unique\\ n-gram){Count(n-gram)}, equation where the numerator is the number of unique n-grams that appear in the generated texts and the denominator is the total number of n-grams in the generated texts. Syntactic-based Metrics The syntax is related to the grammatical arrangement of words in a sentence. A common syntactic-based metric is TESLA~liu2010tesla, which is the abbreviation for Translation Evaluation of Sentences with Linear-programming-based Analysis. In general, there are three variants of TESLA~dahlmeier2011tesla: TESLA-M (minimal), TESLA-B (basic), and TESLA-F (full). TESLA-M uses N-gram matching and basic linguistic analysis like lemmatization, part-of-speech tagging, and WordNet synonym relations. TESLA-B, a new configuration, adds bilingual phrase tables to model phrase synonyms. The most advanced version, TESLA-F (also called TESLA), goes further by incorporating language models and a ranking support vector machine instead of simple averaging. Semantic-based Metrics Semantic-based metrics aim to handle the evaluation of texts that are lexically different but have a similar semantic meaning. Compared with the lexical-based and syntactic similarity, the semantic similarity requires consideration of more information and is more difficult to measure. In recent years, PLM-based semantic evaluation methods have emerged, which aim to evaluate the generated text using the trained PLMs inversely. An typical example is BERTscores~BERTScore, which replaces the n-gram overlaps defined in BLEU, with the embeddings from BERT, to learn a semantic-awareness metric. Similarly, Bertr and YiSi~mathur-etal-2019-putting take advantage of BERT embeddings to capture the semantic similarity between the generated text and its reference. There are also approaches that try to fine-tune PLMs for text quality estimation~reimers2019sentence,zhou2020learning,liu2021naturalness. Particularly, sellam2020bleurt propose a task-specific pre-trained model, namely BLEURT, for text assessment. BLEURT first adds random perturbations to Wikipedia sentences to construct millions of synthetic examples. Then, a BERT-based pre-trained model is trained on several lexical- and semantic-level supervision signals with a multitask loss. The experiments show that BLEURT benefits from pre-training and is robust to both domain and quality drifts. MAUVE~MAUVE_human_machine is an automatic metric to compare human-written and machine-generated texts. Specifically, MAUVE compares the machine-generated text distribution to that of human-written text, which are embedded by a PLM, using divergence frontiers, to reveal two different errors of the NLG model: (1) the model assigns high probability to sequences that do not resemble human-written text, and (2) the generative model fails to yield diverse samples as human-written texts.",
      "origin_cites_number": 13
    },
    {
      "section_title": "Semi-automatic Evaluation Metrics",
      "level": "3",
      "content": "When faced with more diverse tasks such as story generation and open-domain dialogue generation, the automatic evaluation methods turn out less ideal, because they can mainly evaluate the surface-level similarity between the reference and target sentences. Recognizing that humans can better distinguish a more diverse range of features, such as fluency and grammar, semi-automatic evaluation that combines automatic and human-centric evaluation methods has been developed, to get more reliable evaluation results. lowe2017towards encode the context, the generated text, and a reference text into vectors (c, $g$, and r, respectively) using a hierarchical RNN encoder. Then the dot-product operation is adopted to transfer the vectors into a score ($score(c,r,g)=(c^{T}Mg+r^{T}Ng-\\alpha)/\\beta$). Finally this score is made as close as possible to the human judged score. A model that uses human judgments as labels can ensure good consistency with human judgments, but sometimes it may be too conservative and lacks diversity due to the quality of human evaluators. Without using a human-judged score as the label, we can simply calculate the perplexity of a probabilistic model first, and then let humans evaluate the beam-searched outputs. Specifically, hashimoto2019unifying encode the human judgments and model outputs into the same space by using the same encoder. Then a discriminator is trained to distinguish whether the text is generated by a model or by a human evaluator. Finally, the leave-one-out error of the discriminator is computed. By doing so, we can preserve the diversity and quality of the generated text at the same time.",
      "origin_cites_number": 2
    },
    {
      "section_title": "CTG-specific Evaluation",
      "level": "2",
      "content": "In addition to the above three categories of general NLG evaluation metrics, the CTG task demands additional evaluation metrics that take into account the controlled elements, i.e., whether a CTG model has fulfilled the specific controlled conditions. According to the definition of the controlled elements in Section~Controllable_Text_Generation, we can divide CTG-specific evaluation methods into two kinds of automatic evaluation methods. Additionally, human evaluation metrics for CTG are also discussed. Semantic consistency metrics. This kind of evaluation methods generally correspond to the semantic control conditions. We first need to construct a training set with positive (samples satisfying the control conditions) and negative (samples not satisfying the control conditions) samples. Then a classifier is trained to identify whether the model generates the controlled text that is semantically consistent with the controlled attributes e.g., sentiment, topic~pplm, qian-etal-2022-controllable, style~gao2019structuring,chen2019unsupervised and toxic~~GeDi,liu-etal-2021-dexperts, DisCup-2022. Accuracy is always used to measure the semantic consistency performance of the CTG model. It is calculated as the number of test samples correctly according with the controlled elements, divided by the number of test samples. Recently, CTRLEVAL~ke-etal-2022-ctrleval, a PLM-based and reference-free method, is proposed for a training-free evaluation of CTG models. Specifically, CTRLEVAL formulates three aspects, including coherence, consistency and attribute relevance, to evaluate the generated text. Each aspect is defined as multiple text-infilling tasks with the base PLM, from which the ensemble of generation probabilities forms the final evaluation results. This approach does not need any labeled data and achieves higher correlations with human judgments. Rule-based metrics. When it comes to the structurally and lexically controlled text generation tasks, we can use certain rules to judge how well the generated text conforms to the pre-defined controlled elements and then count the number of test samples that satisfy the control conditions as the final evaluation results. For example, Coverage can be used to measure the effectiveness on the lexical-constrained text generation tasks~metion_flag,point_insertion,CBART,non_residual_prompt, e.g., by calculating the average percentage of input keywords that are present in the generated text. Success Rate is used to measure the degree of matching between the generated text and the given structural control elements (i.e., Parts-of-Speech, Syntax Spans, and Syntax Tree). For this purpose, an external tool for sentence structure extraction, such as oracle POS tagger and off-the-shelf syntax parser, is applied to the generated texts~Li-2022-DiffusionLM. Moreover, some general text evaluation metrics can also be used for CTG-specific evaluation. For instance, the lexical-level overlap between the reference text containing the control elements and the generated text can be used to reflect how well the control conditions are met in the task of table/graph to text~puduppully2019data,acl2020_graph2text,plm_amr,acl2020_data2text,structAdapter,findins_acl2021_PlanthenGenerate and story generation~goldfarb2020content,fang2021outline. Thereby the general metrics such as BLEU-n and ROUGE-n could also be regarded as the CTG-specific evaluation metrics to indicate the constraint satisfaction. Human evaluation metric. Most of the afore-mentioned CTG-specific metrics for the evaluation of text semantics and structures require the introduction of an additional semantic-relevant classifier or structure-relevant parsing tools, which may not be as reliable as the well-educated human participants. Therefore, human evaluation is also essential to test how a CTG model satisfies the control elements. Similar to the Human-Centric method described in Section 4.1.1, human assessors are always directly asked to score the relevance of the generated texts to the control attributes (e.g., sentiment, topic, toxic, contextual relevancy, and common sense~CoCon, pplm,liu-etal-2021-dexperts, FUDGE, DisCup-2022, non_residual_prompt etc.), and the average score obtained is used as the final evaluation result.",
      "origin_cites_number": 9
    },
    {
      "section_title": "Summary",
      "level": "2",
      "content": "Human-centric evaluation is the most precise method for evaluating the quality of system-generated texts. It would be ideal when human resources permit, which unfortunately is not always the case. Thus this type of evaluation suffers from various weaknesses: 1) Expensive and time-consuming: the recruitment and selection of evaluators, the setup of the evaluation and other steps all require time and manpower, especially for the evaluation tasks that can only be handled by domain experts; 2) Maintaining quality control ipeirotis2010quality,mitra2015comparing: although the emergence of online crowd-sourcing platforms has eased the cost problem to a certain extent, the quality of personnel conducting online evaluations cannot always be guaranteed; 3) Lack of consistency van2020human: the reproducibility of the evaluation results can be low due to the change of evaluation personnel, which leads to the inconsistency problem. Compared with human-centric evaluation metrics, automatic evaluation metrics are easy to use, fast to obtain results, and with low-cost. However, the evaluation of this type is less precise than human assessments. It is vital to develop automated evaluation methods comparable to the human level evaluation in the future. Semi-automatic evaluation metric combines the advantages of human-centric methods and automatic methods, but still require a lot of human judgments or labeling, which are expensive and time-consuming. One key future research direction is to develop a better way to augment human judgments with automatic evaluation, or vice versa, to obtain improved evaluation quality and diversity. When it comes to the CTG tasks, we not only need to use the general NLG evaluation metrics but also need specific metrics to evaluate whether the generated texts are consistent with the controlled elements. Generally speaking, the consistency of controlled elements and generated texts are relatively easy to measure in most cases. The main challenges of text quality evaluation still lie in the general evaluation methods.",
      "origin_cites_number": 2
    },
    {
      "section_title": "Challenges and Future Directions",
      "level": "1",
      "content": "",
      "origin_cites_number": 0
    },
    {
      "section_title": "Challenges",
      "level": "2",
      "content": "The PLMs have mastered a remarkable level of linguistic knowledge (semantic, syntax, etc.) from large-scale corpus, naturally enabling the production of more fluent and diverse text. However, due to the black box characteristics of neural networks, the general PLMs are still not sufficiently controllable during the text generation process. How to fully exploit the powerful PLMs to generate the desired and controllable text, has become a promising yet challenging field in both academia and industry. Based on the systematic review of the key concepts, methods and findings in the latest development of PLM-based controllable text generation, we think this promising and fast-growing area is still facing a number of challenges in the following aspects. First, PLMs have learned rich knowledge from large-scale corpus used for pre-training. However, an NLG model needs to learn control constraints on its own training corpus. It is often difficult for the existing PLM-based models to ensure the domain diversity of the generated text while pursuing controllability. This is indeed the well-known catastrophic forgetting problem in PLM. In the field of text generation, it is still a challenge to overcome this problem and imporve the ability of the PLM-based NLG model to generate multi-domain text that satisfies specific control conditions, with few or zero domain-specific samples. Second, controlling the generation of text in the decoding stage of a generative model is a low-cost way in terms of model training. It can maintain the characteristics of the original language model to the greatest extent. However, in most cases, the existing methods are relatively rudimentary, and only use the external decoupled attribute discriminator to control the attributes. There is a distribution gap between the discriminator and the generator, leading to a coarser granularity in the guidance process and decreased quality of the generated text. In addition, the decoding-time approaches are hard to be directly applied to fine-grained control scenarios such as data-to-text or multi-attribute control tasks. Third, from the perspective of probability theory, a generative pre-trained language model (referring specifically to the GPT-like models) is essentially an enhanced version of dense conditional probability $p\\left(x_{n} \\mid x_{1}, x_{2}, \\ldots, x_{n-1}\\right)$ to describe the probability distribution of natural language. However, this local normalization format has certain limitations in paragraph/document-level modeling. For example, it is hard to keep long-range coherence in terms of both semantic logic and controlled condition. It calls for further research to establish a global normalization based on PLMs to ensure that text generation can be controlled locally and globally at the same time. Fourth, the construction of large-scale PLMs is typically data-driven, which allows the models to learn the primary logic and commonsense knowledge contained in the training corpus. However, the knowledge captured in those models is often rather superficial. The PLMs will lose generalization ability when the training data does not contain relevant commonsense and domain-specific knowledge. Therefore, purely relying on PLMs could be difficult to control the generated texts faithfully with respect to commonsense and rich knowledge specific to the target domain. Fifth, reasonable and reliable evaluation has always been a bottleneck restricting the development of more advanced text generation technologies. This is also the case for controllable text generation. Generally speaking, the satisfaction of controlled conditions is relatively easy to evaluate. However, there is still a lack of an objective, accurate and comprehensive evaluation mechanism that is fully compatible with human judgment. For controllable text generation, in addition to the control conditions, the quality of the text itself is equally important. If the quality of the generated text of an NLG model cannot be accurately evaluated, it is hard to think of a way to control them. Finally, we believe that the research on controlled text generation is still in its early stage. In Section 2.2 of this paper, we have summarized a range of tasks involving CTG. However, few of them are actually dedicated CTG tasks. With the rapid development of text generation, there is a need to come up with dedicated benchmarking tasks and datasets for CTG with diverse control requirements.",
      "origin_cites_number": 0
    },
    {
      "section_title": "Future Directions",
      "level": "2",
      "content": "Based on the summary of current work and the challenges mentioned above, we suggest the following promising future directions for PLM-based controllable text generation. Prompt-based Learning: Prompt-based learning has become a new way for fine-tuning PLMs. Based on the well-designed prompting function, a PLM is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data, thus overcoming the problem of catastrophic forgetting. The above features are also attractive for controlled text generation, since the prompt-based methods are able to generate more diverse text fields and increase the distribution space of the text to be filtered, so that it is theoretically more possible to produce text that meets the specific control conditions. Currently, the application of prompt-based methods and their variants (e.g., in-context learning~xie2022an, instruction tuning~instructgpt, etc.) in large-scale language models is a hot academic topic. There is also great potential in finding better ways to apply this paradigm to controllable text generation. Fine-grained Decoding Control: More fine-grained decoding control methods need to be explored. On the one hand, the decoding-time methods can be improved to achieve more effective control. For example, co-training between the guided model and the generative model ensures finer-grained text generation. On the other hand, the existing single-attribute (e.g., emotion, topic, etc.) controlled tasks can also be extended to multi-attribute controlled tasks in a unified framework, achieving the simultaneous control of multiple aspects for a generated sentence. Integration with Classic Generative Theory and Linguistic Knowledge: The PLM-based controllable text generation task can be regarded as obtaining a natural language distribution constructed by a PLM, the corresponding distribution that satisfies certain specified constraints. This process is intrinsically related to classic generative models such as Generative Adversarial Networks (GANs)~GANs, Variational Autoencoders (VAEs)~VAEs, Energy-based Model~ebm_ctg and their variants. It is known that auto-regressive PLMs, i.e., the GPT family models, can not model global information of the generated texts naturally, making it difficult to control the generated text's distribution at the paragraph/document level. We expect that combining classic probability theory to bridge the gap between PLMs and traditional generative models, will help solve the problem at the theoretical level. In addition, auto-regressive PLM is essentially a locally normalized fashion, allowing it to produce fluent text in short text-generation scenarios. From a linguistic point of view, it is believed that more linguistic knowledge, such as paragraph/document level structures and logic, are needed in long text generation, which PLMs can not provide directly. A promising solution is to combine linguistic knowledge with PLMs to overcome the inherent problems of auto-regressive models in long text modeling, so as to better ensure the quality and controllability. Incorporation of External Knowledge: Introducing additional knowledge to enhance PLM's generation is a promising direction. One direct idea is to combine with information retrieval and allow the PLM to refer to the retrieved information from the Web or domain data repositories, ensuring that the generated content is more reasonable and alleviating problem of hallucinations~Hallucination. Furthermore, a knowledge graph is a natural carrier of explicit domain-specific knowledge and also provides effective reasoning mechanisms. Therefore it can be a good complement to the use of PLMs, which lack domain-specific knowledge and logical reasoning capabilities. Novel Evaluation Metrics and Methods: Developing innovative evaluation metrics for CTG is still an important topic that needs to be further studied from both the general text generation perspective (such as fluency, diversity, and coherence) and the CTG-specific perspective (such as fidelity). Since the pre-trained language models have mastered a great deal of semantic and grammatical knowledge, applying them in reverse to assess the text quality of an NLG model would be an interesting and fascinating area for further investigation. New CTG tasks: Controllable text generation is a broad concept that has gained significant attention in recent years. With the rapid development of large-scale language models, such as ChatGPT and GPT-4, there is a growing interest in exploring new standards and tasks that align with the goal of achieving General Artificial Intelligence (AGI). Therefore, one promising direction is to define AGI-oriented benchmarks and tasks that aim to control the language model to produce accurate and reliable information or ensure that the generated content is aligned with human values and does not have the harmful effects.",
      "origin_cites_number": 6
    },
    {
      "section_title": "Conclusions",
      "level": "1",
      "content": "In this paper, we have comprehensively summarized the typical applications, main approaches, and evaluation methodologies of controllable text generation based on large-scale pre-trained language models. Based on the critical analysis of the existing methods, we have identified a series of key challenges in this field and highlighted several promising future directions. Large-scale pre-trained language models have brought unprecedented opportunities for the development of controllable text generation technologies, calling for more researchers to join the field and create a new era of it. We are hopeful that this literature survey is able to provide a clear picture of the field and set a roadmap for researchers and practitioners to move forward.",
      "origin_cites_number": 0
    },
    {
      "section_title": "Acknowledgments",
      "level": "1",
      "content": "This work is supported in part by Natural Science Foundation of Beijing (grant No. 4222036). We would like to thank the anonymous reviewers for their valuable comments. ACM-Reference-Format",
      "origin_cites_number": 0
    }
  ],
  "literature_review_id": 245986550,
  "meta_info": {
    "cite_counts": 174,
    "Conference_journal_name": "ACM Computing Surveys",
    "influentialcitationcount": 16,
    "Author_info": {
      "Publicationsh": 10,
      "h_index": 6,
      "Citations": 514,
      "Highly Influential Citations": 0
    },
    "all_cites_title": [
      "Exploring Transformer Text Generation for Medical Dataset Augmentation",
      "Guided Open Vocabulary Image Captioning with Constrained Beam Search",
      "PET: a Tool for Post-editing and Assessing Machine Translation",
      "RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of Conversational Language Models",
      "Longformer: The Long-Document Transformer",
      "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?",
      "A Neural Probabilistic Language Model",
      "Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models",
      "Language Models are Few-Shot Learners",
      "Fine-Grained Controllable Text Generation Using Non-Residual Prompting",
      "Neural data-to-text generation: A comparison between pipeline and end-to-end architectures",
      "Deep Communicating Agents for Abstractive Summarization",
      "Evaluation of Text Generation: A Survey",
      "CoCon: A Self-Supervised Approach for Controlled Text Generation",
      "My Way of Telling a Story\": Persona based Grounded Story Generation",
      "Changing the Mind of Transformers for Topically-Controllable Language Generation",
      "Unsupervised stylish image description generation via domain layer norm",
      "Sentiment-Controllable Chinese Poetry Generation",
      "Palm: Scaling language modeling with pathways",
      "Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models",
      "Cross-Lingual Language Model Pretraining",
      "TESLA at WMT 2011: Translation Evaluation and Tunable Metric",
      "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context",
      "Plug and Play Language Models: A Simple Approach to Controlled Text Generation",
      "Residual Energy-Based Models for Text Generation",
      "Learning from Post-Editing: Online Model Adaptation for Statistical Machine Translation",
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation",
      "Unified Language Model Pre-Training for Natural Language Understanding and Generation",
      "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth",
      "Learning to Ask: Neural Question Generation for Reading Comprehension",
      "Hierarchical Neural Story Generation",
      "Outline to Story: Finegrained Controllable Story Generation from Cascaded Events",
      "Controlling Linguistic Style Aspects in Neural Language Generation",
      "EmoSen: Generating Sentiment and Emotion Controlled Responses in a Multimodal Dialogue System",
      "Being Polite: Modeling Politeness Variation in a Personalized Dialog Agent",
      "Making Pre-trained Language Models Better Few-shot Learners",
      "Structuring Latent Spaces for Stylized Response Generation",
      "A Snapshot of NLG Evaluation Practices 2005 -2014",
      "Content Planning for Neural Story Generation with Aristotelian Rescoring",
      "Generative adversarial networks",
      "Bias Correction of Learned Generative Models Using Likelihood-Free Importance Weighting",
      "Unifying Human and Statistical Evaluation for Natural Language Generation",
      "A Probabilistic Formulation of Unsupervised Text Style Transfer",
      "Parallel Refinements for Lexically Constrained Text Generation with BART",
      "The Curious Case of Neural Text Degeneration",
      "Building Natural Language Generation Systems",
      "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P. Xing. 2017. Controllable Text Generation. CoRR abs/1703.00955 (2017). arXiv:1703.00955 http://arxiv.org/abs/1703.00955",
      "PAIR: Planning and Iterative Refinement in Pre-trained Transformers for Long Text Generation",
      "Challenges in building intelligent open-domain dialog systems",
      "Reducing Sentiment Bias in Language Models via Counterfactual Evaluation",
      "Quality Management on Amazon Mechanical Turk",
      "Survey of Hallucination in Natural Language Generation",
      "How Can We Know What Language Models Know?",
      "Template Guided Text Generation for Task-Oriented Dialogue",
      "Text-to-Text Pre-Training for Data-to-Text Tasks",
      "CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation",
      "CTRL: A Conditional Transformer Language Model for Controllable Generation",
      "A Distributional Approach to Controlled Text Generation",
      "Auto-encoding variational bayes",
      "Reformer: The Efficient Transformer",
      "GeDi: Generative Discriminator Guided Sequence Generation",
      "The Power of Scale for Parameter-Efficient Prompt Tuning",
      "A Diversity-Promoting Objective Function for Neural Conversation Models",
      "A Persona-Based Neural Conversation Model",
      "Rigid Formats Controlled Text Generation",
      "EmoElicitor: An Open Domain Response Generation Model with User Emotional Reaction Awareness",
      "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
      "Diffusion-LM Improves Controllable Text Generation",
      "Gpt-based generation for classical chinese poetry",
      "ROUGE: A Package for Automatic Evaluation of Summaries",
      "The Adapter-Bot: All-In-One Controllable Conversational Model",
      "Plug-and-Blend: A Framework for Plug-and-Play Controllable Story Generation with Sketches",
      "DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts",
      "TESLA: Translation Evaluation of Sentences with Linear-Programming-Based Analysis",
      "A character-centric neural model for automated story generation",
      "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
      "Mitigating political bias in language models through reinforced calibration",
      "Data Boost: Text Data Augmentation Through Reinforcement Learning Guided Conditional Generation",
      "Multilingual Denoising Pre-training for Neural Machine Translation",
      "Naturalness Evaluation of Natural Language Generation in Task-oriented Dialogues using BERT",
      "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "Content preserving text generation with attribute controls",
      "Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses",
      "Learning to Control the Fine-grained Sentiment for Story Ending Generation",
      "Controlled Text Generation for Data Augmentation in Intelligent Artificial Agents",
      "Putting Evaluation in Context: Contextual Embeddings Improve Machine Translation Evaluation",
      "Efficient estimation of word representations in vector space",
      "Mix and Match: Learning-free Controllable Text Generationusing Energy Language Models",
      "Comparing Person-and Process-Centric Strategies for Obtaining Quality Data on Amazon Mechanical Turk",
      "DART: Open-Domain Structured Data Record to Text Generation",
      "Polite Dialogue Generation Without Parallel Data",
      "RankME: Reliable Human Ratings for Natural Language Generation",
      "Training language models to follow instructions with human feedback",
      "Bleu: a Method for Automatic Evaluation of Machine Translation",
      "A Plug-and-Play Method for Controlled Text Generation",
      "Few-shot Natural Language Generation for Task-Oriented Dialog",
      "Deep Contextualized Word Representations",
      "MAUVE: Human-Machine Divergence Curves for Evaluating Open-Ended Text Generation",
      "Exploring Controllable Text Generation Techniques",
      "Automatically neutralizing subjective bias in text",
      "Data-to-text generation with content selection and planning",
      "Controllable Natural Language Generation with Contrastive Prefixes",
      "Reducing gender bias in word-level language models with a gender-equalizing loss function",
      "Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading",
      "COLD Decoding: Energy-based Constrained Text Generation with Langevin Dynamics",
      "Language models are unsupervised multitask learners",
      "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
      "Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features",
      "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
      "Investigating Pretrained Language Models for Graph-to-Text Generation",
      "Structural Adapters in Pretrained Language Models for AMR-to-Text Generation",
      "Emotion-Regularized Conditional Variational Autoencoder for Emotional Response Generation",
      "CounterGeDi: A Controllable Approach to Generate Polite, Detoxified and Emotional Counterspeech",
      "Bidisha Samanta, Mohit Agarwal, and Niloy Ganguly. 2020. Fine-grained Sentiment Controlled Text Generation. arXiv preprint arXiv:2006.09891 (2020). https://arxiv.org/abs/2006.09891",
      "Bloom: A 176b-parameter open-access multilingual language model",
      "Discriminative Adversarial Search for Abstractive Summarization",
      "BLEURT: Learning Robust Metrics for Text Generation",
      "Controlling Politeness in Neural Machine Translation via Side Constraints",
      "A Sentiment and Style Controllable Approach for Chinese Poetry Generation",
      "Towards controllable biases in language generation",
      "SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint",
      "Dispersed Exponential Family Mixture VAEs for Interpretable Text Generation",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
      "Learning Structured Output Representation Using Deep Conditional Generative Models",
      "BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data",
      "Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation",
      "Structural Information Preserving for Graph-to-Text Generation",
      "Generating Responses with a Specific Emotion in Dialog",
      "Learning to Summarize from Human Feedback",
      "A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models",
      "NY, USA, Article 253, 14 pages. https://proceedings.neurips.cc/paper/2020/file/1f89885d556929e98d3ef9b86448f951- Paper.pdf",
      "Plan-then-Generate: Controlled Data-to-Text Generation via Planning",
      "Controllable Neural Story Plot Generation via Reward Shaping",
      "A Topic Augmented Text Generation Model: Joint Learning of Semantics and Structural Features",
      "Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models",
      "ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation",
      "Human evaluation of automatically generated text: Current trends and best practice guidelines",
      "Attention is all you need",
      "Generating lyrics with variational autoencoder and multi-modal artist embeddings",
      "A Template-guided Hybrid Pointer Network for Knowledge-based Task-oriented Dialogue Systems",
      "SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks",
      "Keep it Consistent: Topic-Aware Storytelling from an Image Stream via Iterative Multi-agent Communication",
      "Topic-Guided Variational Auto-Encoder for Text Generation",
      "Mention Flags (MF): Constraining Transformer-based Text Generators",
      "Finetuned Language Models are Zero-Shot Learners",
      "Emotion-aware Chat Machine: Automatic Emotional Response Generation for Human-like Emotional Interaction",
      "Neural Text Generation With Unlikelihood Training",
      "A Controllable Model of Grounded Response Generation",
      "An Explanation of In-context Learning as Implicit Bayesian Inference",
      "Unsupervised Controllable Text Generation with Global Variation Discovery and Disentanglement",
      "MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models",
      "FUDGE: Controlled Text Generation With Future Discriminators",
      "Tailor: A Prompt-Based Approach to Attribute-Based Controlled Text Generation",
      "Enhancing Topic-to-Essay Generation with External Commonsense Knowledge",
      "Generating Thematic Chinese Poetry Using Conditional Variational Autoencoders with Hybrid Decoders",
      "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
      "Auxiliary Tuning and its Application to Conditional Text Generation",
      "A Simple and Efficient Multi-Task Learning Approach for Conditioned Dialogue Generation",
      "DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation",
      "Emotional text generation based on cross-domain sentiment transfer",
      "Personalizing Dialogue Agents: I have a dog, do you have pets too",
      "BERTScore: Evaluating Text Generation with BERT",
      "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation",
      "POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training",
      "ERNIE: Enhanced Language Representation with Informative Entities",
      "Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation",
      "Energy-based Generative Adversarial Networks",
      "A Pre-Training Based Personalized Dialogue Generation Model with Persona-Sparse Data",
      "Towards Persona-Based Empathetic Conversational Models",
      "Learning to compare for better training and evaluation of open domain natural language generation models",
      "Texygen: A Benchmarking Platform for Text Generation Models",
      "Fine-Tuning Language Models from Human Preferences",
      "Controllable Generation from Pre-trained Language Models via Inverse Prompting"
    ]
  }
}