{
  "survey": "Neural networks, cognitive architecture, artificial intelligence (AI), and knowledge retention collectively form the backbone of advanced computational models designed to emulate human cognitive functions. This survey explores these interconnected domains, emphasizing their role in enhancing AI's ability to perform complex tasks autonomously. The integration of neural networks with large language models (LLMs) has significantly improved AI's reasoning and decision-making capabilities, highlighting the importance of cognitive architecture in simulating human-like intelligence. Despite advancements, challenges such as high energy costs and inference delays in Transformer-based models persist. The survey evaluates LLMs' impact on knowledge retention, showcasing their transformative effect on data interaction and synthesis across domains like healthcare and finance. It also examines the development of LLM-based intelligent agents and their applications in various fields, addressing limitations in decision-making and knowledge utilization. The structured analysis of neural networks and cognitive architecture frameworks reveals their critical role in optimizing AI systems' adaptability and efficiency. Furthermore, the survey identifies ethical and interpretability challenges, emphasizing the need for robust evaluation and benchmarking to enhance AI's scalability and applicability. By addressing these challenges, the survey aims to foster the development of more intelligent and autonomous systems capable of overcoming traditional constraints and enabling human-like decision-making processes. Overall, the study underscores the significance of continuous innovation in refining AI technologies, paving the way for their expanded application across diverse domains.\n\nIntroduction Importance of Neural Networks and Cognitive Architecture Neural networks and cognitive architecture are essential for advancing artificial intelligence (AI), providing the structural foundation for systems that emulate human cognitive processes. These frameworks facilitate the simulation of complex human behaviors and decision-making, enabling the development of intelligent agents capable of autonomous and adaptive operation [1]. The integration of neural networks with large language models (LLMs) significantly enhances AI's ability to perform human-like reasoning and action, addressing the traditional limitations in the synergy between these processes [2]. Neural networks are pivotal in modeling human behavior within AI, offering sophisticated frameworks for simulating complex interactions and personality traits that influence opinion expression and decision-making. By utilizing LLMs, these networks enable the creation of generative agents that convincingly replicate human behavior, such as forming opinions and initiating conversations in interactive environments like social network simulations. This advancement deepens our understanding of cognitive architecture and empowers applications across social science and psychology, paving the way for more interactive and context-aware AI systems [3,4,5,6,7]. This modeling is crucial for developing systems that mimic human-like intelligence and bridging the gap between language and behavior modeling in recommender systems. Cognitive architecture provides a structured approach to integrating various cognitive processes, allowing AI systems to execute complex tasks such as dynamic communication and adaptive planning in multi-agent environments. The development of agents emphasizes the necessity for real-time learning and adaptation within complex settings. The exploration of LLMs reveals their potential to enhance decision-making capabilities, overcoming the limitations of prior research that often trained agents in isolated environments. By leveraging vast web knowledge, LLMs demonstrate robust generalization and human-level intelligence, leading to advancements in fields such as social science, robotics, and artificial general intelligence. These models improve human-robot interaction and decision-making, offering extensive opportunities for future research [8,9,10]. Despite advancements in Transformer-based pretrained language models (PLMs), challenges such as high energy consumption and prolonged inference delays hinder their widespread adoption, particularly in edge and mobile computing environments. Although these models achieve state-of-the-art performance across various NLP tasks, their computational and energy demands affect practicality in scenarios requiring efficient resource utilization. Research is increasingly focused on addressing these issues through model compression, acceleration techniques, and parameter-efficient fine-tuning methods to optimize the lifecycle of PLMs from data preparation to inference [11,12,13,14,15]. Addressing these challenges is crucial for maximizing the performance and applicability of AI technologies. Language agents have demonstrated impressive problem-solving skills in defined settings, further underscoring the importance of neural networks and cognitive architecture in AI. Neural networks and cognitive architecture are indispensable in AI, providing essential tools for developing intelligent systems capable of learning, reasoning, and effective interaction. The ongoing advancement of LLMs is vital for overcoming existing limitations and enhancing the performance and applicability of AI technologies across diverse sectors. Recent surveys indicate that these models hold promise for addressing complex societal challenges, such as improving the understanding and application of psychological principles through performance validation and practical implementations. Furthermore, LLM-based AI agents are transforming traditional AI infrastructures with enhanced natural language processing, knowledge storage, and reasoning capabilities. However, these developments also present significant challenges, particularly regarding computational demands and privacy concerns, necessitating innovative methodologies and strategies for efficient integration of external knowledge. Continuing research in these areas will significantly enhance the capabilities and impact of AI technologies [4,16,17,18,5]. Relevance of Artificial Intelligence and Knowledge Retention Artificial intelligence plays a pivotal role in knowledge retention, particularly through its capacity to autonomously manage and interact with vast data sets. The need for agents that adapt flexibly to complex environments while maintaining long-term memory underscores AI's relevance in this domain [19]. The transformative impact of large language models (LLMs) and pre-trained language models (PLMs) on natural language processing (NLP) has significantly enhanced AI's capabilities in efficiently processing and retaining information [13]. These models represent a substantial leap in the ability of AI systems to handle complex data interactions and synthesis. Recent advancements in generative artificial intelligence (GAI) have further expanded the potential for deploying large-scale AI models tailored to specific domains, underscoring AI's critical role in knowledge retention [20]. Customization of AI characters in dialogues, such as through CharacterGLM, enhances personalized knowledge retention by incorporating diverse character attributes and behaviors [21]. Moreover, generative agents leveraging LLMs to simulate human-like behaviors by storing and synthesizing memories exemplify AI's potential for mimicking intricate human interactions [3]. AI's role in enhancing the processing of lengthy inputs is crucial for knowledge retention, as demonstrated by the effectiveness of LLMs in this regard [11]. The integration of domain-specific insights with conversational capabilities, as seen in Radiology-GPT, illustrates AI's application in specialized fields, thereby enhancing task-specific knowledge retention [22]. In open-world settings, AI systems like JARVIS-1 utilize multimodal inputs to improve task completion and knowledge retention [23]. The inadequacy of existing social network simulation methods to accurately mimic human behavior in social interactions highlights AI's importance in addressing these challenges [6]. By enhancing the interaction between reasoning and action planning in LLMs, AI systems can improve their overall effectiveness, directly impacting knowledge retention [24]. Addressing the incomprehension of LLMs regarding user-item relations is crucial for understanding AI's role in personalized knowledge retention [25]. AI's significance in knowledge retention is further underscored by its societal implications, where it mitigates psychological challenges through improved data interaction and autonomous decision-making [4]. However, primary challenges include concerns about fairness, accountability, transparency, and ethics in the use of LLMs, particularly within healthcare settings [2]. Artificial intelligence, through the advancement of LLMs and their integration with external tools, plays a crucial role in knowledge retention, addressing knowledge gaps and enabling innovative applications across diverse domains. Objectives of the Survey The survey aims to provide a comprehensive evaluation of large language models (LLMs), focusing on knowledge and capability evaluation, alignment evaluation, and safety evaluation [26]. It seeks to address the limitations of current autonomous systems, particularly in decision-making and knowledge utilization, by exploring methodologies such as Parameter Efficient Fine-Tuning (PEFT) for optimizing AI models without extensive computational resources. Furthermore, the survey investigates the significance of specialized LLMs like Radiology-GPT in enhancing AI applications within the medical field [22]. A critical objective is to explore the development and deployment of LLM-based intelligent agents, filling knowledge gaps in the area of artificial general intelligence [9]. The survey includes studies on LLM-based autonomous agents across various fields, such as social science, natural science, and engineering, highlighting their diverse applications [8]. Additionally, the focus is on the inference stage of pre-trained language models (PLMs), reviewing model compression and acceleration techniques to improve efficiency [14]. The survey evaluates how language models can replicate human behaviors observed in psychological and economic experiments using the Turing Experiment framework [27]. It explores collaborative learning frameworks like AgentCF to enhance user behavior simulation in AI systems [25]. Moreover, the development of cognitive architectures such as LARP, which integrates memory processing and decision-making to improve agent interactions in gaming, is examined [19]. Addressing the high computational and memory resource demands of LLMs, which hinder their widespread adoption and usability, remains a primary challenge [1]. The survey also covers topics related to the capabilities, training data, methods, optimization strategies, and ethical considerations of LLMs in healthcare [2]. Overall, the survey aims to establish a unified framework for evaluating PLMs in the biomedical field, enhancing their effectiveness and applicability across diverse domains. Structure of the Survey The survey is meticulously structured to guide readers through the complex landscape of neural networks, cognitive architecture, artificial intelligence, and knowledge retention. It commences with an introduction that elucidates the significance of these interconnected domains, setting the stage for a detailed exploration of their roles and implications [28]. The paper then transitions into a comprehensive background section, where foundational definitions and historical developments are examined, providing context for understanding the evolution and significance of these concepts. Following the background, the survey delves into the intricate relationship between neural networks and cognitive architecture, analyzing various frameworks and categorizations that underpin these models. This section also investigates the integration of these architectures with autonomous systems, highlighting their applications and potential [29]. Subsequently, the focus shifts to artificial intelligence's role in knowledge retention, exploring techniques for memory and information retrieval, the impact of LLMs, and methods to address biases and hallucinations in AI systems. The survey progresses to discuss interconnected systems and models, emphasizing the development of multimodal and memory-enhanced systems, alongside the role of cognitive architecture in autonomous agents. Real-world applications are presented, offering detailed case studies across specialized domains such as healthcare and finance. These studies delve into AI's transformative role in enhancing efficiency and effectiveness in healthcare through LLMs, while also addressing concerns related to fairness, accountability, transparency, and ethics. In finance, the focus is on leveraging LLMs for improved natural language processing tasks, guided by a decision framework for adoption based on specific constraints. Furthermore, the implications of AI in security and privacy are examined, highlighting efforts to integrate privacy into AI models, mitigate copyright issues, and comply with privacy regulations [4,17,30,2]. Finally, the survey addresses challenges and future directions in AI research, identifying limitations, resource constraints, and ethical considerations. The reflective summary of the findings emphasizes the crucial role of continuous evaluation and benchmarking in advancing AI technologies, particularly in the context of large language models. It highlights the need for performance validation from diverse perspectives to ensure these models effectively bridge the gap between psychological principles and their real-world applications. Furthermore, the summary underscores the importance of integrating external knowledge to address challenges such as outdated data and domain-specific limitations, suggesting that these efforts will drive progress in AI applications across various fields, including psychology and natural language processing [4,16]. This structured approach ensures a comprehensive understanding of the subject, facilitating further research and development in the field.The following sections are organized as shown in . Background and Definitions Definitions and Core Concepts Neural networks, cognitive architecture, artificial intelligence (AI), and knowledge retention form the backbone of computational intelligence, each playing a pivotal role in mimicking human cognitive functions. Neural networks, inspired by the brain's neuronal architecture, are integral to processing and retrieving vast datasets, significantly enhancing decision-making in multimodal AI systems [1]. They are essential for optimizing complex data processes and advancing similarity search algorithms [23]. Cognitive architecture encompasses theoretical models that delineate the structures and mechanisms governing human cognition within AI systems. These architectures integrate reasoning, memory, and decision-making, promoting adaptive and autonomous behavior. For instance, they enable embodied agents to learn and execute abstract policies in visually grounded settings, showcasing their problem-solving prowess [1]. Such architectures are crucial for developing systems that autonomously handle complex tasks. AI involves creating systems with human-like intelligence, prominently featuring large language models (LLMs) and pretrained language models (PLMs). These advanced architectures are designed to comprehend and generate human language, significantly improving knowledge retention and interaction with extensive datasets. Transformer-based innovations have notably enhanced their capacity to process long-context information, vital for various AI applications [1]. However, challenges like the integration of reasoning and action generation in LLMs persist, affecting task performance [27]. Knowledge retention in AI involves storing, retrieving, and applying information over time. AI systems, such as Personal LLM Agents, synthesize vast data into tailored insights [1]. Instruction tuning aligns language models with human directives, bridging the gap between next-word prediction and nuanced understanding [1]. Moreover, the lack of integration with external knowledge in recommendation systems highlights a significant challenge in effective knowledge retention [1]. The interplay among neural networks, cognitive architecture, AI, and knowledge retention highlights these technologies' potential in fostering intelligent systems capable of autonomous and efficient task execution. The ongoing challenge is refining LLM-based agents for effective operation in both single-agent and multi-agent settings, enhancing planning, reasoning, and communication for human-like decision-making. These agents are increasingly used in complex problem-solving and dynamic simulations, necessitating advancements in profiling, communication methods, and skill development. Researchers aim to optimize generalization across domains, including coding and social applications, while exploring strategies for collaboration and communication issue mitigation. The evolving AI and natural language processing landscape presents extensive opportunities for LLM-based agents to advance toward artificial general intelligence (AGI) [31,9]. Historical Development and Evolution The evolution of neural networks, cognitive architecture, AI, and knowledge retention reflects a substantial shift from basic computational models to sophisticated systems replicating complex human cognitive processes. This journey began with rudimentary neural network models, evolving into advanced architectures like Transformer models, which have significantly enhanced natural language processing (NLP) capabilities [2]. The transition from model-centered to data-centered methodologies underscores data-driven techniques' importance in improving AI's adaptability and efficiency. Large language models (LLMs) have undergone transformative changes, particularly with pretrained language models (PLMs) addressing computational and energy consumption challenges [14]. Models like GLM-130B highlight the need for large-scale bilingual language models, responding to limitations in existing models such as GPT-3 [32]. These advancements illustrate LLMs' increasing complexity and capability in managing intricate language tasks and processing extensive datasets. The evolution of PLMs has been particularly impactful in specialized domains like healthcare, where adaptations address domain-specific challenges [1]. This adaptability is crucial in fields such as materials science and biomedical research, where AI systems must efficiently process vast amounts of complex data. Despite these advancements, the efficiency challenges associated with LLMs, which demand substantial computational resources, remain a core issue [1]. Cognitive architecture has advanced significantly, particularly with the integration of reasoning capabilities and tool integration in augmented language models (ALMs) [1]. This progress enables systems to autonomously interpret and act on information from multiple sensory inputs, enhancing decision-making capabilities and facilitating sophisticated interactions with their environments. The historical development of instruction tuning methodologies has been instrumental in improving LLM performance, aligning language models more closely with human instruction adherence [1]. This advancement addresses the gap between next-word prediction and nuanced understanding, enhancing AI's ability to perform tasks requiring deep comprehension of human language and intentions. In knowledge retention, methods for information extraction have evolved to improve AI systems' ability to retain and synthesize information over time. These advancements tackle challenges like catastrophic forgetting and enable continuous learning, allowing AI systems to maintain long-term memory and adapt to new information [1]. The historical evolution of AI concepts highlights AI research's dynamic and iterative nature, where continuous innovations—particularly in large language models and AI agents—drive the field toward more sophisticated and capable systems. These advancements have profound implications, enabling effective applications in psychology, social media analytics, and clinical nursing. Integrating large language models with AI agents enhances capabilities in natural language processing, knowledge storage, and reasoning, marking a significant shift from traditional AI approaches. As these technologies progress, they promise to reduce labor costs and alleviate social stress, while also posing challenges related to paradigm shifts and necessary upgrades in associated fields [4,5]. The integration of these advancements into real-world applications continues to push the boundaries of AI capabilities, underscoring the importance of ongoing research and development. Significance in AI Integrating neural networks, cognitive architecture, artificial intelligence (AI), and knowledge retention is essential for advancing AI's ability to replicate human cognitive processes. These concepts collectively enhance AI's capacity to autonomously perform complex tasks, transforming fields such as autonomous systems, code generation, and similarity search. The DiLu framework exemplifies this integration by employing large language models (LLMs) to augment decision-making capabilities in autonomous vehicles, surpassing traditional reinforcement learning methods [33]. This advancement underscores LLMs' transformative potential in enhancing AI's adaptability and efficiency in real-world applications. Cognitive architecture's significance in AI is further illustrated by its role in developing sophisticated evaluation frameworks such as the Turing Experiment, which assesses language models by simulating human behavior [27]. This approach provides insights into cognitive processes, enabling AI systems to achieve a deeper understanding of human language and interactions. Such evaluations are vital for advancing AI's ability to replicate complex human cognitive functions, thereby enhancing overall performance and applicability. In code generation, the benchmark CodeAgentBench offers a realistic evaluation framework for LLMs, significantly contributing to AI technologies' advancement [34]. This framework aids in developing more efficient and capable AI systems, capable of autonomously generating high-quality code. The integration of advanced computational techniques, as demonstrated by enhanced GPU utilization for similarity search, underscores these concepts' importance in optimizing AI's performance [35]. The collective significance of neural networks, cognitive architecture, AI, and knowledge retention lies in their ability to transform decision-making, enhance computational efficiency, and emulate human cognitive functions. This transformation is driven by integrating large language models (LLMs) excelling in natural language processing, knowledge storage, and reasoning, providing unprecedented capabilities in areas like social media analytics, clinical insights, and information retrieval. These advancements promise to reduce labor costs and alleviate social stress while necessitating paradigm shifts in AI agent design and medical instrumentation, addressing challenges such as data scarcity and interpretability [4,36,5]. These concepts are instrumental in driving AI research and development, paving the way for more intelligent and autonomous systems capable of addressing diverse challenges across various domains. Neural Networks and Cognitive Architecture Frameworks and Categorization Understanding the frameworks and categorization of neural networks and cognitive architectures is essential for grasping their functionalities and applications within AI systems. This survey highlights model compression frameworks for large language models (LLMs), which optimize computational resources [37]. CharacterGLM exemplifies a framework with scalable model sizes, showcasing cognitive architectures' adaptability [21]. RecMind's self-inspiring algorithm enhances planning by revisiting past states, improving recommendation processes [38]. Generative agents integrate memory, planning, and reflection to emulate human interactions [3], while the ReAct method synergizes reasoning and action generation in LLMs [24]. As illustrated in , the categorization of neural network frameworks and cognitive architectures is depicted, emphasizing model compression techniques, cognitive architecture examples, and methods that integrate action and reasoning. AgentCF's collaborative learning framework optimizes user and item agents, emphasizing cognitive architectures' role in complex decision-making [25]. LARP combines memory processing and personality alignment, fostering adaptive agent behavior [19]. JARVIS-1 utilizes multimodal inputs for actionable plans, illustrating cognitive architecture's significance in decision-making [23]. These frameworks advance psychology, information retrieval, and AI agent development by leveraging LLMs for natural language processing and knowledge integration. Innovative classification schemes and multi-sensory inputs pave the way for sophisticated, context-aware AI systems capable of operating in diverse environments [4,5,16,7,36]. This categorization promotes the development of efficient models to tackle complex challenges across various domains. Simulation and Role-Playing Simulation and role-playing are pivotal in mimicking human brain functions, providing insights into cognitive architecture and AI systems. Character-LLM replicates human behaviors, focusing on identities and emotional states [39], enhancing AI adaptability to diverse scenarios. Role-playing techniques, such as RoleLLM, aid in understanding human interactions and decision-making [40]. The DiLu framework simulates human-like reasoning, crucial for autonomous driving [33]. ChatHaruhi enhances role-playing in chatbots through character-specific memories [41], while MemorySand offers an interface for controlling agent perception and recall [42]. Research on scaling effects of larger language models emphasizes their superior simulation abilities [12]. Synapse:Transformers enhance task representation and generalization by leveraging memory and abstraction [43]. Training large models with instruction tuning, as in Radiology-GPT, underscores simulation's significance in AI systems [22], particularly in specialized domains like radiology. Integration with Autonomous Systems Integrating neural networks and cognitive architectures with autonomous systems enhances task execution with increased autonomy and intelligence. LLMs improve decision-making in macroeconomic simulations [44], highlighting their potential in complex environments. Cognitive architectures enable real-time learning and adaptation, integrating perception, reasoning, and decision-making. This supports open-world understanding in autonomous driving and expands LLM-based applications across sciences and engineering, necessitating improved validation due to data-driven models' \"black box\" nature [8,45]. Neural networks provide computational power for real-time data processing, crucial for timely decision-making in autonomous systems. They enable systems to recognize contextual signals, predict outcomes, and optimize actions using LLMs' language understanding and reasoning abilities. Despite challenges like data scarcity, integrating traditional methods with modern architectures enhances perception and response generation [6,36]. LLMs enhance language processing in autonomous systems, improving human-machine interactions. This allows for natural communication, crucial in applications like autonomous vehicles [10,8]. Integrating neural networks, cognitive architectures, and LLMs represents a transformative AI step, expanding applications from economic modeling to transportation. Ongoing developments in LLMs and multimodal systems promise significant advances, transitioning from rule-based to data-driven strategies, enabling complex tasks with enhanced autonomy. Integrating LLMs with vision models achieves open-world understanding and few-shot learning, addressing transparency and traceability limitations. Frameworks like DiLu demonstrate superior generalization and applicability, revolutionizing transportation and various fields while necessitating academia-industry collaboration [4,29,33,45,8]. In recent years, the field of artificial intelligence has witnessed significant advancements, particularly in knowledge retention and information retrieval. To better understand the complexities of these developments, presents a detailed illustration of the hierarchical structure of key concepts in AI knowledge retention. This figure categorizes essential components such as memory and information retrieval, the role of large language models, knowledge editing techniques, integration of external memory systems, and strategies for addressing hallucinations and biases. Each section of the figure not only delineates the various challenges and advancements but also highlights practical applications and impact areas, thereby providing a comprehensive overview of AI's evolving capabilities in managing extensive datasets and improving reliability. Such visual representation enhances our understanding of the intricate relationships among these concepts and underscores the importance of a structured approach to AI development. Artificial Intelligence and Knowledge Retention Memory and Information Retrieval Memory and information retrieval are crucial for enhancing AI systems, particularly in managing extensive datasets. The integration of large language models (LLMs) into these systems presents challenges such as high resource demands and the lack of dedicated memory units, which restrict explicit knowledge storage and retrieval during tasks [46]. Addressing these issues is vital for optimizing AI performance. As illustrated in , the hierarchical structure of key concepts in memory and information retrieval within AI systems highlights integration challenges, enhancing techniques, and recent advances. Techniques like ExpeL improve decision-making by utilizing experiences and insights, thereby enhancing memory systems. Similarly, Lyfe Agents' Summarize-and-Forget mechanism refines social interactions by optimizing the retention of pertinent information [19]. These methods highlight the importance of integrating memory management techniques for effective AI interactions. Prompting techniques and memory management approaches, as seen in MPC, advance conversational agents by enhancing memory and information retrieval processes. Synapse:Transformers improve decision-making through state abstraction, addressing context length limitations and achieving success in complex tasks [47,14,43]. In autonomous systems, memory retrieval techniques are essential for learning from past experiences and adapting to new information. Alfworld trains agents for tasks requiring abstract reasoning and visual interaction, emphasizing tool learning for improved accuracy [48]. Recent advances in memory mechanisms, driven by LLMs, play a key role in enhancing AI systems. By integrating LLMs with AI agents, these systems exhibit superior capabilities in natural language handling, knowledge storage, and reasoning. Frameworks like RET-LLM introduce scalable memory units for information extraction, significantly improving performance in tasks like question answering and retrieval [49,36,5]. Addressing challenges such as hallucinations remains crucial for improving AI reliability, fostering intelligent and autonomous systems capable of addressing diverse challenges. Large Language Models (LLMs) in Knowledge Retention LLMs have revolutionized AI, demonstrating exceptional abilities in natural language understanding and reasoning. They transform domains like information retrieval and finance by enhancing knowledge retention and application. Evolving from traditional methods to sophisticated architectures, LLMs improve contextual understanding despite challenges like data scarcity and efficiency demands. Strategies such as knowledge editing and retrieval augmentation address domain-specific limitations, inspiring ongoing research [1,16,12,30,36]. LLMs' generalization capabilities facilitate automation in data collection, essential for applications requiring human-like language processing. Addressing hallucinations and outdated information is crucial for reliable outputs. Techniques like Retrieval-Augmented Generation (RAG) improve reliability by integrating contextual retrieval mechanisms during generation [50]. In finance, frameworks like FinMem enhance knowledge retention related to investment decisions [48]. The PEAK benchmark highlights challenges in integrating new information within LLMs, emphasizing the need for consistent knowledge bases, especially in sectors like healthcare [2]. Efficient serving methodologies address LLMs' computational demands, ensuring scalability across scenarios [1]. LLMs simulate personalized user behaviors using collaborative filtering techniques, enhancing personalization within knowledge retention frameworks. Multimodal memory systems like JARVIS-1 improve task performance through real-time information synthesis [1]. Ongoing LLM development drives AI innovations, enhancing knowledge retention capabilities. By integrating established methodologies and addressing challenges, LLMs advance systems capable of learning and communicating with human-like proficiency, expanding AI horizons in knowledge-intensive domains. These models improve robotics by enhancing intelligence and autonomy through better perception and control. Researchers explore methods to integrate external information for improved performance, promising significant advancements in AI agent technology [10,9,16,5]. Knowledge Editing Techniques Knowledge editing techniques ensure LLMs maintain relevance and accuracy over time, focusing on updating models with new information without degrading existing knowledge. Efficient methods for managing updates are emphasized, preserving performance across applications [51]. Models like GLM-130B exemplify strategies enhancing efficiency during editing [32]. The Voyager framework introduces a skill library, showcasing structured knowledge editing through iterative prompting for continuous learning [52]. A classification scheme for AI agents' memory components highlights traditional editing limitations, underscoring innovative frameworks' significance in advancing AI capabilities [5]. Challenges like computational intensity in fine-tuning methods prompt exploration of tuning-free algorithms that refine knowledge bases without extensive fine-tuning, preserving large models' versatility [51]. Symbolic memory systems facilitate precise instruction generation, augmenting LLMs' editing capabilities [46]. Prompt engineering and tuning techniques enhance realism in social network simulations [6]. A two-layer loop system allows iterative refinement of responses and knowledge bases through real-world testing, advancing knowledge editing [53]. Despite progress, extending context length without compromising performance and establishing standardized evaluation methods remain challenges [54]. Addressing these issues is vital for advancing methodologies and enhancing AI performance. Integration of External Memory Systems Integrating external memory systems within AI frameworks enhances cognitive capabilities through efficient data processing and retrieval. This integration optimizes AI performance across domains like perception and decision-making [10]. External memory systems provide structured approaches for managing extensive information, essential for categorizing compression techniques used to optimize LLMs [55]. Moreover, integrating external memory systems enhances AI's autonomous task performance by providing robust frameworks for information storage. Mechanisms like MemoryBank equip LLMs with long-term memory capabilities, enabling them to recall information and mimic human-like memory processes. Frameworks like RET-LLM leverage scalable memory units for complex reasoning, advancing AI performance in intricate scenarios [49,56,57,5]. This capability is vital for applications requiring real-time data processing and adaptive learning. The integration of external memory systems marks a significant advancement in developing intelligent systems, enhancing their ability to autonomously process information and interact seamlessly. This evolution is driven by LLMs' capabilities, supported by multimodal AI systems that interpret visual and contextual data, improving interactions and reducing errors in real-world applications. As systems evolve, they hold potential to transform fields like psychology and social media analytics, offering societal benefits while presenting challenges related to paradigm shifts [4,7,5]. Leveraging these systems, AI models can achieve deeper environmental understanding, enhancing decision-making capabilities across diverse fields. Addressing Hallucinations and Biases Addressing hallucinations and biases in AI systems, particularly LLMs, is fundamental to enhancing trust and reliability. Hallucinations occur when LLMs generate content that appears accurate but lacks substantive grounding, undermining perceived accuracy. Context window limitations hinder LLMs in processing longer information sets, exacerbating hallucination issues [58]. Ensuring information remains current and developing transparent reasoning processes are pivotal in overcoming these constraints. Frameworks like ReAct advance hallucination mitigation by addressing error propagation through enhanced task-solving trajectories [24]. This aligns with robust systems capable of reliable reasoning and task execution in multitasking environments [50]. Improving memory and adaptability through frameworks like LARP highlights the importance of equipping agents for dynamic scenarios [19]. Tackling biases requires identifying and rectifying errors from data influence complexities and real-world challenges, encompassing bias management and operational cost efficiencies. Exploring long context comprehension capabilities is limited, prompting the need for models that extend understanding to maintain coherence and accuracy [58]. The APP framework curtails neighboring perturbation issues, improving knowledge retention and mitigating bias through consistent data management [54]. FinMem's agile response to dynamic data contexts exemplifies progress in retaining critical information, enhancing trading outcomes [48]. Advancing methodologies to address hallucinations and biases necessitates developing evaluation frameworks, adaptive memory management systems, and dynamic approaches to mitigate biases, fostering robust AI models equipped for diverse scenarios. Interconnected Systems and Models Multimodal and Memory-Enhanced Systems Multimodal and memory-enhanced systems represent a significant advancement in AI, enabling context-aware interactions through the integration of external knowledge and multi-sensory inputs [7]. Utilizing large language models (LLMs), these systems enhance decision-making capabilities across domains, such as quantitative investment, by incorporating diverse data sources and memory mechanisms [53]. The ability to process multimodal inputs allows AI systems to synthesize information from various sensory channels, improving their understanding and response to complex environments. For instance, the Dialectic Multi-Robot Collaboration (DMRC) framework exemplifies this capability by facilitating collaborative communication and planning among robots [50]. Such systems underscore the importance of memory enhancement in AI, promoting sophisticated interactions and decision-making processes. Categorizing code LLMs based on their publishers and relationships with general LLMs provides a structured understanding of these models' applications and methodologies [59]. This categorization highlights the potential for tailoring LLMs to specific use cases, thereby enhancing their effectiveness in specialized domains. Decision frameworks for financial professionals offer insights into choosing suitable LLM solutions based on constraints, emphasizing the relevance of multimodal and memory-enhanced systems [30]. Resource efficiency techniques are crucial for optimizing multimodal systems' performance, with nuanced categorizations exploring the relationship between resources and optimization strategies [60]. These techniques ensure efficient operation while maintaining enhanced capabilities, supporting deployment in diverse real-world scenarios. The evolution of multimodal and memory-enhanced systems reflects ongoing AI advancements, emphasizing the integration of diverse inputs and memory mechanisms to create more intelligent and adaptable systems. By categorizing existing research into a unified framework, these advancements provide a comprehensive view of methodologies and applications propelling the field forward [8]. Autonomous Agents and Cognitive Architecture Cognitive architecture is vital in developing autonomous agents by offering a structured framework for integrating essential cognitive processes necessary for autonomous decision-making and interaction. This integration of perception, reasoning, and memory components enhances the adaptability and efficiency of autonomous systems, enabling real-time learning and decision-making capabilities [1]. Cognitive architectures are essential for developing agents capable of complex tasks, such as dynamic communication and adaptive planning in multi-agent environments. The exploration of LLMs in achieving human-like decision-making capabilities demonstrates these models' potential to address limitations in prior research on autonomous agents [2]. Developing such agents highlights the necessity of robust cognitive architectures for real-time learning and adaptation in complex settings. Integrating neural networks within cognitive architectures provides the computational power required for processing and analyzing vast amounts of data in real-time, crucial for autonomous systems where timely and accurate decision-making is essential. Neural networks enable these systems to recognize patterns, predict outcomes, and optimize actions based on environmental data [1]. Furthermore, incorporating LLMs enhances autonomous systems' ability to understand and generate human language, facilitating more natural and effective human-machine interactions [1]. The continuous refinement of cognitive architectures drives advancements in autonomous agents, allowing them to perform increasingly complex tasks with greater autonomy and intelligence. By leveraging these architectures, autonomous agents can achieve a deeper understanding of their environment, enhancing their decision-making capabilities and expanding their potential applications across various fields [2]. Cognitive architecture is essential for the evolution of autonomous agents, providing the necessary tools and frameworks for developing intelligent systems capable of learning, reasoning, and effective interaction [1]. Applications and Case Studies Artificial intelligence, particularly large language models (LLMs), is reshaping diverse sectors by driving innovation and enhancing operational efficiencies. This section examines case studies illustrating LLMs' transformative impact across specialized domains, beginning with healthcare. Applications in Specialized Domains LLMs' integration into domains such as healthcare and finance enhances domain-specific capabilities. In healthcare, LLMs improve diagnostic accuracy and patient care by processing extensive medical data, despite implementation challenges [45]. Their insights into patient conditions are crucial for advancing healthcare outcomes. In finance, LLMs optimize investment decisions through hierarchical memory systems that synthesize real-time financial information with historical data [48]. This capability exemplifies LLMs' proficiency in managing complex data interactions, aiding financial professionals in dynamic market environments. Software engineering benefits from LLM integration, surpassing traditional methods [61]. Automating code generation and enhancing testing methodologies streamline development processes, increasing productivity and reducing error rates. Narrative systems using LLMs simulate intricate character interactions in gaming and interactive storytelling, enriching user experiences through dynamic narratives [62]. In legal and regulatory contexts, LLMs offer transparent reasoning processes, crucial for compliance and accountability [63]. LLMs' application across specialized domains highlights their unique capacity to enhance processes by integrating updated knowledge and optimizing evaluation methods. Techniques such as knowledge editing, retrieval augmentation, and domain-specific fine-tuning illustrate their versatility, addressing societal risks and practical limitations [1,64,16,30,46]. Overcoming implementation challenges, LLMs foster innovations in diverse fields, promoting intelligent systems capable of addressing complex scenarios. Healthcare Applications AI, particularly LLMs, significantly advances patient care and diagnostics in healthcare. SiliconFriend, a chatbot designed with psychological dialog data, enhances patient engagement and supports mental health interventions through empathetic dialogues [57]. In diagnostic imaging, LLMs analyze datasets to identify patterns, improving diagnostic accuracy and facilitating early disease detection. Their language processing capabilities enable precise information access, enhancing patient outcomes while addressing fairness, accountability, and transparency challenges [2,16,65,66,67]. AI's integration in radiology transforms complex imaging data processing, providing actionable insights. AI optimizes healthcare management processes, such as EHR analysis and resource allocation. Synthesizing large data volumes improves decision-making and operational efficiency, with fairness and ethics considerations crucial for deployment. AI reduces labor costs and alleviates social stress in healthcare, yet challenges remain in adapting medical instrumentation [4,18,2]. AI's role in managing patient flow and resource distribution is vital. AI's evolution in healthcare, driven by LLM advancements, offers solutions for enhancing diagnostics, patient engagement, and management efficiency. The shift from traditional PLMs to LLMs signifies a move towards generative AI and data-centered methodologies. Addressing ethics and transparency challenges maximizes LLM potential [65,2]. Continuous development and evaluation are essential for realizing AI's full potential in complex medical challenges. Financial and Economic Systems AI's integration into financial and economic systems revolutionizes traditional methodologies, enabling sophisticated analyses and decision-making processes. LLMs enhance investment decision accuracy by integrating real-time market information with historical data [48]. In quantitative finance, AI systems utilize hierarchical memory architectures to synthesize datasets, leading to accurate predictive models, particularly beneficial in high-frequency trading where rapid responses are essential [48]. AI's application in economic modeling facilitates comprehensive simulations of macroeconomic scenarios. LLMs enable analysts to explore complex interactions and assess policy impacts, providing insights into trends and fostering informed decision-making at organizational and governmental levels [44]. AI enhances risk management by identifying and mitigating financial risks through advanced data analysis techniques. Recognizing patterns within financial data allows proactive risk addressing, bolstering financial institutions' stability and resilience, crucial for regulatory compliance and sustainability [48]. AI's integration into financial systems signifies a transformative shift, leveraging LLMs for enhanced analytical capabilities and intelligent decision-making. Recent AI advancements, particularly through LLMs, open new avenues for financial applications, enabling zero-shot and few-shot learning, domain-specific fine-tuning, and custom model creation. These developments improve financial natural language processing tasks and provide structured frameworks for tailored AI solutions. Integrating AI agents into multimodal environments supports context-aware systems. As AI evolves, its application in finance and economics drives innovations, enabling efficient resource management in a complex global market [4,7,30,5]. Software Testing and Debugging AI's application in software testing and debugging transforms traditional methodologies, offering efficient solutions for identifying and resolving software issues. LLMs automate code generation and enhance testing processes [61]. Their capabilities facilitate complex code structure synthesis, streamlining debugging and reducing error rates. AI-driven techniques in software testing leverage LLMs to simulate user interactions and predict vulnerabilities, enhancing application reliability and security. Analyzing patterns within code allows AI systems to identify issues and suggest optimal solutions, improving debugging accuracy and efficiency [61]. Integrating AI into software development environments enables comprehensive testing frameworks, allowing performance assessment across diverse scenarios, crucial for ensuring robustness in dynamic environments [61]. AI's strategic use in software testing and debugging exemplifies its transformative impact on software engineering, providing innovative solutions and fostering intelligent, adaptable systems. As AI technologies evolve, their application in this field is expected to drive advancements in managing software development processes. Security and Privacy AI's implications for security and privacy are profound, particularly as LLMs integrate into domains like transportation, education, and healthcare. This survey addresses security and privacy risks associated with LLMs, emphasizing robust defense mechanisms [68]. AI systems introduce vulnerabilities requiring strategies to mitigate threats and safeguard sensitive information. In transportation, AI-driven systems enhance operational efficiency but present risks related to data breaches and unauthorized access. LLMs' capacity to process real-time data necessitates stringent security protocols to prevent exploitation. In education, AI applications must navigate privacy concerns regarding student data, ensuring compliance and protecting rights [68]. AI's role in healthcare is sensitive, given medical data's critical nature and security breach consequences. This survey explores defense mechanisms protecting healthcare systems from cyber-attacks, highlighting AI models with built-in security features adapting to threats [68]. These mechanisms maintain medical information integrity and confidentiality, supporting safe AI healthcare deployment. AI's integration into security and privacy frameworks represents significant advancement, enhancing capabilities for risk identification and mitigation across domains. Addressing AI-driven security and privacy challenges highlights ongoing research and development's importance to foster resilient AI systems navigating complex scenarios [68]. Challenges and Future Directions Challenges and Limitations Artificial intelligence systems, particularly those employing large language models (LLMs), face significant challenges that affect their efficacy across diverse applications. A primary concern is the substantial resource consumption required for training and deploying LLMs, which involves high computational, memory, and financial costs, especially in resource-constrained environments [1]. Moreover, Transformer-based LLMs exhibit limitations in handling long-context inputs, affecting their performance in practical scenarios [58]. The quality of tuning instructions and training datasets also influences model reliability and applicability [50]. Interpretability and transparency of pretrained language models (PLMs) pose additional challenges. Many studies lack comprehensive evaluations and standardized metrics, limiting the effectiveness of mitigation strategies and comparability of results. Concerns about private data leaks and the generation of inappropriate content highlight deficiencies in current LLM evaluation frameworks [2], which are critical when deploying LLMs in autonomous systems where decision-making trust is paramount. Hallucinations—instances where AI generates seemingly accurate but ungrounded content—remain a major issue. Current benchmarks inadequately assess the effects of knowledge editing, risking catastrophic forgetting and the incorporation of incorrect information [54]. Additionally, relying on generated data for personality representation may not fully capture the complexity of human traits, impairing the model's ability to replicate nuanced interactions [27]. The dependence on the quality and timeliness of training datasets can limit performance in niche scenarios, such as specific radiological cases [48]. JARVIS-1 may also struggle with scaling to complex tasks and real-time processing of multimodal inputs [23]. Current methods often lack dynamic information processing capabilities, complicating LLM integration across various applications [18]. Addressing these multifaceted challenges is essential for unlocking AI technologies' full potential, particularly in fields like psychology and machine learning, where understanding psychological principles and optimizing system designs for low latency and high throughput are crucial [4,18]. Computational and Resource Constraints The development of AI systems, particularly those using LLMs, is heavily influenced by computational and resource constraints. High resource demands for training and fine-tuning LLMs pose significant challenges, especially in environments with limited computational capabilities. The proprietary nature of parametric weights in LLMs restricts public access and adaptability, exacerbating privacy risks and social biases. The closed architecture of these models complicates efforts to address privacy concerns, such as potential leaked training data, and hampers effective bias evaluation and mitigation [66,69]. Efficient techniques like gradient transformations, such as MEND, show promise for rapid adaptations to large pre-trained models while maintaining efficacy [70]. However, implementing these techniques often requires substantial computational resources for processing feedback and optimizing prompts [71]. This is particularly evident in specialized domains like healthcare, where fine-tuning models on specific medical dialogues enhances response accuracy but demands significant computational investments [72]. The complexity of tasks and the inability to efficiently plan sub-task and API-calling orders complicate resource allocation, especially when utilizing similar APIs [73]. Generative agents, which synthesize memories to emulate human behavior, also face scalability challenges due to the intensive resources required for sophisticated memory management techniques [3]. Future research should focus on refining integration processes, enhancing memory mechanisms, and extending these methods beyond e-commerce applications. This includes developing robust detection methods, improving evaluation benchmarks, and mitigating hallucinations, which are essential for overcoming computational limitations. Enhancing retrieval techniques and exploring augmentation methods, such as those in Retrieval-Augmented Generation (RAG), across various domains could further bolster AI scalability [74]. Benchmark and human evaluations, such as those in the experimental setup for KwaiAgents, provide valuable insights into the performance of LLMs with fewer parameters, paving the way for more resource-efficient AI models [75]. Addressing these computational and resource constraints is vital for advancing AI technologies and expanding their applicability across diverse scenarios. Ethical and Interpretability Challenges Ethical and interpretability challenges in AI are particularly complex with the deployment of LLMs that generate contextually plausible yet potentially inaccurate responses. The opacity of LLM architectures can obscure understanding and accountability, raising significant ethical concerns. The GLM-130B model exemplifies efforts to enhance bilingual language modeling, yet its deployment raises questions about the ethical implications of widespread access to powerful AI technologies [32]. The reliance on user interaction data in frameworks like AgentCF highlights ethical and interpretability challenges, as these systems may inadvertently reflect biases embedded in training data [25]. Understanding and mitigating these biases is crucial for equitable AI applications. The adaptability of systems like LARP could be further improved to address these challenges, ensuring that AI systems maintain consistency in reasoning while evolving their memory for better dialogue continuity and user engagement [19]. In contexts involving real-time learning and multimodal inputs, such as JARVIS-1, ethical considerations are paramount, particularly regarding transparency and accountability [23]. The need for robust evaluation standards is emphasized, as community consensus is vital for ensuring reliability and fairness in AI systems. The limitations of benchmarks like PEAK, which require extensive datasets and struggle to generalize across different LLM architectures, further highlight the necessity for developing generalized explanation methods and improving evaluation frameworks [54]. Emerging trends indicate a focus on developing hybrid approaches that integrate model, data, and framework optimizations to enhance LLM efficiency while addressing ethical and interpretability challenges through improved transparency and reduced biases [1]. Future research could also concentrate on enhancing the adaptability of FinMem's memory system and exploring its application in various financial contexts, ensuring ethical considerations are integrated into AI development [48]. To effectively address ethical and interpretability challenges posed by AI systems, it is essential to establish comprehensive evaluation frameworks that rigorously assess and mitigate biases. This requires a nuanced understanding of social bias and fairness, alongside enhancing transparency and accountability across pre-processing, training, and post-processing stages. Advancing AI models with robust validation, alignment with human intentions, and adherence to legal and privacy norms is crucial. Exploring these facets through systematic taxonomies and ongoing research will guide the development of trustworthy AI systems that are reliable, safe, and socially responsible [4,76,17,69,77]. By refining simulation algorithms, expanding historical contexts analyzed, and exploring real-time applications for conflict resolution, researchers can ensure that AI technologies are deployed responsibly and effectively, aligning with societal values and ethical standards. Evaluation and Benchmarking Evaluation and benchmarking are critical components of AI research, providing essential insights into the performance, capabilities, and limitations of AI systems. These processes are vital for ensuring that AI models, particularly LLMs, meet the rigorous demands of real-world applications. The importance of comprehensive evaluation frameworks is underscored by the need to assess all aspects of LLM performance, including their handling of long-context inputs and integration into autonomous systems [2]. Table provides a detailed overview of the representative benchmarks utilized in the evaluation of AI systems, highlighting their size, domain, task format, and the metrics employed for performance assessment. Emerging trends in AI research emphasize the development of robust frameworks that integrate multiple compression techniques to enhance model performance while maintaining efficiency [14]. This is particularly relevant for scalable knowledge management and extraction (KME) techniques, where developing metrics to evaluate knowledge integration efficacy is crucial [74]. Furthermore, exploring standardized metrics for hallucination and investigating novel mitigation techniques are essential for addressing challenges associated with natural language generation (NLG) models [18]. The ReAct method exemplifies the importance of evaluating and benchmarking against state-of-the-art baselines to measure effectiveness in AI research, highlighting the necessity for ongoing assessment and refinement [24]. This involves creating standardized evaluation frameworks that can assess the integration of LLMs in multi-agent systems, ensuring effective collaboration and communication in complex environments. The comparison of various detection methods and improvement strategies in cognitive architectures further illustrates the need for comprehensive evaluation frameworks that assess the effectiveness of different approaches. Identifying effective strategies for mitigating privacy risks in LLMs and emphasizing the need for ongoing research to enhance privacy protections in AI models are crucial considerations in developing robust evaluation and benchmarking processes [14]. Evaluation and benchmarking are indispensable in AI research, guiding the development of more adaptable, efficient, and secure AI systems. As AI technologies evolve, the focus on enhancing LLM capabilities for personal assistance and addressing security concerns remains a priority, highlighting the necessity for ongoing research and the development of comprehensive evaluation strategies [2]. Conclusion The exploration of large language models (LLMs) showcases their profound impact on enhancing artificial intelligence, particularly through improvements in interactivity and reliability within multimodal systems. Implementing efficient compression and inference techniques enhances the feasibility of deploying LLMs on devices with limited resources, maintaining their performance and adaptability. Tools like KnowEdit offer valuable empirical insights into the knowledge frameworks of LLMs, aiding the development of more sophisticated AI applications. In the realm of mathematical reasoning, models such as ToRA demonstrate notable advancements over existing open-source alternatives, achieving higher accuracy on complex datasets like MATH. The application of multi-party computation (MPC) in conversational agent development shows promising results, achieving performances akin to fine-tuned models, although challenges remain in aggregation tasks as highlighted by evaluations on ZeroSCROLLS. The study emphasizes the critical need for continued research into multimodal large language models (MLLMs), especially their transformative potential in autonomous driving. The ALFWorld framework illustrates the significance of integrating abstract reasoning into AI systems, enhancing the ability of embodied agents to transition from abstract learning to practical execution. In healthcare, models like DoctorGLM demonstrate precise dialogue capabilities, yet require further refinement to maximize their potential. This research provides a thorough examination of resource-efficient LLMs, identifying opportunities for advancing sustainable model development. SafeEdit is highlighted as a pivotal framework for future detoxification research, contributing significantly to AI safety. KnowledgeEditor is effective in refining specific factual knowledge within language models, ensuring consistent predictions for paraphrased inputs without the need for extensive retraining. Advancements in autonomous lifelong learning are exemplified by Voyager, which achieves rapid progress compared to previous methods. Augmented Language Models (ALMs) present a promising trajectory in language modeling, addressing traditional model constraints effectively. LLM-empowered agents offer more realistic macroeconomic predictions than existing approaches, highlighting their potential in economic simulations. The SEP framework excels in generating interpretable stock predictions, surpassing conventional deep learning and LLM methods. RecMind's performance in zero/few-shot scenarios underscores its broad applicability in AI. Generative agents demonstrate the ability to create convincing individual and emergent social behaviors, validating their architectural effectiveness. Laplace-LoRA improves the calibration of fine-tuned LLMs, addressing overconfidence issues, while AgentCF enhances the simulation of personalized user behaviors, advancing next-generation user behavior modeling. The findings highlight the necessity of continuous innovation and refinement in AI technologies, underscoring the importance of persistent research to overcome current challenges and broaden the application of LLMs across various domains. Additionally, JARVIS-1's superior performance over existing agents marks a significant contribution to the field of AI and open-world agents.",
  "reference": {
    "1": "2312.03863v4",
    "2": "2310.05694v3",
    "3": "2304.03442v2",
    "4": "2312.04578v1",
    "5": "2309.14365v1",
    "6": "2307.14984v3",
    "7": "2401.03568v2",
    "8": "2308.11432v7",
    "9": "2401.03428v1",
    "10": "2311.07226v2",
    "11": "2311.12351v2",
    "12": "2303.18223v16",
    "13": "2111.01243v1",
    "14": "2202.07105v2",
    "15": "2312.12148v1",
    "16": "2311.05876v3",
    "17": "2312.06717v4",
    "18": "2312.15234v2",
    "19": "2312.17653v1",
    "20": "2310.07197v1",
    "21": "2311.16832v1",
    "22": "2306.08666v2",
    "23": "2311.05997v3",
    "24": "2210.03629v3",
    "25": "2310.09233v1",
    "26": "2310.19736v3",
    "27": "2208.10264v5",
    "28": "2302.04761v1",
    "29": "2311.12320v1",
    "30": "2311.10723v2",
    "31": "2402.01680v2",
    "32": "2210.02414v2",
    "33": "2309.16292v3",
    "34": "2401.07339v2",
    "35": "1702.08734v1",
    "36": "2308.07107v5",
    "37": "2308.07633v4",
    "38": "2308.14296v3",
    "39": "2310.10158v2",
    "40": "2310.00746v3",
    "41": "2308.09597v1",
    "42": "2308.01542v1",
    "43": "2306.07863v3",
    "44": "2310.10436v4",
    "45": "2311.01043v4",
    "46": "2304.13712v2",
    "47": "2307.03170v2",
    "48": "2311.13743v2",
    "49": "2305.14322v2",
    "50": "2307.04738v1",
    "51": "2310.16218v4",
    "52": "2305.16291v2",
    "53": "2402.03755v1",
    "54": "2401.17623v2",
    "55": "2402.09748v1",
    "56": "2306.03901v2",
    "57": "2305.10250v3",
    "58": "2308.14508v2",
    "59": "2311.10372v2",
    "60": "2401.00625v4",
    "61": "2310.03533v4",
    "62": "2310.01459v1",
    "63": "2309.01029v3",
    "64": "2307.03109v9",
    "65": "2311.05112v7",
    "66": "2310.01424v2",
    "67": "2110.05006v4",
    "68": "2402.00888v2",
    "69": "2309.00770v3",
    "70": "2110.11309v2",
    "71": "2308.02151v3",
    "72": "2304.01097v2",
    "73": "2311.11315v1",
    "74": "2312.10997v5",
    "75": "2312.04889v3",
    "76": "2308.05374v2",
    "77": "2308.10149v2"
  },
  "chooseref": {
    "1": "2401.01286v5",
    "2": "2401.15347v1",
    "3": "2401.01313v3",
    "4": "2309.05922v1",
    "5": "2311.01043v4",
    "6": "2311.10372v2",
    "7": "2310.05694v3",
    "8": "2311.05112v7",
    "9": "2303.18223v16",
    "10": "2307.03109v9",
    "11": "2308.10149v2",
    "12": "2308.11432v7",
    "13": "2402.06647v1",
    "14": "2202.07105v2",
    "15": "2308.07633v4",
    "16": "2311.12320v1",
    "17": "2306.13549v4",
    "18": "2311.12351v2",
    "19": "2401.03568v2",
    "20": "2310.09233v1",
    "21": "2010.03768v2",
    "22": "2309.14365v1",
    "23": "2402.09283v3",
    "24": "2302.07842v1",
    "25": "2306.03901v2",
    "26": "2401.00625v4",
    "27": "2309.00770v3",
    "28": "1702.08734v1",
    "29": "2310.10158v2",
    "30": "2401.07339v2",
    "31": "2309.06794v1",
    "32": "2311.16832v1",
    "33": "2403.14472v5",
    "34": "2307.04738v1",
    "35": "2309.16292v3",
    "36": "2304.01097v2",
    "37": "2308.07269v3",
    "38": "2104.08164v2",
    "39": "2305.13172v3",
    "40": "2310.02168v4",
    "41": "2312.03863v4",
    "42": "2305.10250v3",
    "43": "2310.19736v3",
    "44": "2308.10144v3",
    "45": "2309.01029v3",
    "46": "2401.03428v1",
    "47": "2307.16789v2",
    "48": "2110.11309v2",
    "49": "2311.13743v2",
    "50": "2307.03170v2",
    "51": "2308.14921v1",
    "52": "2312.04889v3",
    "53": "2304.03442v2",
    "54": "2308.10882v1",
    "55": "2210.02414v2",
    "56": "2304.13712v2",
    "57": "2306.05817v6",
    "58": "2310.01424v2",
    "59": "2308.10792v10",
    "60": "2309.13064v1",
    "61": "2311.05997v3",
    "62": "2310.16218v4",
    "63": "2309.04175v1",
    "64": "2302.04761v1",
    "65": "2309.15025v1",
    "66": "2402.01680v2",
    "67": "2308.14296v3",
    "68": "2310.10436v4",
    "69": "2312.17617v3",
    "70": "2309.01157v2",
    "71": "2308.07107v5",
    "72": "2311.07226v2",
    "73": "2310.03533v4",
    "74": "2311.10723v2",
    "75": "2312.17653v1",
    "76": "2402.03659v3",
    "77": "2308.14508v2",
    "78": "2307.03172v3",
    "79": "2308.13111v5",
    "80": "2310.02172v1",
    "81": "2310.07197v1",
    "82": "2308.08239v2",
    "83": "2308.01542v1",
    "84": "2402.09748v1",
    "85": "2310.01459v1",
    "86": "2401.17623v2",
    "87": "2302.13971v1",
    "88": "2312.12148v1",
    "89": "2401.05459v2",
    "90": "2110.05006v4",
    "91": "2312.06717v4",
    "92": "2305.04533v1",
    "93": "2402.03755v1",
    "94": "2306.08666v2",
    "95": "2310.16340v3",
    "96": "2210.03629v3",
    "97": "2111.01243v1",
    "98": "2308.16505v3",
    "99": "2303.11366v4",
    "100": "2305.14322v2",
    "101": "2312.10997v5",
    "102": "2308.02151v3",
    "103": "2308.09597v1",
    "104": "2310.00746v3",
    "105": "2311.16543v3",
    "106": "2307.14984v3",
    "107": "2402.00888v2",
    "108": "2309.01219v3",
    "109": "2307.07221v3",
    "110": "2202.03629v7",
    "111": "2310.10844v1",
    "112": "2306.07863v3",
    "113": "2401.07872v1",
    "114": "2311.08719v1",
    "115": "2304.08354v3",
    "116": "2309.17452v4",
    "117": "2312.04578v1",
    "118": "2312.15234v2",
    "119": "2310.08560v2",
    "120": "2311.11315v1",
    "121": "2311.05876v3",
    "122": "2308.05374v2",
    "123": "2304.06975v1",
    "124": "2208.10264v5",
    "125": "2305.16291v2",
    "126": "2311.17227v2",
    "127": "2401.02705v2",
    "128": "2305.14196v3"
  }
}