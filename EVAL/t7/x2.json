{
  "survey": "This survey paper provides a comprehensive review of large language model-based autonomous agents, focusing on their intersection with natural language processing, artificial intelligence, and reinforcement learning. It explores the transformative capabilities of these agents in enhancing reasoning and decision-making across diverse domains. The survey examines methodologies such as multimodal integration, tool-augmented reasoning, and reinforcement learning, highlighting their contributions to task execution and adaptability. Key findings include advancements in memory and personalization mechanisms, which improve user-agent interactions, and the integration of emerging technologies like augmented reality and blockchain, which enhance the robustness and scalability of autonomous systems. The paper also addresses ethical and safety considerations, emphasizing the importance of transparency and accountability in deploying these agents. Challenges such as scalability and performance limitations are discussed, alongside benchmarking and evaluation difficulties. Future directions propose enhancements in methodologies, expanding applications, and integrating cutting-edge technologies to optimize agent performance. The survey concludes by underscoring the pivotal role of large language model-based autonomous agents in driving innovation and efficiency, advocating for ongoing research to ensure their responsible and effective deployment across various fields.\n\nIntroduction Significance of Large Language Model Based Autonomous Agents Large language model-based autonomous agents play a crucial role in advancing various fields by enhancing reasoning capabilities and bridging high-level semantic knowledge with practical task execution. These agents effectively decompose tasks into mid-level plans in interactive environments, improving their executability. The adaptability of large language models (LLMs) allows them to provide on-demand assistance across numerous domains, significantly impacting the scalability of support services [1]. In scientific research, LLMs have markedly improved efficiency and capabilities, particularly in chemistry-related tasks, as demonstrated by models like ChemCrow [2]. They also address the limited generalizability in recommendation systems by offering solutions that extend beyond task-specific datasets [3]. The integration of LLMs with external tools and reasoning capabilities enhances their performance, filling knowledge gaps and enabling sophisticated functionalities. The development of LLM-augmented Autonomous Agents (LAAs) presents viable alternatives to traditional models, especially in dialogue use cases, thus broadening their applicability [4]. Furthermore, the potential of LLMs as autonomous agents necessitates robust evaluation frameworks to ensure effective deployment and collaboration in interactive environments [5]. In sensitive domains like healthcare and education, large language model-based conversational agents exhibit promising implications, although challenges such as toxicity must be addressed [4]. Recent advancements highlight the exceptional capabilities of LLMs in natural language processing and comprehension, providing novel approaches to interfacing with complex systems. However, LLMs are prone to errors in step-by-step reasoning when faced with complex problems. The creation of intelligent models capable of solving intricate tasks underscores the transformative impact of LLMs in the pursuit of Artificial General Intelligence (AGI) [1]. Their role in driving innovation across various fields necessitates robust evaluation frameworks to ensure effective deployment and collaboration [5]. Grounding LLMs in expansive environments significantly enhances their task planning capabilities, particularly in robotics [6], while the integration of reasoning and acting amplifies their potential in interactive decision-making [7]. Motivation Behind the Survey This survey is motivated by the need to address limitations in traditional language models, particularly regarding bounded input processing [8]. Large Language Models (LLMs) offer novel opportunities to overcome these constraints, especially in complex task planning within large-scale environments [9]. The survey aims to explore methodologies that integrate reasoning and action components, enhancing LLMs' capabilities in executing complex control tasks within embodied agents constrained by transformer architectures [10]. A critical aspect of this survey is the reassessment of AI's role in educational contexts, where traditional instructional methods may be challenged by new technologies, such as AI-driven software testing [11]. Additionally, the survey investigates how LLMs can leverage environmental feedback to improve reasoning capabilities in embodied tasks [6]. This exploration is vital for developing sophisticated benchmarks that can assess LLMs' emotional responses in a nuanced manner, addressing existing inadequacies [4]. The survey also addresses the shortcomings of current epidemic models, which fail to accurately reflect human behaviors and decision-making processes during crises [12]. By analyzing how well language models replicate findings from human subject research, this survey aims to close knowledge gaps and explore the practical applications of LLMs in downstream NLP tasks. The need for a more effective planning approach that combines LLMs' strengths in handling uncertainty with traditional planners' efficiency further motivates this survey [7]. Through this comprehensive review, the survey identifies areas for future research and development, ultimately enhancing the capabilities and applications of large language model-based autonomous agents. Objectives of the Paper This survey provides a comprehensive evaluation and synthesis of the transformative capabilities of large language model-based autonomous agents across diverse domains, including natural language processing, artificial intelligence, and reinforcement learning. A primary objective is to introduce a new testing framework, the Turing Experiment, which assesses the effectiveness of language models in simulating human behavior, thereby addressing their real-world applicability [3]. The survey explores advancements in reasoning tasks, categorizing current methods into train-time and test-time scaling, which are crucial for understanding and evaluating LLMs' performance [13]. Significantly, the paper investigates the generative agent-based modeling approach, simulating individual decision-making and behavior during epidemics, thus demonstrating the application of LLMs in dynamic and unpredictable environments [12]. The integration of LLMs with traditional planning techniques, such as the LLM-DP framework, is discussed to enhance speed and efficiency in solving embodied tasks [7]. Furthermore, augmenting LLMs with external memory can enhance their ability to simulate complex algorithms, broadening their usability across various tasks [8]. The survey examines methodologies like ERPLM, enabling LLMs to utilize environmental feedback for improved reasoning and planning [6]. By serving as a comprehensive guide for practitioners, the survey discusses various LLMs, their training data, and practical applications in NLP tasks, acting as a valuable resource for researchers and developers [2]. It also highlights models such as ChatGPT that manage multiple AI models effectively, providing insights into their operational dynamics and interoperability [1]. Finally, the paper introduces EmotionBench, an evaluation tool designed to assess the empathy capabilities of large language models, fostering improved interactions with emotional nuances [4]. Collectively, these objectives lay the groundwork for future advancements and effective governance in deploying large language model-based autonomous agents across diverse applications. Structure of the Survey This survey is meticulously structured to provide a comprehensive exploration of large language model-based autonomous agents, organized into distinct sections that facilitate a coherent understanding of the subject. The survey begins with an Introduction, outlining the significance and objectives of large language model-based autonomous agents, followed by a detailed Background and Definitions section elucidating key concepts and terminologies essential for understanding subsequent discussions. The Methodologies and Architectures section delves into the technical components and frameworks employed in developing these agents, including reasoning models and learning-to-reason techniques, alongside automated data construction and test-time scaling [13]. This is complemented by an examination of Applications, discussing real-world implementations across various domains and showcasing the practical impact of these agents. The survey further addresses the Challenges inherent in deploying large language model-based autonomous agents, focusing on scalability, ethical considerations, and technical limitations. The discussion on Future Directions explores the transformative potential of large language models across various domains, such as natural language processing, scientific research, and AI ecosystems. It highlights emerging trends, including the integration of LLMs with autonomous scientific research capabilities, practical deployment in real-world applications, and enhancement of reasoning and factuality through multiagent debate. Furthermore, it explores the innovative use of foundation models alongside millions of APIs for task completion and the Algorithm of Thoughts approach for advancing idea exploration and reasoning efficiency. These advancements promise significant breakthroughs in methodologies and applications, paving the way for more robust, versatile, and efficient AI systems [14,2,15,16,17]. The survey concludes with a Conclusion that synthesizes insights gained and proposes recommendations for future research. Additionally, it incorporates socio-cognitive abilities by organizing content into stages, reflecting their theoretical grounding and applicability in cultural contexts [18]. This structured approach ensures a thorough and nuanced understanding of the evolving landscape of large language model-based autonomous agents.The following sections are organized as shown in . Background and Definitions Large Language Models (LLMs) Large Language Models (LLMs) are pivotal in advancing autonomous agents, serving as foundational architectures capable of generating human-like text and facilitating complex reasoning processes [6]. Their capacity to process extensive textual datasets enhances their utility across domains such as natural language processing and robotics task planning [11]. By incorporating external memory, LLMs address the limitations of deterministic models, which are typically constrained by finite inputs [8]. LLMs demonstrate versatility through integration into frameworks like Libro, which automates test case generation from bug reports using natural language processing [6]. They have been optimized for adversarial contexts, improving robustness in executing actions based on textual descriptions, as evidenced by the WebShop benchmark [4]. Additionally, LLMs bolster the interconnection of diverse AI systems, reinforcing their significance within broader AI architectures [11]. Their generative capabilities enable decision-making simulations, particularly in frameworks like Generative Agent-Based Epidemic Modeling (GA-BEM), showcasing adaptability in dynamic environments [4]. This adaptability is further enhanced by LLM-DP, which merges LLM reasoning with traditional planning to optimize task execution [6]. Evaluations of interactive processes and user experiences, especially in human-LM interactions, provide insights into the practical utility and performance of LLMs in real-world applications [4]. These evaluations underscore the transformative impact of LLMs on autonomous agents, highlighting the need for ongoing research to maximize their potential. Autonomous Agents Autonomous agents are computational entities capable of independently executing tasks in dynamic environments by perceiving, deciding, and acting towards specific goals with minimal human intervention. They utilize AI techniques to adapt to environmental changes, with applications ranging from simple rule-based systems to advanced entities capable of sophisticated decision-making and scientific experimentation. By leveraging LLMs, these agents enhance fields like biology, chemistry, and industrial automation, autonomously executing complex tasks such as catalyzed cross-coupling reactions and flexible production processes. Integrating language models with digital twins and industrial systems allows these agents to orchestrate intricate functions for agile production. Additionally, socio-cognitive abilities from developmental psychology enhance their social intelligence and interaction capabilities [18,17,19,20]. LLM-augmented Autonomous Agents (LAAs) excel in complex decision-making tasks by merging reasoning with language understanding, broadening their applicability [21]. They can synthesize code meeting functional requirements, evaluated by benchmarks assessing Python code generation from docstrings [22]. Moreover, these agents simulate social behaviors through social simulacra, prototyping populated interactions based on specific goals and rules [23]. Challenges in developing autonomous agents include understanding character intentions and determining actions in complex contexts, as seen in benchmarks like Tachikuma, which focus on multi-character interactions [24]. Agents are also designed to follow language instructions for intricate tasks across various websites, explored in the Mind2web benchmark [25]. A critical challenge is filtering harmful content and ensuring consistent communication within conversational contexts [26]. These challenges necessitate robust mechanisms for safe and effective operation in diverse environments. As these agents evolve, their integration with emerging technologies will further enhance their capabilities, leading to more sophisticated applications. Natural Language Processing (NLP) Natural Language Processing (NLP) is crucial for developing autonomous agents, enabling them to comprehend, generate, and interact using human language effectively. The ability to generalize from limited examples is vital for these agents, allowing adaptation to new tasks with minimal training data [27]. This capability is supported by datasets encompassing 58 NLP tasks related to social knowledge, including humor, sarcasm, sentiment, and trustworthiness [28], providing a rich foundation for training models to interpret complex social cues. Large datasets containing trillions of tokens support natural language understanding and generation tasks, essential for engaging in meaningful dialogues and complex reasoning [29]. NLP is pivotal in evaluating chatbot performance, particularly in assessing the accuracy and relevance of responses from LLMs [30]. Benchmarks for dialogue scenarios focus on helpfulness and safety, ensuring reliable and non-harmful interactions [31]. A toxicity score quantifies harmfulness in outputs, emphasizing the importance of ethical standards in NLP applications [32]. The effective deployment of LLMs in real-world NLP tasks addresses both their capabilities and limitations [2]. As NLP evolves, its integration with autonomous agents will enhance their interaction capabilities, making them more adaptable across various domains. Artificial Intelligence (AI) Artificial Intelligence (AI) encompasses computational techniques aimed at creating systems that perform tasks requiring human intelligence. For autonomous agents, AI enables perception, reasoning, and action within complex environments, facilitating independent and effective operation [33]. AI-driven autonomous agents leverage LLMs to enhance decision-making, simulating human-like interactions in real and simulated scenarios [33]. The synergy between AI and LLMs has led to advancements in social bots, autonomous agents interacting with users online. Metrics for evaluating these bots are selected to assess their impact and behavior, highlighting the influence of AI-driven agents on social dynamics and communication patterns [34]. By harnessing AI, autonomous agents navigate complex tasks, adapt to new information, and engage in meaningful interactions, broadening their applicability. AI's significance is further emphasized by its capacity to process vast data volumes, enabling continuous learning and evolution. This adaptability is crucial for deploying autonomous agents in dynamic environments, enhancing real-time decision-making and problem-solving through advanced LLM integration for improved communication and task execution. LLMs based on transformer architectures empower agents to autonomously design, plan, and execute scientific experiments while offering self-adaptive capabilities for operational adjustments. By leveraging advanced conversation features and decision-making capabilities, agents navigate rapidly changing conditions, facilitating cooperation and reducing coordination challenges in multiagent systems [35,17]. As AI technologies advance, the capabilities of autonomous agents will further expand, paving the way for sophisticated applications and interactions across diverse fields. Reinforcement Learning (RL) Reinforcement Learning (RL) is a key machine learning paradigm training agents to make sequential decisions through interaction with dynamic environments, receiving feedback in the form of rewards or penalties to optimize objectives [36]. A significant challenge in RL is the slow convergence of agents in environments with large action spaces, complicating the learning process and necessitating sophisticated strategies for efficiency [37]. RL application in autonomous agents is often hindered by unclear reward functions and environment dynamics, complicating the design of effective recommendation systems [38]. Methodologies such as integrating high-level subgoal knowledge improve RL efficiency by providing structured guidance during learning [39]. The REMEMBERER framework illustrates an evolvable LLM-based agent that enhances RL learning by incorporating long-term experience memory [40]. A core obstacle in advancing RL methodologies is the lack of a unified approach utilizing language as a reasoning tool to address multiple RL challenges [20]. This gap underscores the need for frameworks integrating language and reasoning capabilities to enhance RL agent performance. Proximal Policy Optimization (PPO) is a notable RL method optimizing a surrogate objective function through multiple epochs of minibatch updates, improving learning efficiency and robustness [41]. Benchmark experiments evaluating diverse agents, including those based on reinforcement learning, imitation learning, and pre-trained models, highlight their adaptability to new tasks without extensive training data [42]. These findings emphasize the need for continuous improvement in RL methodologies to broaden their applicability. As RL evolves, its integration with LLMs and autonomous agents will further enhance their capabilities, leading to sophisticated applications in dynamic environments. In recent years, the development of autonomous agents has been significantly influenced by various methodologies and architectures. To better understand this evolution, it is essential to consider the hierarchical organization of these methodologies, which can be visualized in . This figure illustrates the categorization of key frameworks and applications across several domains, including multimodal integration, tool-augmented reasoning, reinforcement learning, memory personalization, generative frameworks, and external knowledge integration. By examining this structured representation, we can gain insights into how these diverse approaches converge to enhance the capabilities of autonomous agents. Methodologies and Architectures Multimodal Integration and Reasoning Multimodal integration and reasoning are essential for enhancing autonomous agents' capabilities, enabling them to synthesize information from diverse sources and navigate complex environments. HuggingGPT exemplifies this approach by integrating multiple AI models to tackle intricate tasks, highlighting the significance of multimodal frameworks in problem-solving [1]. The LLM-DP framework further demonstrates this by combining large language models (LLMs) with traditional planners to optimize task execution in dynamic settings [7]. Additionally, ERPLM leverages natural language feedback to refine decision-making and skill execution, underscoring the role of iterative learning in multimodal systems [6]. Incorporating emotional appraisal theory into benchmarks like EmotionBench provides insights into LLMs' emotional responses, enhancing evaluations of interaction quality and emotional intelligence [4]. Moreover, generative AI models in epidemic modeling simulate real-world behaviors, emphasizing multimodal integration's role in replicating complex social dynamics [12]. Collectively, these methodologies illustrate the transformative potential of multimodal integration and reasoning in advancing autonomous agents across various domains. Tool-Augmented and Chain-of-Thought Reasoning Tool-augmented and chain-of-thought reasoning methodologies enhance autonomous agents by integrating structured reasoning processes with external tools. The ChatCoT framework combines chain-of-thought reasoning with tool usage, enabling LLMs to perform step-by-step reasoning while utilizing various resources [43]. The Chain of Hindsight method refines this process by fine-tuning language models with feedback-derived sentence sequences, improving learning from diverse inputs [44]. SelfCheck enhances LLM performance by allowing models to assess and correct their reasoning through a voting system on multiple reasoning paths, ensuring reliable outcomes [45]. ViperGPT innovatively composes vision-and-language models into subroutines via code generation, facilitating Python code execution for visual queries [46]. The Graph of Thoughts (GoT) framework organizes LLM thoughts into a graph, enhancing reasoning and problem-solving capabilities [47]. Additionally, the Self-Consistency strategy employs a decoding method that samples various reasoning paths, selecting the most consistent answer to improve decision accuracy [48]. The Chain of Thought prompting technique provides demonstrations of reasoning steps, guiding models in generating their reasoning processes [49]. Together, these methodologies demonstrate the potential of integrating structured reasoning with external tools, significantly enhancing the reasoning capabilities of LLMs and paving the way for sophisticated autonomous agents. Reinforcement Learning and Interaction Strategies Reinforcement Learning (RL) and interaction strategies are crucial for advancing autonomous agents, enabling dynamic adaptation and optimization of decision-making processes. The LLM-Planner employs few-shot planning techniques, showcasing RL's potential in optimizing planning tasks with minimal training data [50]. The ReAct method allows LLMs to generate reasoning traces and actions in an interleaved manner, integrating reasoning and action components to enhance task-solving capabilities [51]. Introspective examinations of decision-making trajectories emphasize self-assessment's role in refining methodologies [52]. SayPlan utilizes a classical path planner and iterative replanning, refining initial plans based on real-time feedback, illustrating adaptive planning's importance in dynamic environments [9]. Libro applies RL principles in ranking generated test cases for automated bug reproduction, demonstrating RL's applicability in optimizing testing processes [53]. Proximal Policy Optimization (PPO) alternates between data sampling and optimizing a surrogate objective, exemplifying iterative learning in RL [41]. The integration of RL in task planning and model selection, as seen in HuggingGPT, underscores strategic model selection's importance in optimizing task execution [1]. Collectively, these strategies illustrate the transformative potential of integrating structured reasoning with adaptive learning mechanisms, paving the way for sophisticated autonomous agents. Memory and Personalization Mechanisms Memory and personalization mechanisms are vital for enhancing the adaptability of autonomous agents, enabling them to retain critical information and tailor interactions to individual users. The MemoryBank framework incorporates a memory updating mechanism based on the Ebbinghaus Forgetting Curve, allowing LLMs to selectively forget less significant memories while reinforcing important ones, simulating human-like memory processes [54]. The Memory Sandbox method enhances interaction quality by enabling users to manipulate memories, facilitating more personalized interactions [55]. Augmenting LLMs with external databases enables complex multi-hop reasoning, as demonstrated by methods generating SQL instructions for database interactions [56]. The integration of associative read-write memory with the Flan-U-PaLM 540B model exemplifies memory augmentation, allowing for sophisticated reasoning without modifying model weights [8]. Collectively, these mechanisms underscore the importance of dynamic memory management and user-driven customization in advancing autonomous agents, facilitating enriched user experiences across diverse applications, including psychological counseling and complex reasoning tasks. Generative and Simulation-based Frameworks Generative and simulation-based frameworks enhance autonomous agents' capabilities by modeling complex environments and simulating interactions with high fidelity. These frameworks leverage computational agents that mimic human behavior in interactive applications, enabling dynamic memory synthesis and planning behaviors. Transformer-based LLMs facilitate autonomous scientific research, allowing agents to design and execute complex experiments while ensuring safety measures [17,57]. The Tachikuma benchmark focuses on multi-character and novel object interactions, capturing log data from real-time communications during gameplay, providing insights into agent capabilities in complex environments [24]. ViperGPT integrates generative and simulation methodologies by composing visual models into subroutines for code generation and execution [46]. The SimplyRetrieve framework combines a GUI and API for retrieval-augmented generation, emphasizing efficient integration of private data into generative processes [58]. The Multimodal64 methodology highlights the significance of simplifying action spaces for enhanced learning efficiency in autonomous agents [59]. Collectively, these frameworks illustrate the transformative potential of integrating generative capabilities with simulation methodologies, advancing autonomous agents in various domains. Integration with External Knowledge and Tools Integrating external knowledge and tools is fundamental for enhancing autonomous agents' capabilities, enabling them to perform complex tasks with increased accuracy. Toolformer autonomously incorporates external tools into predictions, allowing LLMs to leverage APIs for improved task performance [60]. This approach emphasizes the importance of integrating existing models and APIs to optimize task execution [16]. By incorporating external knowledge, agents can expand their functional capabilities, facilitating seamless interaction with complex systems. As autonomous agents evolve, the integration of external knowledge and tools, including LLMs and digital twins, will play a crucial role in advancing their capabilities, enabling intelligent planning and execution across diverse fields. This integration allows agents to autonomously design and execute complex tasks, such as catalyzed cross-coupling reactions, paving the way for adaptive and versatile applications [17,19]. Applications Multimodal Reasoning and Visual Understanding Multimodal reasoning and visual understanding are crucial for autonomous agents, enabling them to process and integrate information from diverse sensory inputs. The MM-REACT framework epitomizes advancements in multimodal reasoning, addressing complex tasks and enhancing visual understanding capabilities [61]. By integrating visual and textual data, this framework augments decision-making processes. Utilizing large language models (LLMs) alongside visual data processing techniques empowers agents to perform sophisticated reasoning tasks involving images, videos, and text. This integration facilitates navigation in complex environments, informed decision-making, and intuitive user interactions. Embodied reasoning frameworks enable agents to engage in human-like interactions, such as smartphone gestures, while the society of minds approach allows for debating responses, improving factual validity and reducing erroneous outputs. In-context learning and human feedback further enhance adaptability to new tasks and environments, promoting interactive user collaboration [20,36,15,62,59]. Multimodal reasoning and visual understanding significantly impact healthcare, robotics, and education, where agents provide personalized assistance based on visual cues and contextual information. As technology progresses, multimodal frameworks will enhance autonomous agents' adaptability and effectiveness, driven by LLMs' ability to refine reasoning and factual accuracy through multi-agent debate and autonomously design complex scientific experiments. Implementation in smartphone applications showcases their potential for executing complex tasks with human-like interactions. Additionally, embedding language models into reinforcement learning agents enhances exploration and skill reuse, fostering innovative applications across various fields [17,15,59,20]. Code Generation and Software Development The integration of autonomous agents in code generation and software development has advanced with LLMs, enhancing programming capabilities. Models like Codex demonstrate marked improvements in code generation tasks, underscoring LLMs' transformative impact on software development [22]. These models automate code synthesis, enabling efficient generation of functional code snippets and streamlining the programming process. Despite advancements, challenges persist in managing complex coding tasks. The self-collaboration framework, where multiple agents assume distinct roles to collaboratively address code generation tasks, tackles LLMs' limitations in intricate programming scenarios [63]. This approach enhances autonomous agents' ability to manage complex tasks effectively. LLMs also function as valuable testing assistants, providing conversational frameworks that improve developer interactions with testing processes [64]. This versatility illustrates LLMs' role in enhancing software development, offering tools for testing and debugging that improve software quality and efficiency. Recent advancements showcase how autonomous agents and LLMs revolutionize code generation and software development. By serving as automated testing assistants, developers benefit from improved testing processes requiring less specialized expertise. Furthermore, LLMs' integration into industrial automation systems, such as modular production facilities, enables intelligent planning and control through digital twins and service interfaces, facilitating agile production processes. These technologies highlight LLMs' potential to handle undefined tasks and improve programming efficiency [19,64]. Robotics and Autonomous Systems The integration of autonomous agents in robotics and autonomous systems underscores LLMs' transformative potential in enhancing task execution and personalization. TidyBot exemplifies this application by personalizing household cleanup assistance based on user preferences, improving satisfaction and efficiency [65]. Experiments in simulated robotic manipulation environments, where robots stack objects, illustrate reinforcement learning techniques' effectiveness in optimizing robotic functions, allowing adaptation to dynamic environments and efficient execution of complex tasks [20]. Methodologies like SayPlan ground complex task plans in expansive environments, facilitating robust task execution [9]. This integration of planning strategies with autonomous systems optimizes performance in dynamic settings. Additionally, the Introspective Tips method enhances LLM decision-making without fine-tuning, showcasing autonomous agents' potential to refine decision-making independently [52]. Advancements in robotics and autonomous systems highlight autonomous agents' impact on task execution, personalization, and decision-making capabilities. By incorporating advanced planning and learning methodologies, these agents leverage LLMs and multimodal frameworks to improve applications across domains, including robotic manipulation, personalized assistance, and industrial automation. These developments pave the way for agile and adaptive systems in household robotics, smart factory production, and scientific research [19,20,65,17,59]. Education and Personalized Learning The integration of autonomous agents in education and personalized learning environments has advanced significantly, particularly through LLMs that enhance interactivity and adaptability. SiliconFriend, an LLM-based chatbot utilizing the MemoryBank framework, exemplifies improvements in long-term companionship capabilities, offering empathetic responses and understanding user personalities [54]. This application underscores LLMs' transformative potential in providing personalized educational experiences tailored to individual learning needs. The Reflective Learning Persona (RLP) framework introduces dynamic AI personas capable of nuanced negotiations and mental health support, showcasing LLMs' versatility in creating adaptive educational environments [66]. These personas facilitate meaningful dialogues that support learners' educational journeys. Autonomous agents in personalized learning extend beyond traditional settings, offering innovative lifelong learning and skill development solutions. By harnessing LLMs' advanced reasoning and decision-making capabilities, agents deliver tailored educational content that dynamically adapts to learners' evolving needs across domains. Despite challenges in instruction following and decision-making, improvements in training with high-quality multi-round alignment data enhance performance, fostering a more personalized educational experience [67,68]. As these technologies evolve, their integration will further enhance educational tools' effectiveness and personalization, paving the way for impactful learning experiences. Healthcare and Genomics Autonomous agents in healthcare and genomics show significant potential, enhancing accessibility and analysis of complex medical data. LLM integration facilitates sophisticated tools for processing vast genomic information, improving disease analysis and prediction accuracy and efficiency. The Math Agents framework exemplifies this by leveraging LLMs to enhance mathematical accessibility in genomics, particularly in Alzheimer's disease analysis [69]. This framework highlights LLMs' transformative impact in facilitating complex computations and data analysis, providing insights into disease mechanisms and therapeutic interventions. Beyond data analysis, autonomous agents offer innovative personalized medicine and patient care solutions. Leveraging LLMs' capabilities, agents customize medical recommendations and treatment plans to align with individual patient profiles, enhancing healthcare delivery precision and effectiveness. This approach benefits from LLMs' ability to integrate domain-specific expert knowledge and utilize experiential learning for continuous improvement. LLMs operate in complex environments, harnessing reasoning and decision-making abilities to provide personalized healthcare solutions, advancing Artificial General Intelligence (AGI) in medical applications [68,2,64,70,67]. Autonomous agents in genomic research explore complex genetic interactions and identify novel biomarkers, advancing predictive genomics and personalized health strategies. As LLMs and autonomous agents evolve, their application in healthcare and genomics is poised to revolutionize complex medical data processing and interpretation. Transformer-based LLMs, with emergent scientific research capabilities, integrate into intelligent agent systems, enabling autonomous scientific experiment design, planning, and execution. In genomics, mathematical embeddings and generative AI analyze causal relations in longitudinal health records, addressing challenges like Alzheimer's disease. Generative agents in epidemic modeling mimic real-world behaviors, enhancing dynamic system modeling. These advancements offer promising opportunities for research and clinical practice, improving vast dataset management and utilization in personalized medicine and precision health [19,69,17,59,12]. By integrating analytical frameworks with personalized care approaches, these agents promise to revolutionize healthcare delivery and genomic research, leading to more effective and individualized medical solutions. Social Computing and Community Interaction Autonomous agents significantly impact social computing and community interaction by leveraging LLMs to facilitate complex social dynamics and enhance user engagement. LLM integration in social computing applications enables agents to simulate human-like interactions, providing personalized and context-aware communication in community settings [23]. These agents adeptly interpret social cues and respond to user inputs, fostering meaningful and adaptive interactions. Frameworks like SocialSimu highlight autonomous agents' transformative potential in creating social simulacra, serving as prototyping techniques to populate prototypes based on predefined goals and rules [23]. This approach emphasizes simulating social interactions to understand and predict community behaviors, allowing agents to adapt strategies to diverse contexts. Autonomous agents increasingly manage social bots in online environments, with metrics carefully selected to assess their impact and behavior [34]. This application underscores the significance of understanding AI-driven agents' influence on social dynamics and communication patterns, facilitating effective community interaction and engagement. Leveraging LLMs' advanced learning and reasoning capabilities, autonomous agents navigate complex social tasks, adapt to new information, and engage in meaningful interactions. This integration enhances communication and decision-making skills, enabling agents to utilize external models, tools, or APIs for problem-solving. Consequently, these agents' applicability broadens across domains, aligning with AGI efforts and enhancing multiagent system autonomy in dynamic environments [35,70]. As social computing technologies advance, integrating autonomous agents will further enhance their ability to engage in complex interactions, making them more adaptable and effective in fostering community interaction and collaboration. Challenges Scalability and Performance Limitations The scalability and performance limitations of autonomous agents using large language models (LLMs) pose significant challenges to their broad application. Inefficiencies in current methods often lead to increased costs due to the rising number of query requests, particularly in scientific applications where autonomous task execution is constrained [1,7]. Existing benchmarks fail to adequately capture the complexities of LLM-augmented Autonomous Agents (LAAs), necessitating more sophisticated frameworks for accurate capability assessment in dynamic environments [42]. The reliance on exemplar quality in chain-of-thought reasoning further complicates scalability [13]. Bottlenecks arise from sequential reasoning and tool observation fetching, increasing token consumption and hindering real-time application [8]. Balancing fast, intuitive responses with slow, thoughtful planning remains critical, often leading to suboptimal task completion [71]. High data demands in current planning methods restrict agents' ability to quickly learn and adapt [6], while resource-intensive fine-tuning of LLM parameters may not generalize well across tasks [10]. Effective grounding of task plans in large environments is crucial for enhancing scalability [9], and integrating LLM-generated plans into executable actions remains a challenge [7]. The complexity of reinforcement learning methods like TRPO limits practical applications [41]. Addressing these challenges is essential for developing robust, adaptable applications capable of complex tasks across diverse environments, leveraging advanced LLM capabilities [72,15,16,17,59]. Ethical and Safety Considerations Deploying autonomous agents powered by LLMs requires careful consideration of ethical and safety issues to ensure responsible use. Concerns include the potential for LLMs to generate toxic outputs, influenced by persona assignments [11], highlighting the need for robust content filtering mechanisms. Reliance on external sources, as seen in ReAct methodologies, introduces variability based on source quality, impacting agent reliability [51]. The use of synthetic data in models like GPT-4 poses challenges in capturing real-world complexities, affecting system robustness [12]. High computational resources and costly human annotation required for adversarial training present obstacles in developing ethically sound models [2]. Ethical issues also arise from subjective human evaluations of LLM empathy, which may introduce bias [4], and oversimplification of complex social contexts in simulations [3]. Ensuring transparency, accountability, and responsible technology use is crucial for the safe deployment of autonomous agents, paving the way for ethical applications across various domains [17,73,19,15]. Benchmarking and Evaluation Challenges Table provides a detailed overview of existing benchmarks, emphasizing the challenges in evaluating autonomous agents across diverse domains and tasks. Benchmarking and evaluating autonomous agents present challenges in ensuring metrics accurately reflect agent capabilities across diverse tasks. Inconsistencies in existing benchmarks may not effectively measure chatbot performance, leading to unreliable evaluations [30]. The dependency on language model quality affects agents' ability to generalize, necessitating robust evaluation methodologies [20]. As agents are deployed in complex environments, existing benchmarks may fail to capture the full spectrum of capabilities, highlighting the need for sophisticated frameworks like AgentBench to assess reasoning and decision-making abilities [17,67]. Establishing standardized benchmarks with comprehensive evaluation criteria is crucial for accurate assessment, enabling agents to excel in diverse domains while addressing safety and alignment challenges [17,67,30]. Reasoning and Planning Complexities Reasoning and planning complexities significantly impact autonomous agents' effectiveness. Reliance on log data, as seen in the Tachikuma benchmark, may not capture interaction nuances, affecting evaluation accuracy [24]. Limitations in frameworks like Vipergpt in addressing intricate visual queries highlight the need for sophisticated reasoning modules [46]. Balancing intuitive responses with thoughtful planning is challenging, often resulting in suboptimal task performance. Integrating foundational models like ChatGPT with domain-specific models can enhance task-solving capabilities, as seen in initiatives like TaskMatrix.AI and OpenAGI [70,16,15]. Continuous research is needed to enhance autonomous agents' capabilities, enabling them to autonomously design and execute scientific experiments, perform complex tasks in smartphone applications, and explore dynamic environments efficiently [17,59,20]. Future Directions Enhancements in Methodologies and Architectures Advancing methodologies and architectures for autonomous agents and LLMs is crucial for improving their capabilities across domains. A key focus is optimizing reasoning and tool usage integration within LLMs, as demonstrated by HuggingGPT, enhancing task planning algorithms and expanding model integration for efficiency [1]. Ensuring task planning methodologies balance executability and correctness is vital for reliable completion [2]. Instruction following and training data quality assessment are essential for refining autonomous capabilities [11]. Optimizing sampling processes to reduce computational overhead and exploring self-consistency beyond basic reasoning can improve LLM adaptability [4]. In mental health applications, enhancing LLM reliability and understanding user dependency can improve interaction quality [4]. Integrating LLMs with domain-specific models, particularly in industrial engineering, can significantly enhance problem-solving capabilities, akin to human intelligence synergy. This integration broadens LLM applicability in complex fields such as oil and gas engineering and factory automation. Strategies like multi-agent debate and reinforcement learning from task feedback can enhance reasoning, factual validity, and adaptability, advancing AGI and autonomous scientific research [2,15,17,74,70]. Optimizing MRKL architectureâ€™s reasoning capabilities through integration and additional knowledge sources is vital for future research. Memory-augmented models need optimization of their architecture and exploration of diverse applications [8]. Expanding benchmarks and refining orchestration strategies for LAAs will enable comprehensive evaluations and deployments. Enhancing memory management techniques for generative agents can expand their social interaction range. Improving safety measures for intelligent agents and exploring scientific domain applications remains crucial [2]. Optimizing exemplar selection and investigating scalability of chain-of-thought prompting can enhance reasoning capabilities. Exploring LLM applicability in MAS scenarios can refine communication and problem-solving abilities. These enhancements promise to advance autonomous agent methodologies and architectures, facilitating deployment across diverse applications and domains. Refining thought generation and applying frameworks to complex problem-solving tasks is essential [2]. Prioritizing learning-to-reason techniques and dataset quality refinement will further advance LLM reasoning capabilities. Expanding Applications and Domains Expanding applications and domains for autonomous agents powered by LLMs represents a promising research avenue. LLM versatility allows application across domains from complex web tasks to nuanced human behaviors. Future efforts should refine models to incorporate sophisticated interaction patterns, mitigate negative outputs, and enhance adaptability in dynamic environments [75], enabling agents to perform complex tasks accurately. In web applications, the Mind2web benchmark emphasizes dataset expansion and model performance improvement for intricate web tasks [25], crucial for developing agents capable of navigating complex online environments. The Reflective Learning Persona (RLP) framework highlights opportunities for introspective process refinement and exploration across fields [66], facilitating agents that adapt to diverse scenarios and provide personalized interactions. Conversational applications offer significant expansion opportunities; refining datasets and fine-tuning processes can improve model performance in diverse dialogue scenarios [31]. This refinement enhances conversational capabilities, allowing meaningful and adaptive interactions. The survey discusses LLM open challenges and future research directions, outlining a roadmap for expanding applications and domains [13]. Expansion efforts promise to advance autonomous agent capabilities, enabling deployment across varied applications. Focusing on model refinement, dataset expansion, and performance enhancement will foster robust autonomous systems integrating LLMs and foundation models to tackle complex challenges across environments, such as scientific research, catalyzed cross-coupling reactions, and interfacing with APIs. This approach aims to advance capabilities in fields from NLP to biology, chemistry, and programming, addressing safety and compatibility issues to prevent misuse [17,16]. Robustness and Scalability Enhancing robustness and scalability of autonomous agents utilizing LLMs involves refining methodologies, improving feedback mechanisms, and expanding application domains. Refining feedback mechanisms to enhance LLM adaptability in dynamic environments ensures agents effectively respond to changing conditions and maintain performance consistency [6]. Expanding benchmarks to incorporate diverse conversational scenarios provides a comprehensive evaluation framework, crucial for developing agents capable of navigating complex environments. Recent AI and machine learning advances through LLM integration and collaborative multi-agent systems necessitate developing standardized protocols for API integration. Addressing compatibility and accessibility challenges is key to leveraging these models' full potential, enhancing robustness and scalability. Connecting foundation models with diverse APIs, as demonstrated in TaskMatrix.AI and ToolLLaMA, facilitates adaptive task executions across domains [76,19,35,16,17]. Future research should prioritize enhancing language model agents' performance by improving instruction-following and decision-making abilities, alongside exploring benchmark scalability in real-world applications. Robust evaluation frameworks like AgentBench are needed to assess reasoning and decision-making in complex environments, emergent LLM capabilities in scientific research, and challenges in grounding language in interactive web environments like WebShop. Multi-agent debate and E2E benchmarking present promising avenues for improving factuality, reasoning, and accuracy in language model systems [15,17,67,30,42]. Enhancing test generation methodologies and addressing data contamination issues are critical for advancing frameworks. Refining interaction metrics and expanding datasets to include diverse interaction scenarios will facilitate comprehensive evaluations and deployments. Emerging directions promise to enhance robustness and scalability of autonomous agents. Integrating LLMs with capabilities in scientific research, reinforcement learning, industrial automation, and multi-agent debate, these agents are poised to excel in domains like NLP, biology, chemistry, robotics, and smart manufacturing. Integration of language models for reasoning, planning, and execution, combined with improved factuality and strategic reasoning through multi-agent collaboration, enables agents to tackle complex tasks and adapt to new challenges, ensuring safe deployment across applications [17,19,15,20]. Refining methodologies, enhancing evaluation frameworks, and exploring applications will pave the way for robust and adaptable autonomous systems. Integration with Emerging Technologies Integrating emerging technologies into autonomous agents powered by LLMs is pivotal for future advancements, enhancing capabilities and expanding applications across domains. Incorporating advanced machine learning techniques, such as reinforcement learning, optimizes agent performance and adaptability in dynamic environments [36], enabling efficient, accurate task execution. Emerging technologies like AR and VR offer significant potential for enhancing interaction capabilities, allowing agents to engage users in immersive environments and provide personalized assistance based on real-time feedback [23]. This integration improves user experience, enabling context-aware interactions. Advancements in quantum computing and neuromorphic engineering present opportunities for optimizing LLM computational processes, enhancing data processing and reasoning efficiency [38]. These technologies can overcome limitations in processing speed and scalability, paving the way for robust systems. Integration extends to developing sophisticated data management frameworks, such as blockchain, enhancing security and transparency in interactions between agents and users [21]. Blockchain ensures data integrity and confidentiality, fostering trust and reliability in operations. Emerging technologies promise to advance autonomous agent capabilities, enabling deployment across domains and applications. Leveraging technologies like LLMs, digital twins, and modular automation systems, future research will enhance autonomous systems' capabilities. Advancements will enable robust, efficient systems addressing complex challenges in dynamic environments. LLMs can facilitate intelligent planning and control in scientific research and industrial production, while multi-agent debate techniques improve reasoning and factuality. These technologies promise to create agile, flexible systems with applications from scientific experiments to smart factory operations [17,19,15]. Conclusion Large language model-based autonomous agents have demonstrated a profound impact across various fields, notably in enhancing reasoning, decision-making, and task execution capabilities. The incorporation of advanced memory mechanisms, such as Memory Sandbox, has significantly improved user interaction by refining contextual understanding and personalization. This advancement calls for deeper investigations into memory systems to further optimize user-agent engagements. Achieving a remarkable 91\\",
  "reference": {
    "1": "2303.17580v4",
    "2": "2304.13712v2",
    "3": "2208.10264v5",
    "4": "2308.03656v6",
    "5": "2212.09746v5",
    "6": "2207.05608v1",
    "7": "2308.06391v1",
    "8": "2301.04589v1",
    "9": "2307.06135v2",
    "10": "2305.02412v2",
    "11": "2302.03287v3",
    "12": "2307.04986v1",
    "13": "2212.10403v2",
    "14": "2308.10379v3",
    "15": "2305.14325v1",
    "16": "2303.16434v1",
    "17": "2304.05332v1",
    "18": "2307.07871v2",
    "19": "2304.14721v4",
    "20": "2307.09668v1",
    "21": "2308.05960v1",
    "22": "2107.03374v2",
    "23": "2208.04024v1",
    "24": "2307.12573v1",
    "25": "2306.06070v3",
    "26": "2307.15810v1",
    "27": "2005.14165v4",
    "28": "2305.14938v2",
    "29": "2302.13971v1",
    "30": "2308.04624v1",
    "31": "2307.09288v2",
    "32": "2304.05335v1",
    "33": "2308.04026v1",
    "34": "2307.10337v1",
    "35": "2307.06187v1",
    "36": "2302.00763v1",
    "37": "2307.15833v1",
    "38": "1812.10613v3",
    "39": "2301.12050v2",
    "40": "2306.07929v2",
    "41": "1707.06347v2",
    "42": "2207.01206v4",
    "43": "2305.14323v3",
    "44": "2302.02676v8",
    "45": "2308.00436v3",
    "46": "2303.08128v1",
    "47": "2308.09687v4",
    "48": "2203.11171v4",
    "49": "2201.11903v6",
    "50": "2212.04088v3",
    "51": "2210.03629v3",
    "52": "2305.11598v1",
    "53": "2209.11515v3",
    "54": "2305.10250v3",
    "55": "2308.01542v1",
    "56": "2306.03901v2",
    "57": "2304.03442v2",
    "58": "2308.03983v1",
    "59": "2312.13771v2",
    "60": "2302.04761v1",
    "61": "2303.11381v1",
    "62": "2304.10750v2",
    "63": "2304.07590v3",
    "64": "2306.05152v2",
    "65": "2305.05658v2",
    "66": "2305.12647v1",
    "67": "2308.03688v3",
    "68": "2308.10144v3",
    "69": "2307.02502v1",
    "70": "2304.04370v6",
    "71": "2305.17390v2",
    "72": "2302.07842v1",
    "73": "2204.01691v2",
    "74": "2304.14354v1",
    "75": "2308.03313v2",
    "76": "2307.16789v2"
  },
  "chooseref": {
    "1": "2308.04030v1",
    "2": "2308.02439v1",
    "3": "2112.15594v4",
    "4": "2303.18223v16",
    "5": "2307.03109v9",
    "6": "2308.04026v1",
    "7": "2308.10379v3",
    "8": "2305.16291v2",
    "9": "2307.10337v1",
    "10": "2302.07842v1",
    "11": "2305.12487v1",
    "12": "2304.05376v5",
    "13": "2306.03901v2",
    "14": "2308.05960v1",
    "15": "2308.04624v1",
    "16": "2112.09332v3",
    "17": "2307.02485v2",
    "18": "2302.02676v8",
    "19": "2201.11903v6",
    "20": "2308.10204v4",
    "21": "2302.03287v3",
    "22": "2308.01423v2",
    "23": "2302.00763v1",
    "24": "2303.16434v1",
    "25": "2305.20076v3",
    "26": "2307.15833v1",
    "27": "2204.01691v2",
    "28": "2301.12050v2",
    "29": "2305.14938v2",
    "30": "2308.06391v1",
    "31": "2308.02773v1",
    "32": "2307.01848v1",
    "33": "2304.05332v1",
    "34": "2308.03656v6",
    "35": "2304.11477v3",
    "36": "2306.03604v8",
    "37": "2305.10250v3",
    "38": "2307.04986v1",
    "39": "2212.09746v5",
    "40": "2107.03374v2",
    "41": "2308.03688v3",
    "42": "2308.10144v3",
    "43": "2308.01552v1",
    "44": "2307.16789v2",
    "45": "2210.04964v2",
    "46": "1812.10613v3",
    "47": "2304.03442v2",
    "48": "2303.08774v6",
    "49": "2308.09687v4",
    "50": "2307.06135v2",
    "51": "2304.13712v2",
    "52": "2303.17580v4",
    "53": "2305.14325v1",
    "54": "2304.10750v2",
    "55": "2304.14354v1",
    "56": "2207.05608v1",
    "57": "2305.11598v1",
    "58": "2303.11504v2",
    "59": "2005.14165v4",
    "60": "2201.07207v2",
    "61": "2302.04761v1",
    "62": "2308.14296v3",
    "63": "2209.11515v3",
    "64": "2306.07929v2",
    "65": "2205.11916v4",
    "66": "2307.09288v2",
    "67": "2302.13971v1",
    "68": "2212.04088v3",
    "69": "2308.07540v1",
    "70": "2307.02502v1",
    "71": "2301.04589v1",
    "72": "2308.01542v1",
    "73": "2306.06070v3",
    "74": "2306.00924v1",
    "75": "2303.11381v1",
    "76": "2205.00445v1",
    "77": "2312.13771v2",
    "78": "2301.12868v3",
    "79": "2206.14796v2",
    "80": "2307.00184v4",
    "81": "2305.05658v2",
    "82": "2305.02412v2",
    "83": "2305.16867v2",
    "84": "1707.06347v2",
    "85": "2308.03313v2",
    "86": "2210.03629v3",
    "87": "2305.14992v2",
    "88": "2308.16505v3",
    "89": "2305.12647v1",
    "90": "2303.11366v4",
    "91": "2308.02151v3",
    "92": "2305.18323v1",
    "93": "2307.06187v1",
    "94": "2304.07590v3",
    "95": "2203.11171v4",
    "96": "2308.03983v1",
    "97": "2208.04024v1",
    "98": "2307.14984v3",
    "99": "2305.17390v2",
    "100": "2307.12573v1",
    "101": "2308.00245v3",
    "102": "2307.07871v2",
    "103": "2304.08354v3",
    "104": "2305.14323v3",
    "105": "2307.09668v1",
    "106": "2304.14721v4",
    "107": "2306.05152v2",
    "108": "2212.10403v2",
    "109": "2207.01206v4",
    "110": "2304.05335v1",
    "111": "2305.10601v2",
    "112": "2305.14279v4",
    "113": "2307.15810v1",
    "114": "2305.13455v3",
    "115": "2208.10264v5",
    "116": "2308.06921v1",
    "117": "2308.00436v3",
    "118": "2303.08128v1",
    "119": "2304.04370v6"
  }
}