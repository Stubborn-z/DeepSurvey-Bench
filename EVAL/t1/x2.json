{
  "survey": "This survey paper provides a comprehensive examination of Large Language Models (LLMs) within the domains of natural language processing (NLP), artificial intelligence (AI), and neural networks. It highlights the transformative impact of LLMs on technology and society, underscoring their capabilities in language understanding and generation, as well as their applications across various industries. The paper explores architectural innovations, algorithmic breakthroughs, and advancements in training efficiency and scalability that have driven the evolution of LLMs. It also addresses emergent abilities and interpretability challenges, emphasizing the need for robust evaluation frameworks. The survey identifies ongoing research challenges such as scalability, data quality, model interpretability, and robustness, alongside ethical considerations including bias, misinformation, privacy risks, and resource utilization. By focusing on Pretrained Foundation Models (PFMs) and excluding proprietary models, the paper ensures a structured examination of LLMs' underlying technologies and their profound impact across sectors. Future research directions are suggested to enhance LLM capabilities, optimize training processes, and align models with human values, paving the way for advancements in AI and NLP. This survey serves as a vital resource for understanding the current state and future potential of LLMs, grounded in a robust discussion of existing literature and empirical findings.\n\nIntroduction Significance of Large Language Models Large Language Models (LLMs) have become pivotal in advancing natural language processing (NLP) and artificial intelligence (AI), significantly enhancing language understanding and generation capabilities [1]. Innovations in architecture and pretraining methodologies have improved representation quality, allowing for the efficient handling of novel language tasks with minimal examples, similar to human capabilities [2]. This evolution signifies a departure from traditional NLP approaches, highlighting the transformative nature of LLMs [3]. Models like LaMDA underscore the importance of safety and factual grounding in conversational AI, advancing technological developments [2]. LLMs have revolutionized conversational technologies, as seen in models like ChatGPT, which excel in generating AI-generated content (AIGC) [3]. These advancements have prompted discussions about their effectiveness relative to human experts, underscoring their societal implications and the need for a deeper understanding of their capabilities [4]. Furthermore, LLMs play a crucial role in producing natural language explanations for AI predictions, fostering trust in AI systems [5]. The impact of LLMs extends beyond NLP, influencing various technological domains. The introduction of models like BLOOM offers an open-access alternative, promoting equitable access to advanced language modeling capabilities [6]. Efficient foundation language models, such as lightweight open models inspired by Gemini, competently compete with state-of-the-art models using publicly available datasets, addressing the demand for scalable alternatives to curated corpora [7]. The performance of LLMs is heavily contingent on the quality and size of their pretraining datasets, emphasizing the necessity for comprehensive datasets [7]. Moreover, addressing memory constraints through model parallelism is essential for training super-large deep learning models, which have demonstrated remarkable performance [6]. LLMs enhance reasoning capabilities through language model prompting, contributing significantly to this emerging field [1]. Their broad impact facilitates advancements across diverse sectors, including software development and academic research, where LLMs are vital for code understanding and generation. Models like phi-3-mini highlight the importance of deploying efficient language models on mobile devices, crucial for AI applications in smartphones [7]. Embodied language models further integrate real-world continuous sensor modalities, linking words with percepts, thus enhancing their significance in robotics and AI. In reinforcement learning, LLMs improve the communication of complex goals using human preferences, which is critical for practical applications [1]. Advanced models like GPT-4 address the growing demand for AI systems capable of handling multimodal inputs, particularly in professional and academic contexts [3]. Additionally, models such as GLM-130B target challenges in training stability and efficiency, offering high-performance, open-source bilingual models that match or surpass existing models like GPT-3. LLMs are crucial for achieving generalization across multiple AI tasks, driving advancements in various industry applications. Their significance is underscored by their ability to transform industries, enhance communication, and improve human-computer interaction. However, challenges related to privacy, utility, and fairness persist due to their tendency to memorize training data, necessitating ongoing research to address these issues [4]. The development of multilingual models further enhances generalization capabilities to non-English languages, broadening the global applicability of LLMs. Scope of the Survey This survey is meticulously defined to explore the development, capabilities, and applications of Large Language Models (LLMs) within natural language processing, artificial intelligence, and neural networks, while intentionally excluding unrelated AI applications and technologies that do not contribute to content generation [1]. It aims to provide a comprehensive overview of LLMs by focusing on architectural innovations, algorithmic breakthroughs, and emergent abilities, as well as their transformative impacts on technology and society. The survey specifically addresses challenges posed by insufficiently large and diverse datasets in text mining, particularly in academic contexts [3]. Discussions encompass mainstream architectures of pre-trained language models (PLMs), adaptation strategies for various input data, and fine-tuning methods for text generation, while excluding applications of text generation outside the realm of PLMs [1]. Additionally, it covers applications of reasoning in language models, particularly in medical diagnosis and negotiation, and includes key tasks, datasets, and methods related to mathematical reasoning and deep learning [3]. The survey also incorporates advancements in dense retrieval techniques leveraging PLMs, focusing on architecture, training, indexing, and integration, while excluding traditional heuristic-based retrieval methods. An in-depth analysis of the evolution of generative models from GANs to ChatGPT is provided, emphasizing foundational components and recent advancements in AI-generated content (AIGC). Both unimodal interactions, such as text and image generation, and multimodal interactions, including cross-modal applications exemplified by models like Kosmos-1, are explored. The survey highlights the role of large-scale models in enhancing content creation by improving intent extraction and generation quality while discussing open challenges and future directions in the field [8,9,10,11]. Various prompting methods, pre-trained language models, and tuning strategies are examined, while traditional supervised learning methods that do not involve prompting are excluded. The necessity of benchmarks for evaluating and comparing LLM performance across tasks and domains is also addressed, contributing to the broader AI research landscape. Throughout the survey, the misconception of LLMs as thinking entities rather than sophisticated algorithms processing language is clarified, emphasizing the importance of understanding their functional scope and limitations. By focusing on Pretrained Foundation Models (PFMs) in natural language processing, computer vision, and graph learning, the survey excludes specific implementations or proprietary models not widely studied in the literature. This structured approach facilitates a focused examination of LLMs and their underlying technologies, highlighting their profound impact across various sectors through advanced data selection techniques that enhance pre-training efficiency and accuracy, optimize resource consumption, and leverage dense retrieval methods for improved semantic representation and relevance matching in information systems [12,13,14]. Structure of the Survey This survey is organized into eight distinct sections, each aimed at providing a thorough exploration of Large Language Models (LLMs) and their implications across various domains. The introduction outlines the significance of LLMs in natural language processing (NLP), artificial intelligence (AI), and neural networks, emphasizing their transformative impact on technology and society [1]. The second section delves into the background and definitions, offering detailed explanations of essential terms and the historical evolution of LLMs. The third section examines the development of LLMs, focusing on architectural innovations, algorithmic breakthroughs, and advancements in training efficiency, scalability, and interpretability. The fourth section explores the capabilities and applications of LLMs, discussing their proficiency in language understanding, generation, and domain-specific applications, as well as the integration of multiple modalities. In the fifth section, the impact of LLMs on technology and society is analyzed, showcasing their transformative effects on various industries and improvements in communication and human-computer interaction. The sixth section identifies ongoing research challenges, including scalability, data quality, model interpretability, and robustness [4]. The seventh section is dedicated to examining ethical considerations, such as bias, misinformation, privacy risks, resource utilization, and alignment with human values. Finally, the conclusion reflects on the survey's key points, discussing future research directions and opportunities within the LLM landscape. This logical and systematic approach ensures that readers gain a comprehensive understanding of the current state and future potential of LLMs, grounded in an in-depth discussion of existing literature and empirical findings. The survey highlights the innovative paradigm of reasoning in LLMs, where models are trained to emulate complex human reasoning processes through techniques such as reinforcement learning and test-time scaling, significantly enhancing their reasoning capacity. It also explores the impact of careful data selection and pre-training strategies, such as document de-duplication and diversification, on improving LLM performance and efficiency. By examining these advancements, the review provides insights into the foundational background and technical components driving LLM development while identifying open challenges and future research directions in the field [13,1].The following sections are organized as shown in . Background and Definitions Key Concepts and Definitions The foundation of Large Language Models (LLMs) is built upon pivotal concepts and technological advancements that define their functionality. Central to these models is the transformer architecture, distinguished by its self-attention mechanisms, which facilitate the identification of significant words in sequences, thereby addressing limitations inherent in traditional recurrent models by capturing long-term dependencies [2]. LLM development operates through two main phases: the pre-training phase, where models assimilate general language patterns from extensive datasets, and the fine-tuning phase, which refines these models for specific applications, optimizing task performance across diverse domains [15]. The process benefits immensely from large, diverse, and high-quality datasets, where benchmarks extract high-quality monolingual datasets from extensive web crawl data [16]. Subword tokenization, converting raw sentences into subword units, enhances LLM efficiency in processing unstructured text, although challenges remain concerning ambiguity in segmentation. Effective training strategies address issues in neural machine translation, such as domain mismatch and handling rare words [2]. Rigorous benchmarks are vital for multilingual models, assessing their capacity to navigate various languages and contexts and evaluating the impact of architectures and pretraining objectives on zero-shot generalization [3]. Technical domains present challenges in utilizing context lengths that surpass the original training sequences, with alignment of LLMs with human values critical to meet safety and responsibility standards, particularly in culturally specific contexts [5]. In multimedia applications, synthesizing narrative with visual elements is crucial for enhancing zero-shot capabilities in multimodal tasks through instruction tuning. Dialogue systems face hurdles in generating human-like responses, necessitating benchmarks tailored to single-turn dialogue contexts to enhance conversational AI [2]. Recurrent Neural Networks (RNNs) encounter obstacles in training speed and optimization when managing extensive sequential data. Natural language prompts are core components for training and querying within NLP, emphasizing interpretation of textual instructions for cross-task generalization. Evaluation of hyperparameters and training data sizes significantly impacts model performance, often overlooked in existing frameworks [16]. Prompt-based learning explores enhancing language model performance in NLP tasks, incorporating reasoning steps to bolster capabilities. Challenges in generating consistent natural language explanations require instruction-tuned models and synthetic instruction data to advance understanding. The JEC-QA dataset exemplifies complexities in domain-specific tasks like legal question answering. Benchmarks like GLUE address models' proficiency across linguistic tasks, promoting advancement in natural language understanding beyond superficial input-output correlations [17,18,19]. Addressing duplicate data in training sets is crucial to prevent models from memorizing rather than generating original content, with unintended memorization leading to verbatim text emissions from training data. Aligning deep learning approaches with human standards is vital, particularly enhancing mathematical reasoning in AI systems [15]. Understanding these fundamental aspects is essential to improving LLM performance, despite challenges like coherence in lengthy text generation, emphasizing the importance of distributed vector representations in capturing syntactic and semantic relationships. Historical Development and Evolution The historical progression of Large Language Models (LLMs) is marked by key milestones shaping their evolution and capabilities. The transformational introduction of the transformer architecture revolutionized sequence processing through self-attention mechanisms, addressing scalability limitations of recurrent neural networks to efficiently manage long-range dependencies and enhance performance across NLP tasks [20,21]. Significant developments in pre-training techniques have evolved from static to dynamic methods, improving model effectiveness through complex linguistic pattern and semantic capture [22,23]. Data deduplication study reflects the critical impact of comprehensive data management on model performance, shifting toward models demonstrating robust generalization and language understanding across tasks and domains [24]. Expanding and diversifying training datasets have been instrumental, with benchmarks like LAMBADA emphasizing the importance of broader discourse context [25]. Datasets such as S2ORC, offering large-scale structured data with metadata, facilitate sophisticated analyses and zero-shot learning scenarios [26,27]. Methodological advancements such as LayerNorm optimize computational efficiency, enhancing training speed and performance [20]. Subword tokenization methods improve models' processing capacity, aiding in tasks like neural machine translation against challenges presented by rare words [28]. The trajectory of LLMs is marked by efforts to boost generalization performance and learning dynamics, with approaches such as [29] offering insights into overcoming overfitting. Benchmarks like JEC-QA, simulating tasks requiring refined logical reasoning, extend LLM application scopes, encompassing domains like legal question answering [30]. Development of Large Language Models Recent advancements in Large Language Models (LLMs) have been driven by innovations in architecture and methodology, significantly enhancing their performance and versatility. Key developments include data-efficient pre-training techniques, such as document de-duplication and intelligent data selection, which improve training efficiency and accuracy in downstream tasks. Enhancements in reasoning capabilities, exemplified by \"thought\" sequences and reinforcement learning applications, have expanded LLMs' capacity to address complex tasks. As illustrated in , the hierarchical categorization of these advancements highlights crucial architectural innovations, algorithmic breakthroughs, training efficiency, scalability improvements, emergent abilities, and interpretability challenges. This structured overview encapsulates the developments that have enhanced LLM capabilities and functionalities. Table offers a comprehensive comparison of various methods that have contributed to these advancements, emphasizing the critical aspects of architectural innovations, algorithmic breakthroughs, and training efficiency and scalability. Despite numerous modifications to the Transformer architecture, only a few have demonstrated substantial benefits, emphasizing the importance of implementation details for performance improvements [31,13,14,1]. This section explores these foundational changes that have propelled advancements in language processing technologies. Architectural Innovations Architectural innovations have been crucial in enhancing LLM capabilities across linguistic and domain-specific challenges. The transformer architecture revolutionized sequence processing with self-attention mechanisms, effectively managing long-range dependencies and addressing recurrent neural networks' limitations [2]. Models like LaMDA refine this architecture to improve contextual understanding and response generation in dialog applications. The Receptance Weighted Key Value (RWKV) method merges efficient Transformer training with RNN inference capabilities, enabling flexible architecture [32]. Other advancements, such as the Sparse Mixture of Experts (SMoE) architecture [33] and the Structured State Space sequence model (S4) [34], optimize training processes and enhance model adaptability. LoRA introduces trainable rank decomposition matrices into layers of frozen pre-trained Transformer models, facilitating efficient task adaptation [35]. Colossal-AI's unified interface for scaling training processes enables multiple parallel strategies that significantly enhance large-scale model training speed [36]. The benchmark by [6] integrates deduplication and language identification with additional filtering to improve dataset quality. GLaM's architecture supports scaling up to 1.2 trillion parameters while reducing training costs to one-third of GPT-3 and halving computational flops for inference [37]. Sparse Transformers utilize sparse factorizations of the attention matrix to effectively model long sequences, introducing novel approaches for handling extensive input data [38]. The shift from static methods to dynamic approaches like BERT is highlighted in pre-training methods [22]. DeepSpeed-Chat optimizes the RLHF training process for models like ChatGPT, emphasizing human-centric architectural design [39]. The integration of encoder and decoder models into a single prefix-LM, along with simplifying learning methods into a unified algorithm, significantly enhances the training process [40]. MXNet's hybrid approach allows auto differentiation and efficient computation across devices, from mobile to distributed GPU clusters [41]. Sequence parallelism and selective activation recomputation optimize memory usage and computational efficiency during large transformer model training [42]. RFA introduces a linear time and space attention mechanism that approximates the softmax function using random feature methods, replacing conventional softmax attention in transformers [43]. BigBird's sparse attention mechanism reduces memory dependence from quadratic to linear, enabling longer sequence processing [44]. Visual ChatGPT integrates multiple Visual Foundation Models to support multi-step interactions and visual feedback [45]. GLM-130B introduces unique training strategies that enhance stability and efficiency, distinguishing it from previous models [46]. Algorithmic Breakthroughs Algorithmic breakthroughs have greatly enhanced LLM functionality and efficiency, enabling them to tackle complex tasks with greater precision. As illustrated in , these breakthroughs can be categorized into several key areas: pretraining and optimization, reinforcement learning, and multitask learning and decoding strategies. Each category highlights significant advancements that contribute to the enhanced functionality and efficiency of LLMs. Generalized autoregressive pretraining methods, such as XLNet, optimize expected likelihood across all permutations of factorization order, facilitating effective bidirectional context learning and improving language understanding [47]. This innovation addresses challenges inherent in traditional pre-training techniques that often struggle with contextual ambiguity. Optimization methods have progressed with Adafactor, estimating per-parameter second moments using aggregated sums, reducing memory requirements and enhancing computational efficiency [48]. Random feature methods, as in RFA, offer an alternative to conventional softmax attention by approximating the softmax function in linear time and space, paving the way for efficient attention mechanisms [43]. Reinforcement learning has emerged as a key advancement, particularly with Deep Reinforcement Learning from Human Preferences (DRLHP), which trains agents using human preferences instead of traditional reward signals, enhancing adaptability and performance [49]. Safe Reinforcement Learning from Human Feedback (Safe RLHF) formalizes safety concerns as an optimization task, maximizing reward functions while adhering to specified cost constraints, addressing critical safety and ethical considerations [4]. In multitask learning, the T-Zero benchmark systematically converts supervised datasets into prompted forms, improving zero-shot performance evaluation across tasks [50]. The Minerva model exemplifies advancements in quantitative reasoning tasks, showcasing improved performance in complex reasoning scenarios [15]. Mamba integrates selective state-space models into a streamlined architecture, eliminating the need for attention or MLP blocks and focusing on efficient information processing [51]. ILMP introduces a simple intra-layer model parallel approach that enhances training efficiency without extensive modifications to existing frameworks, demonstrating potential for scalable model training [52]. Contrastive decoding optimizes a contrastive objective comparing outputs from large and small models to ensure plausibility in generated text [53]. This method emphasizes coherence in language generation tasks. BigBird's sparse attention mechanism allows efficient processing of longer sequences by reducing memory requirements from quadratic to linear [44]. Nucleus Sampling refines text generation by sampling from the dynamic nucleus of the probability distribution, focusing on more reliable outputs [54]. These algorithmic breakthroughs underscore the significance of continuous innovation in enhancing LLM functionality. They demonstrate improved preprocessing through advanced document de-duplication and diversification, increased training efficiency via data-efficient methods like Ask-LLM and Density sampling, and enhanced context management with dynamic pre-training technologies. These advancements can accelerate training by up to 70 Training Efficiency and Scalability Advancements in training efficiency and scalability are crucial for optimizing LLMs to handle extensive datasets and complex tasks with enhanced precision. Sparse Transformers represent a significant breakthrough by reducing the attention matrix's complexity from quadratic to \\(O(n )\\), thus improving training efficiency and scalability for long sequences [38]. This reduction in computational complexity facilitates more effective processing of extensive input data, broadening the deployment of LLMs across applications. Random Feature Attention (RFA) enhances scalability by approximating the softmax function in linear time and space, enabling the handling of longer sequences while maintaining performance [43]. Similarly, Mamba efficiently processes long sequences without relying on attention mechanisms, achieving high throughput and linear scalability, thus enhancing the model's capacity to manage extensive input data [51]. Intra-layer Model Parallelism (ILMP) enables the training of large transformer models by distributing computations across multiple GPUs, overcoming memory constraints and ensuring efficient scaling [52]. The fastText model achieves performance comparable to deep learning classifiers while being significantly faster, completing tasks in under a minute for large datasets, demonstrating rapid training and deployment potential [55]. Contrastive Decoding (CD) innovatively combines the strengths of large and small language models by employing a contrastive objective to guide text generation, distinguishing it from traditional decoding methods reliant solely on larger models [53]. This method underscores the importance of coherence and plausibility in language generation tasks, contributing to improved scalability. Benchmark tests of various state-of-the-art neural language models focus on their scaling behavior, emphasizing the importance of understanding the scalability of different architectures [56]. The introduction of a scaling law for compute optimality incorporates the effects of data repetition, differing from previous benchmarks that typically focus on unique data, thus providing insights into efficient resource utilization [57]. Safe Reinforcement Learning from Human Feedback (Safe RLHF) enhances training efficiency by decoupling human preferences for helpfulness and harmlessness, leading to clearer training signals [4]. The paper SlimPajama highlights the importance of diverse data configurations in improving training efficiency and scalability of large language models, emphasizing the need to optimize pretraining datasets for better model outcomes [16]. Leveraging vast amounts of data for training language models is critical for understanding and scoring commonsense knowledge, thereby enhancing models' generalization capabilities across diverse applications [58]. Emergent Abilities and Interpretability Exploring emergent abilities and interpretability within LLMs reveals a complex interplay of scale, architecture, and multimodal integration that shapes model capabilities. Emergent abilities manifest as models scale, significantly enhancing performance and sample efficiency across various tasks [8]. These abilities, often unpredictable, arise uniquely in larger architectures and are influenced by evaluation metrics rather than being inherent characteristics [59]. This distinction highlights the necessity of careful metric selection for accurately assessing model capabilities. Multimodal large language models (MLLMs) illustrate emergent abilities by integrating text, images, and audio, enabling reasoning capabilities that surpass traditional unimodal models. The challenges posed by current models in effectively processing and integrating information across multiple modalities underscore the demand for architectural innovations that facilitate seamless multimodal integration [60]. Benchmarks evaluating MLLM reasoning capabilities demonstrate their potential in understanding and generating responses based on both text and images, showcasing the transformative impact of emergent abilities [8]. The RWKV model represents architectural innovation by efficiently managing long sequences with linear scaling, offering flexibility to function as both a Transformer and an RNN [61]. This dual functionality emphasizes the potential for architectural advancements to unlock emergent capabilities, further illustrating the significance of complex interactions within large models [62]. Controlled training environments, as suggested by findings from [63], provide critical insights into the development and scaling of LLMs, indicating that continued scaling and architectural refinement may unveil additional capabilities. Interpretability remains a significant challenge in harnessing the full potential of LLMs. The emergent ability of models to generate explanations introduces interpretability issues, particularly when inconsistencies occur in these explanations [64]. This complexity underscores the need for robust interpretability frameworks capable of decoding model outputs and offering coherent insights into decision-making processes. The Focused Transformer (FoT) enhances interpretability by differentiating between relevant and irrelevant keys in a structured (key, value) space, mitigating distraction issues [65]. Dense retrieval methods enhance interpretability by improving information retrieval systems, facilitating more transparent and accountable language models [12]. Instruction tuning processes, exemplified by FLAN, improve generalization to unseen tasks, increasing model versatility and interpretability [66]. Findings from [67] indicate that both model architecture and pretraining objectives significantly influence zero-shot generalization, with specific configurations yielding superior performance and contributing to improved interpretability. Capabilities and Applications The expansion of Large Language Models (LLMs) has led to a broad spectrum of applications, capitalizing on their advanced language understanding and generation skills. This section delves into LLMs' foundational aspects, particularly their ability to generate contextually relevant and coherent text, crucial for various applications. We will explore the architectural innovations and training methodologies that underlie these capabilities, setting the stage for a comprehensive examination of their practical applications. Language Understanding and Generation LLMs exhibit outstanding language understanding and generation capabilities, driven by architectural advancements, extensive datasets, and improved algorithms. They excel in producing coherent text, essential for dialogue systems and content creation. The LAMBADA dataset, comprising diverse narrative texts, evaluates text understanding by assessing the prediction of the last word in narratives, highlighting context's role in language comprehension [25]. LaMDA enhances dialogue applications by generating safe and factually accurate responses, integrating safety measures to ensure reliability [2]. Nucleus Sampling improves machine-generated text quality, producing outputs akin to human writing in diversity and coherence [54]. The Minerva model achieves state-of-the-art performance in quantitative reasoning, demonstrating LLMs' proficiency in structured commonsense reasoning tasks [15]. Sparse Transformers excel in modeling long sequences, generating diverse and coherent outputs, crucial for handling extensive input data [38]. Fine-tuning LLMs using human feedback enhances their ability to follow instructions and generate desired outputs, emphasizing adaptability and performance improvement [5,16]. Domain-Specific Applications LLMs have advanced significantly in domain-specific applications, leveraging architectures and expansive datasets to address challenges in healthcare, education, and industry. In healthcare, LLMs are integral to OpenQA systems, answering complex medical questions and aiding diagnostics [68]. In education, LLMs enhance multilingual capabilities, performing tasks like summarization and machine translation, contributing to inclusive educational tools [69]. Industry applications are exemplified by AlphaCode, which generates diverse programming solutions, showcasing LLMs' ability to tackle complex coding challenges and improve software productivity [70]. illustrates the domain-specific applications of LLMs, highlighting their roles in healthcare, education, and industry. Each sector benefits from specialized LLM capabilities, such as OpenQA systems in healthcare, multilingual educational tools, and code generation in industry. In image generation, the Cogview model uses advanced transformer mechanisms to create images from text descriptions, essential for creative industries [71]. The Pushshift Reddit dataset, comprising billions of comments, enables comprehensive studies on social dynamics and sentiment analysis, offering insights into societal trends [72]. The competitive performance of models like OLMo illustrates LLMs' potential in research applications, providing tools for analyzing complex datasets [6]. Multimodal and Domain-Specific Models The integration of multiple modalities in LLMs has led to significant advancements in processing and generating content across diverse domains. Multimodal models like PandaGPT effectively process and integrate multimodal inputs, producing coherent outputs across various tasks [60]. This integration is crucial for models' capabilities to understand and generate content that reflects real-world complexities, where information often comes in multiple forms. The dataset introduced in [73] is pivotal for evaluating vision-language models designed for multimodal inputs, providing a framework for assessing their ability to process diverse data types. The benchmark discussed in [74] expands this evaluation by incorporating text and image inputs, emphasizing the need for seamless integration for broader applicability. Visual ChatGPT exemplifies multimodal potential by enabling interactive dialogue with text and images, facilitating complex visual tasks [45]. In domain-specific applications, LLMs' multimodal capabilities enhance their ability to meet specific needs. In healthcare, integrating medical images with patient records improves diagnostic capabilities. In education, multimodal models create interactive learning experiences by combining textual explanations with visual aids, akin to aligning books with movies for richer storytelling. Models like Kosmos-1 exemplify the convergence of language and multimodal perception, enabling tasks like visual question answering and dialogue, facilitating cross-modal knowledge transfer [10,75,76,8,12]. These advancements highlight LLMs' transformative potential in addressing complex challenges across sectors, paving the way for future innovations in artificial intelligence and natural language processing. Impact on Technology and Society Large Language Models (LLMs) have profoundly impacted technology and society by transforming industry operations and redefining interaction paradigms. This section examines how LLMs enhance efficiency and innovation across various sectors, reshaping technological landscapes and influencing societal dynamics. The subsequent subsection will detail their transformative effects on industries, illustrating the breadth and depth of their applications. Transformative Effects on Industries LLMs have revolutionized industries by optimizing operational efficiency, fostering innovation, and redefining interaction paradigms. As illustrated in , the transformative effects of large language models on industries can be categorized into three main areas: operational efficiency, complex reasoning, and multilingual adaptability. Advancements in Pretrained Foundation Models (PFMs) such as CodeGen2 streamline complex tasks like program synthesis, boosting productivity [40]. In machine translation, systems like the Google Neural Machine Translation (GNMT) have significantly improved translation quality, reducing errors by 60\\ Complex reasoning capabilities are advanced through techniques like 'Chain of Thought Prompting', achieving state-of-the-art results in reasoning benchmarks [77]. Mathematical models like Llemma demonstrate significant advancements in problem-solving [78], supported by training verifiers that improve multi-step reasoning performance [79], impacting fields reliant on complex problem-solving, such as theoretical physics and engineering. LLMs' multilingual adaptability is evident as finetuning on English tasks improves performance across both English and non-English tasks [24], beneficial in industries with prevalent language diversity. The open-source release of models like GLM-130B further exemplifies contributions to bilingual language processing [46]. Integrating visual processing with conversational AI, models like Visual ChatGPT enhance user interaction through dialogue capabilities incorporating visual feedback [45], crucial for sectors like retail and customer service. Innovations in sequence modeling, exemplified by Mamba, demonstrate superior throughput and efficiency compared to traditional transformers [51], while models like fastText facilitate real-time application deployment due to their speed and efficiency [55], vital for efficient data handling in finance and telecommunications. Optimizing language model scaling is crucial for maximizing utility, with research suggesting larger models trained on smaller datasets can yield improved performance within fixed computational resources [56]. Training language models with repeated data remains effective up to certain thresholds, beyond which additional compute yields diminishing returns [57], highlighting strategic data optimization's importance in industries relying on data-driven insights. Advancements in Communication and Human-Computer Interaction LLMs have enhanced communication and human-computer interaction by providing sophisticated tools for seamless interactions across platforms. Their integration into communication systems improves information exchange quality and efficiency, enabling natural user experiences. Visual ChatGPT, for example, integrates visual feedback with textual dialogue, enhancing interactive capabilities in customer service and virtual assistant applications [45]. Dialogue systems like LaMDA focus on generating safe and factually accurate responses, crucial for maintaining trust and reliability in conversational AI [2], ensuring interactions are coherent, contextually relevant, and adhere to ethical standards, thus enhancing user satisfaction. Multimodal models like PandaGPT demonstrate LLMs' potential in processing diverse inputs, allowing comprehensive reasoning capabilities surpassing traditional unimodal models [60]. Their ability to handle text, images, and audio simultaneously enables nuanced responses, advancing human-computer interaction. In machine translation, LLMs markedly improve translation quality, facilitating seamless communication across linguistic barriers. Systems like GNMT reduce translation errors by 60\\ Models like AlphaCode, designed for competitive programming, showcase LLMs' ability to tackle complex coding challenges and enhance productivity in software development [70], highlighting their potential to automate coding tasks, reduce development time, and improve code quality, facilitating efficient human-computer interaction in technical domains. Research Challenges Scalability and Computational Efficiency Scalability and computational efficiency are critical challenges in developing Large Language Models (LLMs), driven by architectural complexities and resource demands. Full attention mechanisms often lead to computational inefficiency, restricting sequence length processing capabilities, thus limiting LLM applicability in general sequence modeling [38]. Sparse Transformers address these issues by optimizing attention mechanisms, reducing complexity from quadratic to \\(O(n )\\), thereby improving scalability for long sequences [38]. Large model sizes, such as CodeGen2, place significant demands on computational resources, complicating the training of extensive deep learning models across multiple GPUs due to memory limitations and inefficient parallel strategies [40]. The complexity introduced by plugins or wrappers for model or pipeline parallelism further exacerbates implementation challenges [36]. Effective partitioning of DNN layers varies based on model architecture, impacting scalability [47]. Training data quality poses additional challenges, particularly in training large bilingual models, which often experience loss spikes and divergence [46]. Traditional attention mechanisms in transformers struggle with long sequences, limiting their applicability across tasks [43]. Existing benchmarks often focus on resource-intensive deep learning models, making them impractical for real-time applications [55]. Addressing these challenges requires a comprehensive approach involving architectural innovations, algorithmic advancements, and improved data management strategies. Future research should explore refinements to paraphrasing models, investigate diverse rephrasing styles, and assess the impact of synthetic data on various LLM architectures, which are essential for enhancing performance and applicability across diverse tasks and domains. illustrates the hierarchical categorization of scalability and efficiency challenges in LLMs, focusing on the optimization of attention mechanisms, training large models, and addressing data quality through benchmarking. This visual representation underscores the interconnected nature of these challenges and emphasizes the need for targeted solutions in each area. Data Efficiency and Quality Data efficiency and quality are crucial determinants of performance and generalization capabilities in LLMs. The complexity and high dimensionality of raw text data pose challenges to model adaptability. Reliance on open data sources may introduce noise and variability, necessitating meticulous data curation and deduplication strategies to enhance model outcomes [6,16]. Efficient data handling is vital for addressing computational constraints, with research suggesting optimizations in activation management beyond transformers [42]. Evaluations of models like Mamba across modalities such as language and genomics underscore the importance of diverse, high-quality datasets in enhancing model capabilities [51]. Intra-layer Model Parallelism (ILMP) limitations in managing extremely large models that exceed GPU memory capacities remain a challenge [52]. The selection and quality of training data are particularly critical in systems like Google's Neural Machine Translation (GNMT), where managing rare words and computational expenses is essential for optimizing performance [80]. Integrating synthetic and real-world data can introduce biases, necessitating balanced datasets for effective evaluation [58]. Current benchmarks often inadequately assess zero-shot performance across diverse tasks, emphasizing the need for comprehensive evaluation metrics incorporating ethical considerations and data efficiency [50]. Benchmarks simulating real-world constraints underscore the importance of strategic data selection and management [57]. Innovative approaches to optimize data strategies are crucial, as highlighted by discussions on enhancing user accessibility and exploring optimizations for specific hardware configurations [41]. Model Interpretability and Robustness Model interpretability and robustness are essential considerations in deploying LLMs, presenting challenges due to complex architectures and diverse training data. Models like BigBird demonstrate advancements in robustness by efficiently handling longer sequences while maintaining performance comparable to full attention models [44]. However, the complexity of models such as PaLM-E, which utilize diverse training data, complicates interpretability and performance in less represented scenarios [34], necessitating robust frameworks to differentiate relevant information and ensure coherent outputs. Interpretability challenges are exacerbated by limitations in current models' ability to manage broader discourse contexts, as evidenced by struggles with the LAMBADA benchmark [25]. This highlights the need for novel approaches in natural language understanding that effectively handle extensive context. Despite enhancements in models like InstructGPT aimed at improving interpretability, persistent simple errors indicate a need for ongoing refinements [5]. Moreover, unresolved questions regarding optimal training strategies for effective reasoning further complicate interpretability [1]. Robustness faces challenges due to architectural dependencies that restrict task generalization. Sparse Transformers show promise, yet their reliance on specific architectural changes may limit compatibility with existing transformer frameworks [38]. Additionally, methods like Contrastive Decoding face constraints due to the quality of the smaller model, potentially impacting overall output quality [53]. The complexity of defining appropriate cost constraints in Safe Reinforcement Learning from Human Feedback (RLHF) methods further illustrates the challenges in ensuring robustness across applications [4]. In sampling methods, Nucleus Sampling balances diversity and reliability by focusing on the most probable outputs, enhancing text generation quality [54]. However, tasks requiring deeper reasoning and the ethical implications of Artificial General Intelligence (AGI) remain areas with unanswered questions, indicating a pressing need for more robust evaluation frameworks [3]. Ethical Considerations The deployment of Large Language Models (LLMs) presents significant ethical challenges, particularly concerning bias and misinformation, which may undermine the integrity of AI-generated outputs. Addressing these issues is crucial for ensuring responsible and equitable use of LLM technologies. This section examines the complex nature of bias and misinformation in LLMs, exploring their origins and implications for users and society. Understanding these challenges allows for the development of strategies to mitigate their impact and promote ethical practices in LLM development and application. Bias and Misinformation Bias and misinformation in LLMs often originate from training datasets that inadvertently reflect societal prejudices, as observed in models like LaMDA [2]. Benchmark studies highlight the risk of generating toxic content, emphasizing the need for controlled training data to address these issues [81]. Inadequate management of training data can lead to biased outputs and performance degradation [23]. The memorization of sensitive data poses significant concerns, as LLMs may unintentionally perpetuate existing biases or misinformation [82]. Developing text-based assistants aligned with human values is crucial for ensuring LLMs provide helpful, honest, and harmless responses [19]. Evaluating alignment with human values is essential to mitigate risks posed by LLMs [83]. Bias in AI-generated explanations can result in misinformation, particularly when outputs are inconsistent or fail to adequately address complex queries [64]. The limitations in technology's ability to comprehend intricate queries underscore the need for effective training and verification techniques to counteract the spread of neural fake news. Existing benchmarks may not fully capture model performance across all languages, especially low-resource languages, leading to biased evaluations and outcomes [84]. Privacy Risks LLMs pose significant privacy risks due to the vast data utilized during training and their complex architectures. The importance of deduplication in training datasets is emphasized to mitigate privacy risks and enhance language model security by preventing the memorization of sensitive information [85]. Sparse architectures, despite their efficiency, present privacy challenges due to complexities in data management during training [86]. These risks necessitate robust data management strategies to safeguard privacy throughout the training process. Ethical implications of LLMs in natural language processing highlight the need for comprehensive frameworks to address privacy concerns in LLM deployment [22]. Addressing ethical considerations in deploying Pretrained Foundation Models (PFMs) is crucial, emphasizing ongoing research to align model capabilities with ethical and privacy standards [87]. Resource Utilization and Environmental Impact LLMs require substantial computational resources, leading to significant environmental consequences. As models scale, the demand for processing power and memory escalates, resulting in increased energy consumption and carbon emissions [4]. Training large models like GPT-3 necessitates extensive computational infrastructure for both training and inference [7], highlighting the need for optimizing resource utilization to mitigate environmental impacts. Innovations such as Sparse Transformers improve LLM efficiency by optimizing attention mechanisms, allowing for more efficient processing of long sequences [38]. Such advancements contribute to reducing the overall resource footprint of LLMs, promoting sustainability in energy consumption. Lightweight models inspired by Gemini offer scalable alternatives requiring less computational power [7]. Efficient data management strategies during training significantly influence the environmental impact of LLMs. Techniques such as deduplication and strategic data selection are crucial for minimizing redundancy and optimizing resource utilization [6]. Integrating renewable energy sources and energy-efficient hardware in data centers can further reduce the carbon footprint of LLM operations, aligning with the goal of environmentally responsible AI development [4]. Alignment with Human Values Aligning LLMs with human values and ethical standards presents significant challenges that require comprehensive strategies and robust benchmarks. Establishing well-defined benchmarks for alignment is critical for fostering the development of responsible AI systems, as they evaluate LLM performance against ethical and value-based criteria [19]. This ensures models provide accurate, contextually relevant outputs while adhering to societal norms. The complexity of aligning LLMs with human values is compounded by diverse cultural contexts and linguistic nuances. Ongoing evaluation of the ethical implications of model outputs is necessary to assess their potential impacts across various societal settings. By integrating value alignment into the core evaluation frameworks of LLMs, developers can better address potential biases and ethical dilemmas during deployment. As illustrated in , the hierarchical structure of aligning large language models with human values highlights not only the challenges and strategies involved but also the dynamic nature of these values, echoing insights from the Ageneralla59 paper. The dynamic nature of human values necessitates continuous updates and adaptations of LLMs to reflect evolving ethical standards and societal expectations. This involves refining algorithms and datasets while engaging interdisciplinary teams encompassing ethics, sociology, and linguistics to ensure a holistic approach to AI development. Conclusion Future Directions and Opportunities The trajectory of Large Language Models (LLMs) suggests a promising future filled with opportunities to refine their capabilities and address prevailing challenges. Key areas of focus include the advancement of context-aware models and the expansion of multilingual functionalities, underscoring the importance of sustained research in these domains. Enhancements in training methodologies, exemplified by models like XLNet, offer potential for improved adaptability and efficiency in handling diverse linguistic tasks. The integration of high-quality text data sources, as suggested by CCNet, is essential for augmenting the reliability and robustness of LLM outputs. Innovations in the mixture-of-experts architecture, such as those seen in GLaM, hold the potential to elevate performance across a spectrum of natural language processing tasks. The refinement of reward models and reinforcement learning strategies promises enhancements in summarization capabilities, expanding the utility of LLMs in content generation. Efforts to streamline preference collection and broaden the scope of tasks through the DRLHP approach remain crucial. Optimizing rank selection and advancing LoRA can enhance its applicability across a wider range of models and tasks, contributing to greater efficiency and scalability in deploying LLMs. Investigations into CoT calibration and the influence of CoT length on task performance can further optimize reasoning capabilities. The exploration of Llemma in mathematical contexts represents another avenue for refinement. The development of additional verification techniques, coupled with a focus on the ethical considerations of AI technologies, is vital for responsible innovation. Enhancing model architectures to accommodate a broader range of natural language processing tasks remains an essential pursuit, with potential gains in versatility and efficiency. Future research may extend GLM-130B's linguistic capabilities and optimize its application-specific performance. Improvements to fastText for complex classification tasks, alongside efforts to bolster model robustness against biases, are advantageous directions. Investigating diverse datasets for commonsense reasoning, broadening the LAMBADA benchmark, and validating OLMo's efficacy in various NLP tasks are critical steps forward. Prioritizing the enhancement of reasoning techniques and exploring new learning paradigms to augment LLM reasoning abilities is imperative. Refining cost constraint definitions and extending Safe RLHF's applicability beyond LLMs can yield significant insights. Expanding datasets and refining evaluation metrics for LaMDA denote vital growth opportunities in conversational AI. Lastly, advancing models beyond next-word prediction, exploring novel architectures, and addressing societal challenges posed by AGI advancements are pivotal areas for future inquiry. Discovering new data sources and configurations to optimize training practices for LLMs, alongside efforts to enhance model robustness and integrate human feedback for improved alignment, are essential for continued progress.",
  "reference": {
    "1": "2212.10403v2",
    "2": "2201.08239v3",
    "3": "2303.12712v5",
    "4": "2310.12773v1",
    "5": "2203.02155v1",
    "6": "2402.00838v4",
    "7": "2403.08295v4",
    "8": "2302.14045v2",
    "9": "2303.04226v1",
    "10": "1905.00075v1",
    "11": "2201.05273v4",
    "12": "2211.14876v1",
    "13": "2308.12284v1",
    "14": "2402.09668v1",
    "15": "2206.14858v2",
    "16": "2309.10818v3",
    "17": "1804.07461v3",
    "18": "2104.08773v4",
    "19": "2112.00861v3",
    "20": "1910.07467v1",
    "21": "1911.00359v2",
    "22": "2003.08271v4",
    "23": "2205.10487v1",
    "24": "2211.01786v2",
    "25": "1606.06031v1",
    "26": "1911.02782v3",
    "27": "2303.14957v1",
    "28": "1508.07909v5",
    "29": "2201.02177v1",
    "30": "1911.12011v1",
    "31": "2102.11972v2",
    "32": "2305.13048v2",
    "33": "2401.04088v1",
    "34": "2111.00396v3",
    "35": "2106.09685v2",
    "36": "2110.14883v3",
    "37": "2112.06905v2",
    "38": "1904.10509v1",
    "39": "2308.01320v1",
    "40": "2305.02309v2",
    "41": "1512.01274v1",
    "42": "2205.05198v1",
    "43": "2103.02143v2",
    "44": "2007.14062v2",
    "45": "2303.04671v1",
    "46": "2210.02414v2",
    "47": "1906.08237v2",
    "48": "1804.04235v1",
    "49": "1706.03741v4",
    "50": "2110.08207v3",
    "51": "2312.00752v2",
    "52": "1909.08053v4",
    "53": "2210.15097v2",
    "54": "1904.09751v2",
    "55": "2406.17557v2",
    "56": "1607.01759v3",
    "57": "2001.08361v1",
    "58": "2305.16264v5",
    "59": "1806.02847v2",
    "60": "2304.15004v2",
    "61": "2305.16355v1",
    "62": "2305.13048v2",
    "63": "2206.07682v2",
    "64": "2304.01373v2",
    "65": "1910.03065v3",
    "66": "2307.03170v2",
    "67": "2109.01652v5",
    "68": "2204.05832v1",
    "69": "2009.13081v1",
    "70": "2208.01448v2",
    "71": "2203.07814v1",
    "72": "2105.13290v3",
    "73": "2001.08435v1",
    "74": "2305.06500v2",
    "75": "2303.08774v6",
    "76": "2212.09597v8",
    "77": "1506.06724v1",
    "78": "1609.08144v2",
    "79": "2201.11903v6",
    "80": "2310.10631v3",
    "81": "2110.14168v2",
    "82": "2305.13169v2",
    "83": "2202.07646v3",
    "84": "2307.09705v1",
    "85": "2212.10535v2",
    "86": "2202.06539v3",
    "87": "2303.10845v1",
    "88": "2302.09419v3"
  },
  "chooseref": {
    "1": "2303.04226v1",
    "2": "2302.09419v3",
    "3": "2202.06417v3",
    "4": "1705.04304v3",
    "5": "2112.00861v3",
    "6": "2212.10554v1",
    "7": "2305.13169v2",
    "8": "1806.02847v2",
    "9": "2212.10535v2",
    "10": "2202.13169v3",
    "11": "1804.04235v1",
    "12": "1412.6980v9",
    "13": "1809.10853v3",
    "14": "2208.01448v2",
    "15": "1506.06724v1",
    "16": "2104.05343v1",
    "17": "2304.15004v2",
    "18": "1706.03762v7",
    "19": "1910.13461v1",
    "20": "1810.04805v2",
    "21": "2211.05100v4",
    "22": "1607.01759v3",
    "23": "2309.10305v4",
    "24": "1502.03167v3",
    "25": "2007.14062v2",
    "26": "1911.00359v2",
    "27": "2201.11903v6",
    "28": "2308.12950v3",
    "29": "2002.08155v4",
    "30": "2305.02309v2",
    "31": "2105.13290v3",
    "32": "2110.14883v3",
    "33": "2203.07814v1",
    "34": "2210.15097v2",
    "35": "1808.10006v2",
    "36": "2104.08773v4",
    "37": "2211.01786v2",
    "38": "2307.09705v1",
    "39": "1911.00536v3",
    "40": "2302.03169v3",
    "41": "2309.02033v3",
    "42": "2107.06499v2",
    "43": "2202.06539v3",
    "44": "1802.05365v2",
    "45": "1912.02292v1",
    "46": "1706.03741v4",
    "47": "2308.01320v1",
    "48": "1905.12616v3",
    "49": "2211.14876v1",
    "50": "2101.02235v1",
    "51": "1310.4546v1",
    "52": "1610.02424v2",
    "53": "2102.11972v2",
    "54": "2309.03883v2",
    "55": "2402.00159v2",
    "56": "2305.10429v4",
    "57": "1301.3781v3",
    "58": "2104.04473v5",
    "59": "2309.06180v1",
    "60": "2111.00396v3",
    "61": "2206.07682v2",
    "62": "2306.15595v2",
    "63": "2305.12816v1",
    "64": "2103.13262v1",
    "65": "2109.01652v5",
    "66": "2307.08691v1",
    "67": "2205.14135v2",
    "68": "2307.03170v2",
    "69": "2210.02414v2",
    "70": "2002.05202v1",
    "71": "1804.07461v3",
    "72": "2211.09085v1",
    "73": "1606.08415v5",
    "74": "2403.08295v4",
    "75": "1904.10509v1",
    "76": "2112.06905v2",
    "77": "1609.08144v2",
    "78": "2303.08774v6",
    "79": "2201.02177v1",
    "80": "2006.16668v1",
    "81": "2301.07597v1",
    "82": "2402.09668v1",
    "83": "2302.10866v3",
    "84": "2209.14375v1",
    "85": "2308.12284v1",
    "86": "2305.06500v2",
    "87": "2403.07082v1",
    "88": "1911.12011v1",
    "89": "2201.08239v3",
    "90": "2302.14045v2",
    "91": "2005.14165v4",
    "92": "2210.07128v3",
    "93": "1607.06450v1",
    "94": "1704.01444v2",
    "95": "2009.01325v3",
    "96": "2302.13971v1",
    "97": "2310.10631v3",
    "98": "2202.00666v6",
    "99": "2106.09685v2",
    "100": "1910.03065v3",
    "101": "2312.00752v2",
    "102": "1909.08053v4",
    "103": "2304.10592v2",
    "104": "2401.04088v1",
    "105": "2110.08207v3",
    "106": "1512.01274v1",
    "107": "1103.0398v1",
    "108": "1508.07909v5",
    "109": "2212.12017v3",
    "110": "2402.00838v4",
    "111": "2002.04745v2",
    "112": "1905.00075v1",
    "113": "2110.15032v6",
    "114": "2305.10403v3",
    "115": "2303.03378v1",
    "116": "2305.16355v1",
    "117": "2303.10845v1",
    "118": "2404.14219v4",
    "119": "1806.03377v1",
    "120": "2107.13586v1",
    "121": "2003.08271v4",
    "122": "2201.05273v4",
    "123": "2202.01279v3",
    "124": "1707.06347v2",
    "125": "2304.01373v2",
    "126": "1912.01703v1",
    "127": "2202.07646v3",
    "128": "2309.16609v1",
    "129": "2407.10671v4",
    "130": "2305.13048v2",
    "131": "2103.02143v2",
    "132": "2212.09597v8",
    "133": "2004.13637v2",
    "134": "2205.05198v1",
    "135": "2401.16380v1",
    "136": "2303.06349v1",
    "137": "2307.08621v4",
    "138": "1907.11692v1",
    "139": "1910.07467v1",
    "140": "2305.13048v2",
    "141": "1911.02782v3",
    "142": "2310.12773v1",
    "143": "2305.16264v5",
    "144": "2210.11416v5",
    "145": "2205.10487v1",
    "146": "2010.14701v2",
    "147": "2001.08361v1",
    "148": "2212.10560v2",
    "149": "1808.06226v1",
    "150": "2208.04933v3",
    "151": "1706.03872v1",
    "152": "2307.14430v1",
    "153": "2310.19341v1",
    "154": "2309.10818v3",
    "155": "2206.14858v2",
    "156": "2303.12712v5",
    "157": "2305.06161v2",
    "158": "1804.10959v1",
    "159": "2101.03961v3",
    "160": "2212.03551v5",
    "161": "2201.10005v1",
    "162": "1606.06031v1",
    "163": "2306.01116v1",
    "164": "1904.09751v2",
    "165": "2406.17557v2",
    "166": "2301.13688v2",
    "167": "2101.00027v1",
    "168": "2001.08435v1",
    "169": "2211.15533v1",
    "170": "2302.04761v1",
    "171": "2212.10403v2",
    "172": "2108.12409v2",
    "173": "2204.05862v1",
    "174": "2203.15556v1",
    "175": "2203.02155v1",
    "176": "2110.14168v2",
    "177": "2210.11399v2",
    "178": "1901.02860v3",
    "179": "1910.03771v5",
    "180": "2210.15191v1",
    "181": "2004.08249v3",
    "182": "1905.03197v3",
    "183": "2202.01169v2",
    "184": "2303.04671v1",
    "185": "2304.08485v2",
    "186": "2112.09332v3",
    "187": "2209.10372v5",
    "188": "2009.13081v1",
    "189": "2204.05832v1",
    "190": "2210.15424v2",
    "191": "2309.04564v1",
    "192": "1906.08237v2",
    "193": "2309.00071v2",
    "194": "2112.12731v1",
    "195": "2303.14957v1"
  }
}