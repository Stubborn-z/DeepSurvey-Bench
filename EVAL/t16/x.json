{
  "survey": "The survey \"The Rise and Potential of Large Language Model Based Agents: A Survey\" provides a comprehensive analysis of the transformative impact of large language models (LLMs) on artificial intelligence (AI) and natural language processing (NLP). It explores the significance of these agents in enhancing language understanding, generation, reasoning, and decision-making capabilities. Key advancements include the integration of multimodal data, innovative model architectures, and sophisticated training techniques. The survey highlights the critical challenges faced by LLMs, such as computational demands, ethical considerations, and catastrophic forgetting, emphasizing the need for ongoing research and development. Future directions include refining existing models, expanding datasets, and exploring novel applications to optimize model performance and adaptability. The recognition of models like GPT-4 underscores the potential implications for AGI development, while the survey identifies actionable directions for advancing language agents within the broader AI landscape. Collectively, these insights underscore the transformative potential of LLMs in shaping the future of AI and NLP, driving innovation and ensuring the responsible deployment of AI systems across diverse domains.\n\nIntroduction Significance of Large Language Model-Based Agents Large language model-based agents represent significant advancements in artificial intelligence and natural language processing, enhancing language understanding and generation. Notable examples, such as MultiModal-GPT, improve dialogue systems by integrating vision and language capabilities, which are essential for the evolution of AI and NLP [1]. The empirical scaling laws of neural language models reveal that model size, dataset size, and training compute are critical factors influencing performance [2]. These models enhance the applicability of language instructions in robotic tasks, demonstrating their versatility in complex reasoning [3]. The exploration of generative deep neural networks in dialogue applications highlights their potential to transform natural language response generation [4]. Moreover, aligning language models with user intent ensures outputs are truthful, non-toxic, and helpful, thereby enhancing user experience and practical utility [5]. Pretrained language models also serve as knowledge bases, advancing AI by efficiently storing and retrieving knowledge from unstructured text [6]. In the context of embodied reasoning and planning for robotic control, these models mimic human reasoning processes, addressing knowledge gaps [7]. Collectively, these advancements underscore the pivotal role of large language model-based agents in shaping the future of AI and NLP. Motivation for the Survey This survey addresses critical challenges and opportunities associated with large language model-based agents. A primary motivation is the inefficiency of traditional fact-checking methods, which often require resource-intensive fine-tuning of pre-trained models [8]. The survey aims to explore innovative approaches to enhance the efficiency and effectiveness of language models across diverse applications. Additionally, the survey investigates the capabilities of large language models (LLMs) in question answering (QA) and their abilities in priori and posteriori judgment, essential for advancing AI capabilities [9]. Existing limitations in following complex human instructions, particularly in multimodal contexts, highlight the need for this survey to address these gaps [1]. Understanding factors that impact the performance of language models, especially regarding cross-entropy loss, is crucial for grasping technological advancements [2]. The challenges in applying high-level, natural language instructions to real-world robotic tasks due to the lack of real-world experience further motivate this survey [3]. The focus on the intersection of LLMs and reasoning methodologies is vital for advancing AI [10]. Addressing the generation of meaningful responses in dialogue systems using generative neural network architectures is another significant motivation [4]. Furthermore, the survey seeks to understand advancements in aligning language models with user intent, particularly through fine-tuning with human feedback, which is crucial for improving user interaction [5]. The need for new approaches to process feedback from dynamic environments emphasizes the challenges faced by LLMs in such contexts [7]. Finally, identifying key aspects that enable language models to function effectively as knowledge bases is essential, as it directly influences their performance and applicability [6]. These motivations underscore the necessity of this survey to address existing limitations, explore innovative approaches, and drive technological advancements in large language model-based agents. Relevance in the Current Technological Landscape Large language model-based agents are increasingly relevant in today's technological landscape, significantly impacting various industries. Models like MultiModal-GPT align with current trends by integrating visual and textual data, influencing sectors reliant on dialogue systems [1]. The ability of LLMs to understand their factual knowledge boundaries and the effectiveness of retrieval augmentation in enhancing this awareness are critical for real-time information retrieval and decision-making processes [9]. Advanced models such as GPT-4 demonstrate capabilities across multiple domains, including mathematics, coding, vision, medicine, law, and psychology, showcasing substantial improvements over predecessors like ChatGPT and Google's PaLM. These advancements illustrate the transformative potential of LLMs to redefine traditional practices by enhancing creativity, factual accuracy, and reasoning processes. In creative fields, LLMs produce high-quality outputs in poetry and storytelling, challenging conventional notions of creativity. In factual domains, retrieval augmentation and multi-agent debate techniques enhance LLMs' ability to discern knowledge boundaries and improve reasoning, thereby reducing errors and hallucinations. Innovations like RET-LLM introduce scalable memory units, enabling efficient knowledge storage and retrieval, thus enhancing performance in open-domain question answering and temporal information management [11,9,12,13]. Despite these advancements, challenges persist in interpretability, consistency, and scalability, which are crucial for executing complex tasks effectively. The integration of external knowledge sources and discrete reasoning is essential for further development, as current methods primarily focus on linguistic processing. This limitation is evident in the need for real-time, contextually relevant answers, which models sometimes struggle to provide due to difficulties in accurately perceiving their factual knowledge boundaries and managing conflicts between internal and external information. Although retrieval augmentation can enhance awareness, models often exhibit overconfidence in their knowledge and are easily distracted by irrelevant context, leading to decreased accuracy. While multi-agent debate strategies show promise in improving reasoning and factual validity, models still encounter challenges in consistently delivering precise and contextually appropriate responses [14,12,9,15]. Innovative frameworks utilizing probabilistic programming and rational meaning construction offer potential solutions by enabling context-sensitive meaning translation. Furthermore, the cognitive origins of tool learning and paradigm shifts introduced by foundation models underscore the growing importance of these agents in the technological landscape. Despite existing challenges, LLMs are increasingly applied in critical areas, driving innovation in creative writing and factual knowledge retrieval while addressing complexities posed by current technological trends. They are revolutionizing AI by producing high-quality creative outputs and enhancing factual accuracy through retrieval augmentation and multi-agent debate strategies. Nonetheless, questions regarding their true creativity and ability to understand knowledge boundaries persist, highlighting ongoing legal, ethical, and technical challenges [9,12,13]. These developments emphasize the critical role of large language model-based agents in shaping the future of AI and their potential impact across various industries. Structure of the Survey This survey is structured to provide a comprehensive exploration of large language model-based agents, beginning with an introduction that establishes their significance, motivation, and relevance in the current technological landscape. The survey is organized into several sections, each addressing key aspects of these models. Section 2 delves into background and preliminary concepts, providing an overview of foundational principles, the role of natural language processing in AI agents, and the transformative impact of transformer models. It further explores multimodal language models and the application of transfer and continual learning in NLP tasks. Section 3 examines the development of large language model-based agents, tracing their historical evolution, advancements in model architectures, and the integration of multimodal data. Section 4 focuses on the capabilities of these agents, highlighting their performance in language understanding, generation, reasoning, and decision-making tasks. Section 5 discusses the impact of transformer models, emphasizing hierarchical attention mechanisms and innovations in positional encoding. Section 6 identifies challenges and limitations, including computational demands, ethical considerations, and biases. Finally, Section 7 explores future prospects and research directions, suggesting areas for refinement, expansion, and novel applications. Each section is supported by relevant research findings, providing a well-rounded understanding of the topic.The following sections are organized as shown in . Background and Preliminary Concepts Core Concepts of Large Language Models Large language models (LLMs) are built on foundational principles that facilitate advanced language processing and generation. A key feature is their ability to integrate multimodal data, as seen in models like MultiModal-GPT, which enhance dialogue systems by merging visual and linguistic information [1]. The interplay of model size, dataset size, and computational resources is critical, influencing scalability and performance [2]. LLMs encode knowledge implicitly from extensive text corpora, enabling them to function as information repositories [6]. This implicit encoding is vital for interpreting complex natural language instructions, particularly in robotic applications requiring reasoning and planning [7]. The combination of deep learning and reinforcement learning enhances their ability to automatically extract features from high-dimensional data, facilitating nuanced task execution [16]. Challenges such as overfitting in reinforcement learning hinder adaptability, affecting generalization across diverse level designs [17]. To counter these issues, LLMs utilize transfer learning, applying knowledge from previous tasks to new ones [18]. Generative sequence-to-sequence models are essential for dialogue response generation, providing a framework for coherent outputs [4]. Aligning outputs with user intent addresses issues of untruthfulness, toxicity, and unhelpfulness in generated content [5]. Benchmarks like DS-1000 illustrate LLMs' broad applicability across various domains [19]. These principles collectively underscore the transformative potential of LLMs in advancing AI and NLP. Natural Language Processing and AI Agents Natural language processing (NLP) is fundamental to AI agent development, providing the framework for understanding and generating human language. Incorporating Theory of Mind into communication assistants enhances collaborative efficiency by evaluating information relevance before sharing [20]. Effective speech representations are crucial for robust speech recognition, as demonstrated in speech representation learning [21]. Integrating classical planning techniques with LLMs enables optimal plan generation from natural language problem descriptions, enhancing reasoning capabilities [22]. Instruction tuning fine-tunes language models on multiple tasks using natural language instructions, enhancing zero-shot learning capabilities [23]. Defining general-purpose task prompts in computer vision is challenging due to diverse output representations, necessitating tailored NLP approaches that capture syntax, semantics, and polysemy [24]. Existing models inadequately account for serialized graphs, hindering accurate representation generation [25]. Interactive capabilities are essential for evolving language models from static generators to adaptive agents that learn from feedback [26]. Enhancements in querying processes through automatic prompt generation and paraphrasing improve NLP application efficiency [27]. These advancements highlight NLP's transformative impact on AI agents, emphasizing its critical role in applications like autonomous scientific research and interactive language processing. Transformer-based LLMs revolutionize machine learning by enabling autonomous experimentation in fields like biology and chemistry, while interactive NLP paradigms enhance agents' abilities to understand and generate language through iterative interactions. Unified neural network architectures streamline NLP tasks by learning from vast unlabeled data, demonstrating versatility in language understanding and generation without task-specific engineering. These developments underscore NLP's multifaceted capabilities in empowering AI agents to perform complex tasks while addressing ethical and safety considerations [26,28,29]. Transformer Models and Their Impact Transformer models have significantly influenced NLP and AI through innovative architectures, reshaping approaches to complex language tasks. Their capacity to handle diverse NLP tasks, including long document classification, is enhanced by benchmarks like Efficientc84 [30]. Traditional transformers face challenges with long input sequences due to quadratic scaling of attention mechanisms, addressed by models like BigBird, which implement sparse attention [31]. Transformers demonstrate impressive generalization on tasks with fixed context lengths but struggle with arbitrarily long sequences due to positional encodings being out-of-distribution [32]. Innovations such as the Attention on Attention (AoA) module enhance traditional attention mechanisms by evaluating the relevance of attention results to queries [33]. Models like CoLT5 improve efficiency by selectively applying computation to important tokens, resulting in faster training and inference than existing methods like LongT5 [34]. The distillation token facilitates attention-based learning from a teacher model, enabling student transformers to achieve competitive performance without convolutional layers [35]. In speech processing, approaches like FastSpeech demonstrate simplified training processes and improved voice quality [36]. Despite advancements, challenges remain in managing long context lengths due to high memory requirements [37]. These innovations highlight the transformative impact of transformer models on NLP and AI, driving advancements in efficiency, scalability, and applicability across various tasks. Transformers revolutionize fields such as biology, chemistry, and programming by enabling autonomous research and experimentation, improving long document classification, and enhancing transfer learning techniques. They also show potential as knowledge bases by encoding vast information from large corpora, with ongoing exploration into their storytelling capabilities despite challenges in text diversity and repetition [38,29,6,30,39]. Multimodal Language Models The integration of multimodal data within LLMs marks a significant advancement in AI, enhancing models' abilities to process and understand complex inputs across various data types. This capability is essential for tasks requiring simultaneous interpretation of visual, auditory, and textual information. Large-scale multimodal models emphasize the importance of processing both image and text inputs to advance AI capabilities in real-world scenarios [40]. Models like PandaGPT address limitations of unimodal methods and underscore the need for visual and auditory instruction-following capabilities [41]. Embodied language models, such as Palm-e, integrate visual and textual encodings, demonstrating multimodal integration's potential for enhanced performance [42]. MiniGPT-4 aligns a frozen visual encoder with a frozen advanced LLM, improving vision-language understanding [43]. Video-ChatGPT merges a video-adapted visual encoder with an LLM, addressing the under-explored area of video-based conversation [44]. The BLOOM dataset comprises hundreds of sources in 46 natural languages and 13 programming languages, illustrating multimodal models' broad applicability [45]. Innovations in integrating LLMs with multimodal sensory modules enable high-level planning and reasoning while grounding LLMs in environmental context [46]. BLIP-2 employs a pre-training strategy using frozen pre-trained image encoders and LLMs to facilitate vision-language representation learning [47]. These advancements underscore multimodal language models' transformative potential in AI, enabling nuanced and contextually aware interactions. They leverage LLMs' emergent capabilities for autonomous scientific research, integrate augmented reasoning and tool-use skills, and employ multiagent debate techniques to enhance factual accuracy and reasoning. Additionally, they exhibit remarkable abilities in multimodal tasks, such as story generation from images and optical character recognition-free math reasoning, suggesting a promising path toward artificial general intelligence. The rapid development of these models aims to expand capabilities across more granular modalities, languages, and scenarios while addressing challenges like dialogue comprehension and multimodal hallucination [48,29,49,50,12]. Transfer and Continual Learning in NLP Transfer learning and continual learning are crucial methodologies for advancing NLP capabilities. Transfer learning leverages pre-trained models on extensive unlabeled datasets, allowing efficient adaptation to new tasks through fine-tuning on task-specific data [51]. The Importance Weighted Transfer of Samples (IWTS) method optimizes transfer learning efficiency by estimating the importance weight of each source sample [52]. Continual learning (CL) enables models to learn continuously from new tasks without forgetting previously acquired knowledge, addressing catastrophic forgetting [53]. Techniques like Learning without Forgetting (LwF) allow neural networks to learn new tasks using only new task data while maintaining performance on previously learned tasks [54]. Training language models on a stream of text data without losing previously acquired knowledge remains a significant concern in CL, particularly in episodic memory systems [55]. Integrating transfer learning with reinforcement learning is exemplified by approaches like MAESN, a gradient-based fast adaptation algorithm designed to learn effective exploration strategies from prior experiences [18]. The Actor-Mimic approach creates a unified policy network that learns from multiple expert teachers, enhancing efficiency in learning new tasks. The complexity of generalizing from limited training conditions underscores the necessity for robust strategies to bridge diverse representations across modalities. Benchmarks like Multitask Prompted datasets evaluate models on completely held-out tasks, effectively testing zero-shot capabilities [56]. Exploring transfer learning and continual learning methodologies highlights their transformative impact on NLP, showcasing potential innovations by enhancing model adaptability and efficiency. Transfer learning achieves state-of-the-art results in tasks like summarization and question answering through pre-training on data-rich tasks before fine-tuning. Continual learning mimics human cognitive processes, enabling models to accumulate and transfer knowledge without forgetting, thus improving performance on new tasks. Together, these approaches advance NLP capabilities, from autonomous scientific research to efficient processing of diverse language tasks, while addressing challenges such as catastrophic forgetting and inter-task class separation [39,28,57,29]. In recent years, the development of large language model-based agents has undergone significant evolution, characterized by various historical milestones and advancements in both model architectures and training techniques. To better illustrate this progression, presents a comprehensive figure that elucidates the hierarchical categorization of these developments. This figure highlights not only the primary categories of advancements but also delves into subcategories, showcasing significant innovations and frameworks that have contributed to the evolution of AI capabilities. Additionally, it emphasizes the integration of multimodal data, which has become increasingly vital in enhancing the performance and versatility of these models. By examining this structured overview, one can appreciate the complex interplay of factors that have driven the rapid advancements in the field of artificial intelligence. Development of Large Language Model-Based Agents Historical Evolution and Milestones The development of large language model-based agents has been marked by significant milestones that have advanced capabilities in AI and NLP. Models like UNIFIED-IO have been pivotal in addressing the need for versatility across various tasks and domains [58]. This adaptability is further enhanced by LLM-Planner, which utilizes large language models for few-shot planning, thereby refining AI agents' planning abilities [59]. The shift from traditional reinforcement learning to more advanced methods like DRLHP exemplifies the evolution in optimizing learning through human feedback [60]. Complementary to these advancements, the Self-Checker introduces a fact-checking method that reduces the need for extensive model training [8]. Zero-shot generalization capabilities in large language models highlight the potential of multitask learning to improve performance across tasks [56]. This capability emphasizes the significance of real-world grounding in robotic decision-making, underscoring the necessity for contextual integration to enhance AI capabilities [3]. OpenAI's o1 series represents a breakthrough in large reasoning models, facilitating complex reasoning tasks [10]. PLG-RL incorporates procedural generation during training to enhance generalization to new environments [17]. Generative encoder-decoder architectures in dialogue systems have advanced through language models, particularly in managing long-term dialogue history [4]. Benchmarks testing models like GPT-4 in professional and academic tasks with multimodal inputs further enhance model capabilities [40]. illustrates key advancements and applications in large language model-based AI, highlighting significant milestones in AI capabilities, real-world applications, and the challenges they encounter, along with proposed solutions. The historical progression of large language model-based agents is characterized by innovations that improve text generation quality, enabling autonomous scientific experiments and complex task reasoning. Extensive web knowledge acquisition propels these agents toward human-level intelligence, fostering applications across various fields. Evaluating generative AI in multilingual settings reveals strengths and limitations, particularly in low-resource languages, necessitating safety measures and evaluation strategies to ensure progress [61,28,29,62,10]. Table presents a detailed examination of significant methods in the evolution of large language model-based agents, emphasizing their milestones, generalization capabilities, and diverse application domains. Advancements in Model Architectures Recent advancements in model architectures have significantly enhanced the performance and versatility of large language model-based agents. Unified-IO presents a novel approach by standardizing inputs and outputs into a common representation, allowing a single transformer-based architecture to efficiently manage diverse tasks [58]. This flexibility is crucial for handling multiple modalities and applications. The reframing of structured commonsense reasoning tasks as code generation showcases the adaptability of language models in executing complex reasoning tasks [25]. BART enhances robustness by reconstructing original text from corrupted inputs, essential for processing noisy data [63]. In speech synthesis, FastSpeech addresses the one-to-many mapping problem through direct training with ground-truth data and detailed speech variation information [36]. Innovative methods for discovering high-quality prompts and ensemble techniques improve estimation accuracy, highlighting refined prompt engineering's potential in decision-making [27]. BigBird's sparse attention mechanism transforms the quadratic dependency of transformers to linear, enabling longer sequence handling [31]. Parameter-efficient fine-tuning methods, such as LoRA used in OpenFlamingo, optimize model architectures for complex tasks [1]. InstructGPT, fine-tuned from GPT-3, utilizes human feedback for better alignment with user requests, enhancing interaction quality [5]. The Deep Q-Network (DQN) exemplifies the integration of reinforcement learning with deep learning architectures, enhancing model capabilities through direct learning from high-dimensional data [16]. These advancements underscore large language models' transformative potential in AI, driving innovation in efficiency, scalability, and applicability across diverse tasks. Rapid advancements in machine learning research span applications in natural language, biology, chemistry, and computer programming, with significant improvements in text generation quality through extreme scaling and reinforcement learning from human feedback. The multilingual evaluation of generative AI models, as seen in MEGA benchmarking, highlights impressive capabilities across 70 languages while addressing challenges in low-resource languages [61,29]. Training Techniques and Computational Resources The development of large language model-based agents relies heavily on advanced training techniques and substantial computational resources to optimize performance across tasks. MultiModal-GPT exemplifies this by employing joint training with diverse instruction templates, integrating visual and language data for enhanced performance [1]. This approach underscores the importance of multimodal inputs in training methodologies for robust AI agents. Empirical scaling laws are vital for determining optimal training configurations, focusing on the interplay between model size, dataset size, and computational resources, guiding resource allocation and training regime design [2]. In code generation, benchmarks like DS-1000, tested with Codex-002, illustrate the application of state-of-the-art models in generating complex code structures, emphasizing computational demands [19]. The integration of deep learning with reinforcement learning, as seen in DQN, facilitates learning control policies from high-dimensional sensory input, exemplifying end-to-end training for feature extraction [16]. Frameworks like 'Inner Monologue Planning with Language Models' (IMPLM) incorporate environmental feedback into the reasoning processes of LLMs, enabling adaptive actions based on real-time inputs [7]. This integration showcases language models' dynamic adaptation capabilities, enhancing practical utility. These training techniques and computational resources highlight the transformative potential of large language models, driving innovation in model efficiency, scalability, and applicability. The continuous evolution of training methodologies, including extreme scaling and reinforcement learning from human feedback, alongside strategic resource deployment, is crucial for enhancing AI agents' capabilities. Innovations enable AI to perform complex tasks across domains like NLP, biology, and chemistry while addressing challenges such as catastrophic forgetting and inter-task generalizability. Integrating continual learning paradigms and dialogue comprehension techniques allows AI systems to adaptively accumulate and transfer knowledge, improving functionality in increasingly complex environments [64,57,29,50]. Integration of Multimodal Data The integration of multimodal data into large language models has significantly enhanced AI agents' capabilities, enabling them to process complex inputs across various modalities. Kosmos-2 exemplifies this advancement by linking textual descriptions with visual elements in images, enhancing comprehension and response generation based on integrated information [65]. This capability is crucial for tasks requiring simultaneous interpretation of diverse data types, such as image captioning and visual question answering. Integrating a vision encoder with a frozen language model creates a multimodal few-shot learner that adapts to new tasks using interleaved image and text embeddings [66]. This method illustrates the potential of leveraging pre-trained models for efficient multimodal input management. Macaw-LLM advances multimodal integration by processing visual, audio, and textual information through structured modules, enhancing nuanced understanding and interaction with multimodal data [67]. PandaGPT integrates multimodal encoders with large language models to process visual and auditory instructions simultaneously, benefiting applications in robotics and interactive systems where real-time sensory input processing is crucial [41]. The Interactive Perception Framework (IPF) employs a Large Language Model to manage epistemic actions and reason over sensory inputs, facilitating effective robot interaction in multimodal environments [46]. This framework highlights the significance of integrating sensory data with reasoning capabilities for practical applications. X-LLM introduces a method for converting multimodal information into languages using X2L interfaces, subsequently processed by a large language model [68]. This innovative approach enables seamless integration and processing of diverse data types, showcasing language models' efficiency in handling complex multimodal tasks. These advancements demonstrate the transformative impact of multimodal data integration in the evolution of language model-based agents. This integration enhances model adaptability, efficiency, and applicability across various applications, including autonomous scientific research, improved factuality and reasoning through multiagent debate, and the development of multimodal large language models (MLLMs) like GPT-4V and Kosmos-1. These models exhibit capabilities such as reasoning from images without traditional OCR, engaging in multimodal dialogues, and performing tasks across diverse modalities, paving the way toward artificial general intelligence. Augmented language models (ALMs) further illustrate the potential to overcome traditional limitations by incorporating reasoning skills and tool usage, thereby expanding context processing abilities and enhancing interpretability, consistency, and scalability [69,48,29,49,12]. Capabilities of Large Language Model-Based Agents Large language model-based agents possess a wide range of capabilities that enhance their effectiveness across various applications, transcending basic language understanding and generation. This section examines their multifaceted functionalities, starting with foundational skills in language comprehension and generation, supported by advanced architectures and training methodologies. These enhancements pave the way for a detailed exploration of reasoning and decision-making skills in subsequent subsections. Language Understanding and Generation Large language model-based agents excel in understanding and generating human language, facilitated by innovations in model architectures and training techniques. Pretrained skills enable these agents to handle complex tasks, enhancing their language capabilities [3]. Procedural level generation aids in the generalization of reinforcement learning agents, allowing adaptation to diverse linguistic tasks [17]. Generative models produce nuanced responses with minimal domain-specific knowledge, showcasing adeptness in language tasks [4]. InstructGPT refines outputs to align with user intent, emphasizing user-centric language generation [5]. Additionally, models enhance reasoning capabilities in planning tasks by utilizing environmental feedback, enriching adaptability in dynamic contexts like robotics [7]. This is illustrated in , which highlights the key advancements in language understanding and generation. The figure emphasizes the role of pretrained skills for robotic tasks, procedural generation for reinforcement learning agents, and the alignment with user intent through InstructGPT. These advancements collectively underscore the transformative potential of large language model-based agents in driving innovation across various tasks and domains. Reasoning and Decision-Making Large language model-based agents exhibit significant advancements in reasoning and decision-making, driven by innovative methodologies and architectures. SwiftSage integrates fast and slow cognitive processes, enhancing task performance through refined reasoning strategies, enabling dynamic adjustments in reasoning [14,10,49,30,12]. Generative agents autonomously engage in intricate social interactions, leveraging past experiences for decision-making, enhancing problem-solving capabilities. Models like GPT-3 demonstrate emergent analogical reasoning abilities, matching or exceeding human performance in zero-shot problem-solving scenarios, highlighting potential in executing complex tasks autonomously [70,29]. The Tree of Thought (ToT) methodology allows exploration of multiple reasoning paths, improving performance in planning tasks [71,72,73]. Self-Polish (SP) refines problem comprehension, guiding models to enhance clarity and solvability, complementing reasoning techniques like Chain-of-Thought (CoT) [74,10,75,12]. In multimodal environments, LLMs manage interactive robot behavior, integrating sensory inputs with reasoning processes [29,12]. Importance Weighted Transfer of Samples (IWTS) and Learning without Forgetting (LwF) optimize decision-making by leveraging prior knowledge and ensuring performance consistency [52,54]. MAESN enhances exploration strategies, demonstrating reinforcement learning's efficacy in optimizing decision-making [18]. Collectively, these advancements underscore the transformative potential of large language model-based agents in reasoning and decision-making, driving innovation across applications and enhancing capabilities in scientific research and autonomous tasks. Interactive and Conversational Abilities Large language model-based agents possess advanced interactive and conversational abilities, facilitating meaningful engagement with users in real-world applications. Multimodal data integration allows these models to process visual, auditory, and textual inputs simultaneously, enhancing user interaction understanding [65]. PandaGPT exemplifies the importance of multimodal approaches in improving conversational interactions through visual and auditory instruction-following capabilities [41]. Video-ChatGPT merges video-adapted visual encoders with language models, expanding versatility in interaction formats [44]. The Interactive Perception Framework (IPF) showcases LLMs' potential in managing epistemic actions and reasoning over sensory inputs, enhancing utility in dynamic environments [46]. Techniques like automatic prompt generation and paraphrasing improve NLP applications' efficiency, enabling coherent and contextually relevant responses [27]. These advancements highlight large language model-based agents' transformative potential in interactive and conversational applications, driving innovation in adaptability and efficiency across diverse tasks, including natural language processing and dialogue comprehension. Integration of extreme scaling, reinforcement learning, and multiagent debate techniques significantly improves text generation quality, enabling autonomous design and execution of complex tasks, while addressing societal and ethical implications [50,29,62,12]. Creative and Generative Applications Large language model-based agents demonstrate remarkable capabilities in creative and generative applications, addressing complex challenges in machine creativity. Analysis of 'easy' and 'hard' problems illustrates LLMs' transformative potential in intricate creative tasks [13]. These models excel in generating diverse, contextually relevant content, leveraging advanced language understanding for innovative outputs across fields. Macaw-LLM exemplifies the advantages of multimodal integration, enhancing content understanding and generation compared to traditional LLMs [67]. LLMs tackle 'hard' problems, such as generating novel artistic compositions or solving intricate design challenges, underscoring potential in creative industries. Their capacity for high-quality creative writing, including poetry and storytelling, along with emergent analogical reasoning capabilities, positions them as formidable tools in the creative landscape [70,29,13,12]. These advancements illustrate large language model-based agents' transformative impact in redefining machine creativity and driving multifaceted innovation. Transformer-based models revolutionize fields like natural language processing, scientific research, and creative writing, showcasing capabilities like autonomous scientific experimentation and multilingual generation. As these models evolve, they push creativity's boundaries while presenting new challenges and opportunities regarding societal, legal, and ethical implications [61,29,13]. Expressivity and Chain of Thought (CoT) Large language models (LLMs) have advanced in expressivity and reasoning through Chain-of-Thought (CoT) prompting techniques, enhancing articulation of nuanced reasoning paths and improving performance in complex problem-solving scenarios. CoT prompting provides reasoning step examples, enabling models to generate coherent outputs [76]. Integration of episodic memory with sparse experience replay and local adaptation enhances LLM expressivity, reducing memory space requirements while maintaining performance [53]. Self-Consistency decoding strategies sample multiple reasoning paths to select the most consistent answer, illustrating CoT techniques' potential in refining model outputs [77]. Progressive Prompts facilitate forward transfer and resist forgetting, optimizing memory utilization while maintaining expressivity [78]. Self-Polish (SP) enhances reasoning by guiding models to refine problems for clarity and solvability, complementing techniques like CoT [75]. Faithful CoT employs a two-stage reasoning framework translating natural language queries into symbolic reasoning chains, enhancing expressivity through structured reasoning paths [79]. Innovations like MAD disrupt LLMs' linear thought process, encouraging diverse reasoning approaches and enhancing problem-solving capabilities [80]. Recent advancements in expressivity and CoT underscore their transformative potential, driving innovation in adaptability and efficiency across diverse tasks. Scaled models enhanced with reinforcement learning demonstrate autonomous scientific research capabilities, achieving remarkable accuracy in tasks from arithmetic to symbolic reasoning, while emphasizing addressing safety and misuse concerns [76,29]. State-of-the-Art NLP Achievements Recent advancements in large language model-based agents have led to state-of-the-art achievements across various natural language processing (NLP) tasks, showcasing their transformative impact. Randomized positional encoding enhances Transformers' generalization capabilities, enabling effective management of sequences of unseen lengths [32]. BigBird's sparse attention mechanism demonstrates superior performance in tasks like question answering and summarization [31]. In multimodal interactions, X-LLM exhibits impressive chat abilities, achieving a relative score of 84.5 Impact of Transformer Models Transformer models have revolutionized natural language processing (NLP) by introducing sophisticated architectures, particularly through the enhancement of attention mechanisms. A key focus is the innovation within attention mechanisms, which are crucial for the operation of these models. This section examines various advancements in attention mechanisms, beginning with hierarchical attention mechanisms, which bolster the model's ability to process information at multiple abstraction levels and effectively handle long sequences, thereby deepening our understanding of their impact on transformer architectures. Hierarchical Attention Mechanisms Hierarchical attention mechanisms are pivotal in enhancing large language models' performance by organizing attention across multiple layers. They enable models to concentrate on different aspects of input data at varying abstraction levels, facilitating nuanced comprehension and processing of complex information. Architectures like BigBird utilize sparse attention to efficiently manage long sequences [31]. The Attention on Attention (AoA) module refines traditional attention mechanisms by evaluating the relevance of attention results to the queries, thereby improving model effectiveness across diverse tasks [33]. This refinement ensures precise focus on pertinent data, enhancing output accuracy and coherence. Hierarchical attention mechanisms also contribute to model scalability, enabling the management of large datasets without performance degradation, addressing the quadratic scaling issues of full attention mechanisms. These structures support multimodal data integration, allowing models to process and synthesize information from various sources effectively, which is vital for tasks requiring simultaneous interpretation of visual, auditory, and textual inputs. Hierarchical Attention Transformer (HAT) models demonstrate superior efficiency in long document classification, outperforming models like Longformer while utilizing significantly less GPU memory and processing time. Additionally, hierarchical attention optimizes encoder-decoder attention in summarization tasks by leveraging sparsity in sentence structures, maintaining performance while reducing computational costs. Collectively, these advancements highlight the profound impact of hierarchical attention mechanisms on machine learning models across various domains [81,82,29,30,83]. Innovations in Positional Encoding Positional encoding is fundamental to transformer models, providing order to input sequences. Traditional positional encodings often face challenges with sequences of varying lengths, as they are typically designed for fixed-length inputs. Randomized positional encoding represents a significant innovation, allowing for the selection of an ordered subset of positions that match the input sequence length, thus overcoming the limitations of fixed positional encodings [32]. Randomized positional encoding enhances transformer models' ability to generalize across sequences of varying lengths, addressing challenges of out-of-distribution positional encodings for longer sequences without the inefficiencies of training on extended sequences. This method involves simulating positions of longer sequences and selecting a random ordered subset, yielding an average test accuracy improvement of 12.0 Innovations in positional encoding, including randomized schemes and hierarchical attention mechanisms, significantly enhance transformer architectures' robustness. These advancements enable transformers to manage complex tasks involving long-range dependencies more effectively, improving length generalization and reducing computational complexity. For example, randomized positional encodings allow transformers to generalize to unseen sequence lengths, increasing test accuracy by an average of 12 Sparse Attention Mechanisms Sparse attention mechanisms have emerged as critical innovations in transformer models, addressing inefficiencies associated with the quadratic scaling of traditional full attention mechanisms. By selectively focusing on key elements within input sequences, sparse attention reduces computational complexity, enabling models to manage longer sequences effectively without sacrificing performance [31]. Models like BigBird exemplify this approach by utilizing sparse attention to enhance scalability and efficiency in processing large datasets. The integration of sparse attention mechanisms facilitates efficient memory utilization, allowing models to allocate computational resources to the most relevant parts of the input data. This selective attention enhances model performance and supports handling complex tasks requiring long-range dependencies, such as document classification and language modeling [30]. Additionally, sparse attention mechanisms contribute to transformer models' adaptability, enabling effective processing of diverse data types and modalities. Advancements in sparse attention have also facilitated the development of multimodal language models, where integrating visual, auditory, and textual information is critical for real-world applications. By optimizing attention processes, sparse attention mechanisms enhance language models' versatility across various tasks and domains. For instance, in NLP tasks like summarization, modified transformer architectures such as LED or LoBART leverage local attention patterns to mitigate the computational expense of quadratic self-attention, while innovations in encoder-decoder attention utilize sparse sentence structures to maintain performance. In speech processing, large-scale weak supervision enables models to achieve competitive accuracy and robustness in zero-shot settings, approaching human-level performance. In long document classification, sparse attention mechanisms balance accuracy with time and space efficiency, underscoring the importance of comprehensive baselines and datasets in developing robust models [81,30,83]. Challenges and Limitations The progression of large language models (LLMs) is impeded by substantial computational demands and resource constraints, affecting their scalability and efficacy across tasks. This section delves into these computational challenges, highlighting inefficiencies in current methods and the reliance on extensive training data, both crucial for understanding model performance and adaptability. Computational Demands and Resource Constraints Deploying LLM-based agents is challenged by significant computational demands and resource constraints, particularly due to the quadratic complexity of global attention mechanisms [2]. Models like LongT5 attempt to address these issues, yet limitations remain in efficiently handling extended sequences, necessitating innovative resource optimization approaches. The dependence on the quality and availability of pretrained skills further underscores computational challenges, especially for tasks requiring specific competencies [3]. Extensive training data requirements and the complexity of implementing reinforcement learning techniques, exemplified by the resource-intensive Deep Q-Network (DQN) method, further illustrate these constraints [10,16]. Procedural generation in reinforcement learning agents depends heavily on the design quality of procedural generators, affecting generalization capabilities [17]. Benchmarks like DS-1000 often fail to represent realistic use cases, leading to inflated performance metrics that may not reflect real-world applications [19]. In environments with sparse or ambiguous feedback, methods like inner monologue planning struggle, hindering effective planning and decision-making [7]. These challenges necessitate efficient resource utilization and innovative architectures balancing model complexity with computational needs. Insights from studies emphasize the need for research focused on optimizing memory utilization, enhancing training efficiency, and developing architectures that balance performance with resource allocation. Advanced frameworks like RET-LLM, integrating scalable and interpretable memory units, and robust speech recognition systems using large-scale weak supervision, demonstrate potential for achieving human-like accuracy without extensive fine-tuning. Efficient classification methodologies for long documents using transformers highlight the importance of comprehensive baselines and datasets for consistent model performance. Unified neural network architectures minimizing task-specific engineering while maximizing unlabeled data utility show promise for versatile NLP applications with reduced computational requirements [15,28,11,30,83]. These advancements are crucial for facilitating LLM applications across diverse fields. Knowledge Transfer and Catastrophic Forgetting Knowledge transfer and catastrophic forgetting pose significant challenges for LLMs, affecting their ability to retain information across sequential tasks. Catastrophic forgetting, where models lose previously acquired knowledge when learning new tasks, presents a critical barrier in continual learning environments [53]. This issue is exacerbated in scenarios where models cannot retrain with new tasks due to unavailable original training data, complicating knowledge retention [54]. Existing benchmarks inadequately assess model robustness in handling linguistically diverse and complex reasoning tasks [84], underscoring the need for comprehensive evaluation frameworks measuring generalization capabilities across varied linguistic contexts. The effectiveness of knowledge transfer is influenced by the quality and relevance of prior task experiences, which vary significantly [18]. Robust methodologies are essential to adapt to different model architectures and task requirements, enabling LLMs to leverage past knowledge effectively. Innovative continual learning strategies have emerged, allowing models to learn new tasks without forgetting previously acquired knowledge [85]. These approaches emphasize balancing stability and plasticity, enabling models to adapt their behavior while retaining core competencies. These challenges highlight the need for research to enhance knowledge transfer and mitigate catastrophic forgetting in language models. This is particularly vital given advancements in transformer-based models facilitating autonomous scientific research, exploring factual knowledge boundaries with retrieval augmentation, and the potential for LLMs to function as knowledge bases without human supervision. Addressing these issues is crucial for improving AI systems' adaptability and robustness in dynamic learning environments, ensuring they can maintain and build upon acquired knowledge across sequential tasks [6,57,29,9]. Evaluation and Benchmarking Limitations Evaluating and benchmarking LLMs presents limitations that hinder comprehensive assessments of their capabilities across diverse tasks. A primary concern is the reliance on existing datasets that may not encapsulate all facets of conversational quality, leading to incomplete evaluations of model performance in real-world scenarios [86]. This gap necessitates developing nuanced datasets reflecting human dialogue complexities and varied contexts in which LLMs operate. Table provides a detailed overview of the representative benchmarks currently utilized to evaluate large language models, emphasizing the diversity in domain, task format, and evaluation metrics in context with the limitations in existing methodologies. Current benchmarks inadequately assess the robustness of Neural Theory-of-Mind (N-ToM) abilities in LLMs, relying on anecdotal evidence and psychological tests that may not effectively capture cognitive processes [73]. This reliance on insufficient measures highlights the need for advanced evaluation frameworks accurately reflecting cognitive and interactive capabilities of language models. Additionally, complexities of long document classification are not sufficiently represented in current benchmarking practices. Many benchmarks lack scope and fail to consider nuances of processing extended textual inputs, resulting in inconsistent performance across different datasets [30]. This limitation underscores developing benchmarks encompassing a broader range of document lengths and formats, ensuring rigorous testing for scalability and efficiency. These evaluation and benchmarking limitations emphasize the need for ongoing refinement of assessment methodologies to accurately capture diverse tasks encountered by language models, particularly as they evolve to function as knowledge bases, integrate reasoning and tool-use capabilities, and navigate factual knowledge boundaries. Enhanced methodologies provide better insights into planning abilities and heuristic guidance of language models, addressing interpretability, consistency, and scalability issues [87,6,49,9]. Addressing these limitations is vital for advancing NLP and enhancing LLM reliability across various domains. Ethical Considerations and Biases Ethical considerations and biases inherent in LLMs present substantial challenges to their deployment across diverse applications. A significant concern is the excessive confidence LLMs exhibit in their internal knowledge, complicating reconciliation with external information sources and potentially leading to inaccuracies in outputs [9]. This issue is intensified by reliance on frozen single-modal encoders in models like X-LLM, which may restrict adaptability and learning of new modalities, limiting bias mitigation [68]. Dependency on the quality of external information sources complicates ethical compliance, as inaccuracies can result in erroneous model outputs, raising reliability concerns in sensitive applications [88]. Additionally, sparse attention mechanisms in models like BigBird introduce complexities requiring careful tuning to avoid ethical pitfalls [31]. MultiModal-GPT highlights ethical issues stemming from training data quality, as inherent biases can influence model outputs and lead to harmful or unhelpful content [1]. This concern is echoed in InstructGPT, which, despite improvements, still produces errors and content misaligned with ethical standards, underscoring the need for continuous refinement [5]. Studies inadequately address dialogue complexities, such as maintaining coherence over extended conversations, raising ethical concerns about generating misleading or biased content [4]. Limitations in understanding knowledge representation and retrieval accuracy in LLMs highlight ethical concerns regarding their reliability as knowledge bases [6]. Integration of multimodal inputs and scalability of results across contexts also present ethical challenges, as demonstrated by limitations of models like GPT-4, requiring further refinement to ensure ethical compliance and reliability across applications [40]. These ethical considerations and biases underscore the importance of fostering trust and inclusivity in AI systems, ensuring responsible deployment across domains. Addressing these challenges is crucial for ethical integration of LLMs into society. Generalization and Adaptability Challenges Achieving generalization and adaptability in LLMs presents multifaceted challenges, primarily due to their inability to retain information from previous tasks while learning new ones without interference [89]. This core obstacle, known as catastrophic forgetting, remains a significant barrier to developing models capable of continuous learning across diverse tasks [85]. Despite various methods aimed at mitigating this issue, the problem persists, highlighting the need for ongoing research and innovative solutions. A critical limitation affecting generalization is reliance on the quality and diversity of training data. Models like Flamingo illustrate the impact of training data quality on performance, particularly for underrepresented tasks [90]. This dependency suggests enhancing data diversity and representation is essential for improving model adaptability across broader applications. In audio processing, models such as AudioGPT encounter challenges in real-time processing due to reliance on foundational model quality [91]. This reliance can hinder audio model generalization across contexts, emphasizing the necessity for robust foundational models supporting diverse audio tasks. Speech synthesis models like FastSpeech face difficulties generalizing across varying speech patterns, as they often rely on specific conditional inputs [36]. This limitation underscores developing flexible models capable of adapting to diverse speech characteristics without compromising performance. The challenges discussed emphasize the need for methodologies enhancing generalization and adaptability of LLMs across diverse tasks. This includes developing techniques for model editing to maintain relevancy and correct errors, improving reasoning and factual accuracy through multi-agent debate, augmenting models with tool-using capabilities, and employing retrieval augmentation to better understand knowledge boundaries. These advancements aim to address limitations such as performance consistency, interpretability, and scalability, ultimately paving the way for more robust and versatile LLMs [49,92,9,12]. Addressing these issues is vital for realizing the full potential of language models in dynamic environments, ensuring reliable performance and applicability across a wide range of applications. Future Prospects and Research Directions Advancing large language models (LLMs) requires a comprehensive approach that focuses on refining models, expanding datasets, and enhancing benchmarking methodologies. These efforts ensure that LLMs are optimized for current tasks while preparing them for future applications. The following subsections delve into strategies for model refinement, dataset expansion, and improvements in reasoning processes. Refinement and Optimization of Existing Models Optimizing LLMs is crucial for improving performance across various tasks. Future research should enhance procedural generation level designs in reinforcement learning to boost generalization [17]. Enhancing adaptability in methods like MAESN and incorporating complex prior knowledge can significantly improve learning strategies [18]. Refinements to Learning without Forgetting are essential to minimize knowledge loss across tasks [54]. Improving human feedback integration, as seen in InstructGPT, is vital for aligning models with user intent [5]. Expanding benchmarks like DS-1000 to encompass diverse problems and refining evaluation metrics will facilitate comprehensive model assessments, particularly in code generation [19]. Optimizing training efficiency and reducing data requirements in methods like DQN can enhance reinforcement learning practicality [16]. Enhancing feedback mechanisms in IMPLM for complex environments will improve real-time decision-making [7]. Advancing probing techniques for language models will bolster their utility in information retrieval [6]. Collectively, these strategies highlight rapid advancements in LLMs, driven by extreme scaling, reinforcement learning from human feedback, and reasoning and tool usage augmentation, enabling autonomous scientific experiments and improving factual validity through multiagent debate [29,6,49,93,12]. Expansion of Datasets and Benchmarking Expanding datasets and benchmarking methods is vital for enhancing LLM capabilities and robustness. Future research should broaden datasets used in LLM-Eval to provide a comprehensive evaluation framework for diverse tasks [86]. This expansion is crucial for capturing human dialogue nuances and rigorously testing models in realistic scenarios. Expanding training datasets for models like MiniGPT-4 will facilitate exploration in multimodal contexts, enhancing versatility in real-world applications [43]. Investigating larger datasets and addressing catastrophic forgetting are essential for developing continual learning capabilities [85]. Improving evaluation benchmarks is crucial for accurately assessing generalization capabilities and ensuring reliability across tasks. These efforts to expand datasets and enhance benchmarking methods are vital for advancing natural language processing, enabling LLMs to learn from vast, mostly unlabeled data and serve effectively as knowledge bases [6,28]. Enhancements in Reasoning and Decision-Making Processes Future advancements in reasoning and decision-making for LLMs can be achieved through strategic enhancements. Concurrent learning of hard attention masks for each task, utilizing previous masks, reduces catastrophic forgetting [89]. Improving data generation for multimodal instruction-following, as suggested for LLaVA, can enhance reasoning capabilities [94]. The iterative PALMS approach, incorporating feedback for refining training datasets, presents a promising method for continuous improvement [95]. Exploring additional modalities and applying Macaw-LLM across various applications can optimize training processes [67]. Future research should refine sampling processes and explore contexts for self-consistency [77]. The C-LoRA method exemplifies adaptive learning strategies that mitigate forgetting [96]. These enhancements highlight LLMs' transformative potential, driving innovation in adaptability and efficiency. Future research should address current limitations, develop methodologies for AGI [97], integrate contextual and social factors into language processing [98], and refine benchmarks to mitigate hallucination issues [99]. Exploration of Novel Applications and Domains Exploring novel applications for LLM-based agents is crucial for enhancing their impact across various fields. Future research could enhance models like Kosmos-2 to manage complex visual scenarios, expanding applicability in autonomous navigation and visual content analysis [65]. Investigating language model robustness to ambiguous data is essential for advancing multimodal tasks, facilitating innovations in multimedia content generation and cross-modal information retrieval [66]. Audio processing components, such as those in AudioGPT, could benefit from enhanced robustness and exploration of interactive applications [91]. Expanding training datasets to include diverse multimodal inputs, as suggested for PandaGPT, will improve capabilities in applications like robotics and human-computer interaction [41]. Future work should refine memory selection processes and explore mechanisms to enhance learning capabilities, as indicated by episodic memory systems [55]. Exploring dynamic representations in various contexts could unlock new research avenues [100]. Enhancing benchmarks to include diverse scenarios and improving evaluation methodologies in real-world settings will drive model performance advancements [40]. These explorations underscore LLM-based agents' transformative potential, driving innovation in adaptability, efficiency, and applicability across fields such as scientific research, autonomous agents, factual reasoning, knowledge bases, and zero-shot planning. LLMs are advancing machine learning by enabling autonomous scientific experiments, enhancing decision-making through vast knowledge, improving reasoning via multiagent debate, and decomposing high-level tasks into actionable steps for embodied agents, revolutionizing sectors and paving the way for breakthroughs [101,29,62,6,12]. Conclusion The survey provides a comprehensive analysis of the rise and capabilities of large language model-based agents, underscoring their significant impact on artificial intelligence and natural language processing. It outlines strategic directions for advancing these language agents and contextualizes their role within the expansive AI framework. Key developments in model architectures, training techniques, and multimodal integration are crucial in enhancing abilities in language comprehension, generation, reasoning, and decision-making. The emergence of GPT-4 marks a significant milestone in AI, suggesting profound effects on the trajectory of AGI development. As the domain evolves, addressing issues related to computational requirements, ethical concerns, and generalization constraints is vital to fully leverage the potential of large language models. Future investigations should focus on improving current models, expanding datasets, and exploring novel applications to drive progress and ensure the ethical deployment of AI systems across diverse sectors.",
  "reference": {
    "1": "2305.04790v3",
    "2": "2001.08361v1",
    "3": "2204.01691v2",
    "4": "1611.06216v1",
    "5": "2203.02155v1",
    "6": "2204.06031v1",
    "7": "2207.05608v1",
    "8": "2305.14623v2",
    "9": "2307.11019v3",
    "10": "2212.10403v2",
    "11": "2305.14322v2",
    "12": "2305.14325v1",
    "13": "2304.00008v5",
    "14": "2302.00093v3",
    "15": "2002.08910v4",
    "16": "1312.5602v1",
    "17": "1806.10729v5",
    "18": "1802.07245v1",
    "19": "2211.11501v1",
    "20": "2109.01355v1",
    "21": "2106.07447v1",
    "22": "2304.11477v3",
    "23": "2109.01652v5",
    "24": "2212.02499v2",
    "25": "2210.07128v3",
    "26": "2305.13246v1",
    "27": "1911.12543v2",
    "28": "1103.0398v1",
    "29": "2304.05332v1",
    "30": "2203.11258v1",
    "31": "2007.14062v2",
    "32": "2305.16843v1",
    "33": "1908.06954v2",
    "34": "2303.09752v3",
    "35": "2012.12877v2",
    "36": "1905.09263v5",
    "37": "2305.16300v2",
    "38": "1909.10705v1",
    "39": "1910.10683v4",
    "40": "2303.08774v6",
    "41": "2305.16355v1",
    "42": "2303.03378v1",
    "43": "2304.10592v2",
    "44": "2306.05424v2",
    "45": "2211.05100v4",
    "46": "2303.08268v3",
    "47": "2301.12597v3",
    "48": "2306.13549v4",
    "49": "2302.07842v1",
    "50": "2110.04984v2",
    "51": "2009.07888v7",
    "52": "1805.10886v1",
    "53": "1706.08840v6",
    "54": "1606.09282v3",
    "55": "1906.01076v3",
    "56": "2110.08207v3",
    "57": "2211.12701v2",
    "58": "2206.08916v2",
    "59": "2212.04088v3",
    "60": "1706.03741v4",
    "61": "2303.12528v4",
    "62": "2308.11432v7",
    "63": "1910.13461v1",
    "64": "2302.00487v3",
    "65": "2306.14824v3",
    "66": "2106.13884v2",
    "67": "2306.09093v1",
    "68": "2305.04160v3",
    "69": "2302.14045v2",
    "70": "2212.09196v3",
    "71": "2305.10601v2",
    "72": "2305.15408v5",
    "73": "2305.14763v1",
    "74": "2205.09712v1",
    "75": "2305.14497v2",
    "76": "2201.11903v6",
    "77": "2203.11171v4",
    "78": "2301.12314v1",
    "79": "2301.13379v3",
    "80": "2305.19118v4",
    "81": "2109.03888v1",
    "82": "2210.05529v1",
    "83": "2212.04356v1",
    "84": "2112.07916v2",
    "85": "2110.14168v2",
    "86": "1708.02072v4",
    "87": "2305.13711v1",
    "88": "2302.06706v1",
    "89": "2210.03629v3",
    "90": "1801.01423v3",
    "91": "2204.14198v2",
    "92": "2304.12995v1",
    "93": "2305.13172v3",
    "94": "2010.05731v1",
    "95": "2304.08485v2",
    "96": "2106.10328v2",
    "97": "2304.06027v2",
    "98": "2303.12712v5",
    "99": "2004.10151v3",
    "100": "2302.04023v4",
    "101": "2106.00737v1",
    "102": "2201.07207v2"
  },
  "chooseref": {
    "1": "2302.00487v3",
    "2": "2302.04023v4",
    "3": "1506.05869v3",
    "4": "2204.06031v1",
    "5": "1804.06893v2",
    "6": "2308.11432v7",
    "7": "2306.13549v4",
    "8": "2202.13169v3",
    "9": "cs/0004001v1",
    "10": "2110.01691v3",
    "11": "2104.01778v3",
    "12": "1511.06342v4",
    "13": "2110.04984v2",
    "14": "2308.04026v1",
    "15": "2210.05529v1",
    "16": "2010.11929v2",
    "17": "1706.03762v7",
    "18": "1908.06954v2",
    "19": "2304.12995v1",
    "20": "2302.07842v1",
    "21": "1910.13461v1",
    "22": "1810.04805v2",
    "23": "2301.12597v3",
    "24": "2211.05100v4",
    "25": "2007.14062v2",
    "26": "2310.10021v2",
    "27": "2302.09185v1",
    "28": "2307.02485v2",
    "29": "2305.11738v4",
    "30": "2210.05499v2",
    "31": "2302.02676v8",
    "32": "2201.11903v6",
    "33": "2303.08268v3",
    "34": "2305.14323v3",
    "35": "2306.03901v2",
    "36": "2308.07201v1",
    "37": "2302.12813v3",
    "38": "2305.14763v1",
    "39": "2309.02427v3",
    "40": "2303.09752v3",
    "41": "2106.06103v1",
    "42": "2304.06027v2",
    "43": "2211.12701v2",
    "44": "2211.11501v1",
    "45": "1802.05365v2",
    "46": "1706.03741v4",
    "47": "1701.07274v6",
    "48": "2302.01560v3",
    "49": "2105.02446v6",
    "50": "2204.01691v2",
    "51": "1909.10705v1",
    "52": "2004.10964v3",
    "53": "2308.06391v1",
    "54": "2104.08164v2",
    "55": "2305.13172v3",
    "56": "2203.11258v1",
    "57": "1903.08254v1",
    "58": "2305.15021v2",
    "59": "2206.07682v2",
    "60": "2212.09196v3",
    "61": "2304.05332v1",
    "62": "2305.19118v4",
    "63": "1906.01076v3",
    "64": "2308.10144v3",
    "65": "2004.10151v3",
    "66": "1811.11682v2",
    "67": "1910.10683v4",
    "68": "2301.13379v3",
    "69": "2104.08786v2",
    "70": "1905.09263v5",
    "71": "2109.01652v5",
    "72": "2204.14198v2",
    "73": "2306.12672v2",
    "74": "2303.08774v6",
    "75": "1810.00123v3",
    "76": "2304.03442v2",
    "77": "1611.06216v1",
    "78": "1706.08840v6",
    "79": "1905.06566v1",
    "80": "1911.12543v2",
    "81": "2111.09509v1",
    "82": "2002.08910v4",
    "83": "1806.10729v5",
    "84": "2212.02499v2",
    "85": "2106.00737v1",
    "86": "1805.10886v1",
    "87": "2305.14325v1",
    "88": "2305.10142v1",
    "89": "2204.02515v1",
    "90": "2207.05608v1",
    "91": "2305.06500v2",
    "92": "2305.13246v1",
    "93": "2307.11019v3",
    "94": "2304.01746v1",
    "95": "2306.14824v3",
    "96": "2304.11477v3",
    "97": "2305.16300v2",
    "98": "2302.14045v2",
    "99": "2005.14165v4",
    "100": "2212.01681v1",
    "101": "2201.07207v2",
    "102": "2210.07128v3",
    "103": "2205.11916v4",
    "104": "2302.00093v3",
    "105": "1602.03483v1",
    "106": "1802.01604v1",
    "107": "2009.14715v3",
    "108": "1704.01444v2",
    "109": "2308.01399v2",
    "110": "1606.09282v3",
    "111": "2205.10625v3",
    "112": "2010.11939v3",
    "113": "2302.13971v1",
    "114": "2305.13711v1",
    "115": "2212.04088v3",
    "116": "2112.07916v2",
    "117": "2303.12528v4",
    "118": "2205.00445v1",
    "119": "2306.09093v1",
    "120": "1708.02072v4",
    "121": "2308.01542v1",
    "122": "2206.06520v1",
    "123": "1810.03548v1",
    "124": "1802.07245v1",
    "125": "2304.10592v2",
    "126": "2105.01601v4",
    "127": "2110.02178v2",
    "128": "2304.04675v4",
    "129": "2106.13884v2",
    "130": "2305.04790v3",
    "131": "2110.08207v3",
    "132": "1103.0398v1",
    "133": "2301.02111v1",
    "134": "1711.00937v2",
    "135": "2212.12017v3",
    "136": "2304.00008v5",
    "137": "2302.06706v1",
    "138": "2304.04370v6",
    "139": "1910.07104v1",
    "140": "1612.00796v2",
    "141": "1801.01423v3",
    "142": "2303.03378v1",
    "143": "2305.16355v1",
    "144": "2305.02412v2",
    "145": "1312.5602v1",
    "146": "2010.05731v1",
    "147": "2106.10328v2",
    "148": "2301.12314v1",
    "149": "2202.01279v3",
    "150": "2305.14322v2",
    "151": "2305.08844v2",
    "152": "2305.16843v1",
    "153": "2210.03629v3",
    "154": "2305.14992v2",
    "155": "2004.13637v2",
    "156": "2303.11366v4",
    "157": "2104.05837v2",
    "158": "2002.04833v4",
    "159": "2305.18323v1",
    "160": "2212.04356v1",
    "161": "2210.11416v5",
    "162": "2001.08361v1",
    "163": "2205.09712v1",
    "164": "2305.14623v2",
    "165": "2203.11171v4",
    "166": "2305.14497v2",
    "167": "2303.17651v2",
    "168": "2106.07447v1",
    "169": "2303.08896v3",
    "170": "2309.01219v3",
    "171": "2303.12712v5",
    "172": "2109.03888v1",
    "173": "2305.17390v2",
    "174": "2204.11792v1",
    "175": "2211.12433v2",
    "176": "2109.01355v1",
    "177": "2304.08354v3",
    "178": "2302.04761v1",
    "179": "2001.09977v3",
    "180": "2212.10403v2",
    "181": "2305.15408v5",
    "182": "2012.12877v2",
    "183": "2203.02155v1",
    "184": "2110.14168v2",
    "185": "2304.03373v2",
    "186": "2009.07888v7",
    "187": "2305.10601v2",
    "188": "2206.08916v2",
    "189": "2305.01625v3",
    "190": "2308.00436v3",
    "191": "2306.05424v2",
    "192": "2306.02858v4",
    "193": "2305.06355v2",
    "194": "2304.08485v2",
    "195": "2209.00647v1",
    "196": "2305.16291v2",
    "197": "2112.09332v3",
    "198": "2107.06277v1",
    "199": "2305.04160v3",
    "200": "2003.14080v1"
  }
}