{
  "survey": "Graph Retrieval-Augmented Generation (GRAG) represents a significant advancement in the integration of graph neural networks (GNNs) and knowledge graphs (KGs) with information retrieval systems to enhance data generation processes. This survey provides a comprehensive overview of GRAG, highlighting its transformative potential in improving the accuracy and contextual relevance of large language models (LLMs) in knowledge-intensive tasks such as open-domain question answering and complex query scenarios. The deployment of frameworks like GRAG exemplifies the potential of retrieval-augmented generation methods in scenarios requiring sophisticated reasoning capabilities, outperforming traditional approaches by leveraging structured graph-based information. Innovative methodologies such as the ENGINE framework and the KD-CoT method demonstrate enhanced training and inference efficiency, optimizing the data generation process through dynamic strategies. The adaptability of systems like RAG4DyG in dynamic graph modeling further establishes their effectiveness in improving predictive accuracy and adaptability. The integration of KG-Agent showcases the effectiveness of leveraging knowledge graphs to enhance reasoning capabilities, contributing to the advancement of retrieval-augmented generation systems. This survey underscores the transformative impact of integrating GNNs and KGs with information retrieval systems, highlighting the potential for these methodologies to advance the capabilities of data generation processes, enhancing accuracy, efficiency, and contextual relevance across diverse applications.\n\nIntroduction Motivation and Purpose The motivation for utilizing graph retrieval-augmented generation lies in enhancing generative models' capabilities to answer questions effectively by integrating knowledge from pre-trained language models and knowledge graphs. This integration addresses challenges in identifying relevant knowledge and performing joint reasoning [1], ultimately aligning outputs with user intent, which is essential for complex reasoning and precise information retrieval [2]. Graph Retrieval-Augmented Generation (GRAG) specifically aims to surpass the limitations of traditional Retrieval-Augmented Generation methods, which often struggle with networked documents such as citation graphs and social media [3]. Enhancing the reasoning abilities of large language models over knowledge graphs is crucial for providing accurate and contextually relevant responses to complex questions [4]. This survey explores the role of large language models in knowledge representation and processing, focusing on the integration of symbolic knowledge and the enhancement of traditional knowledge bases [5]. By summarizing challenges and solutions in complex Knowledge Base Question Answering, the survey addresses semantically or syntactically complicated questions, optimizing the retrieval-augmented generation process [6]. Significance of Structured Information Structured information is vital for improving the accuracy and relevance of data generated by large language models (LLMs), providing a framework that aligns outputs with user intent and enhances content reliability [2]. The integration of structured data, particularly knowledge graphs (KGs), significantly augments LLM capabilities, enabling a better understanding and manipulation of complex world knowledge [5]. This integration is essential in multi-hop reasoning tasks, where combining textual and topological information, as demonstrated by the GRAG framework, notably enhances performance [3]. Furthermore, structured information necessitates verification mechanisms to detect errors in both outputs and the underlying knowledge utilized by knowledge-augmented language models [7]. Leveraging dynamic external data through structured information improves the accuracy and reliability of generated outputs, as highlighted in recent surveys on data generation processes [8]. Additionally, structured information supports the creation of benchmarks, such as KILT, that facilitate component reuse across tasks and accelerate research into task-agnostic memory architectures [9]. The reciprocal benefits of utilizing graph structures to enhance LLM capabilities are evident in how LLMs can improve Graph Machine Learning (Graph ML) performance [10]. This symbiotic relationship underscores the importance of structured information in advancing retrieval-augmented generation, optimizing the accuracy and contextual relevance of generated data. Moreover, structured information is crucial for developing effective evaluation benchmarks that assess the performance of Retrieval-Augmented Generation (RAG) systems, focusing on their integration of retrieval and generation components [11]. Structure of the Survey The survey is systematically organized to provide a comprehensive exploration of Graph Retrieval-Augmented Generation (GRAG). It begins with an introduction that highlights the integration of graph neural networks and knowledge graphs with information retrieval techniques, establishing the significance of structured graph-based information for enhanced accuracy and contextual relevance in data generation. Following the introduction, Section 2 delves into the background and core concepts, offering an overview of fundamental theories related to graph neural networks, knowledge graphs, and information retrieval. It elucidates the interactions among these components and their contributions to retrieval-augmented generation. Section 3 focuses on the role of graph neural networks in retrieval-augmented generation, discussing methodologies and architectures that integrate GNNs with retrieval systems, as well as advancements in question answering facilitated by GNNs. Section 4 explores the intricacies of knowledge graphs, examining their dense and structured representation of factual information and their integration into retrieval systems to enhance information retrieval and link prediction. It highlights how knowledge graphs can alleviate the information overload problem in fields like biomedical research by surfacing rare associations between entities and improving retrieval performance. Additionally, it discusses innovative frameworks, such as retrieve-and-read models and hybrid approaches that combine embedding similarity with knowledge graph retrieval methods, enhancing precision and recall in retrieval systems and offering potential improvements to question-answering models [12,13,14]. This section also addresses innovative integration techniques and the leveraging of temporal and contextual information, along with the role of commonsense reasoning in enhancing the generation process. Section 5 scrutinizes information retrieval techniques, contrasting traditional and modern methods while assessing their strengths and limitations, including the performance metrics and evaluation techniques used to gauge retrieval methods. Section 6 delves into real-world applications and case studies where Graph Retrieval-Augmented Generation (GRAG) has been effectively implemented, highlighting its success in managing complex query scenarios, such as multi-hop reasoning on textual graphs, applications in the medical domain, and tasks involving knowledge base completion and fact verification. GRAG's innovative approach integrates textual and topological information into Large Language Models (LLMs), enabling enhanced comprehension and utilization of graph contexts, thereby outperforming traditional Retrieval-Augmented Generation (RAG) methods [15,3]. Finally, Section 7 identifies current challenges in the field, discussing potential solutions and future research directions, including scalability, efficiency, and ethical considerations. The survey concludes by summarizing key points and emphasizing the importance of integrating graph neural networks and knowledge graphs with information retrieval for improved data generation.The following sections are organized as shown in . Background and Core Concepts Graph Neural Networks and Their Role in Retrieval Graph Neural Networks (GNNs) significantly enhance retrieval systems by capturing complex relationships within knowledge bases, addressing the limitations of traditional Pre-trained Language Models (PLMs) [16]. They facilitate iterative retrieval processes and reasoning, crucial for tackling complex questions and improving generative models in open-domain question answering [1]. Integrating GNNs with large language models (LLMs) through approaches like Think-on-Graph (ToG) enables LLMs to dynamically interact with knowledge graphs (KGs), enhancing reasoning and interaction with external knowledge sources [17]. GNNs provide a structured framework for semantic matching, particularly beneficial for long-tail queries often overlooked by conventional methods. The Graph Retrieval-Augmented Generation (GRAG) system employs a divide-and-conquer strategy for efficient retrieval of optimal textual subgraphs, addressing traditional Retrieval-Augmented Generation (RAG) methods' focus on individual documents. By incorporating textual and topological information into LLMs, GRAG enhances dynamic graph predictions, significantly improving multi-hop reasoning and adaptability in dynamic scenarios [18,19,3]. Innovative frameworks like GraphRAG construct indices from source documents to enable query-focused summarization over large text corpora [20]. Methodologies such as GraphSAGE generate node embeddings by sampling and aggregating features from local neighborhoods, providing robust inductive frameworks for tasks requiring representations of local structure and node features [21]. This approach is particularly advantageous for multi-hop Question Answering over Knowledge Graphs (KGQA), where answer entities may be multiple hops away from topic entities [22]. GNNs also verify and modify reasoning traces in structured multi-round QA formats, allowing LLMs to effectively interact with external knowledge sources [23]. Benchmarks like KILT are crucial for addressing challenges in open-domain question answering, fact-checking, slot filling, and entity linking [9]. Moreover, benchmarks such as RiddleSense emphasize the need for targeted evaluation of natural language understanding systems, particularly those struggling with riddle-style questions [24]. GNNs enhance retrieval systems by improving reasoning capabilities, integrating structured data, and evaluating retrieval components. These methodologies and frameworks are pivotal for advancing retrieval-augmented generation, enabling more accurate and contextually relevant information generation while addressing traditional LLMs' limitations. Challenges in Knowledge Base Question Answering (KBQA) are tackled through these innovative approaches, focusing on understanding question semantics and knowledge from knowledge bases (KBs) [25]. Additionally, integrating symbolic knowledge structures with large language models highlights the necessity for knowledge-augmented language modeling [5]. Knowledge Graphs: Structure and Integration Knowledge graphs (KGs) are essential in enhancing retrieval-augmented generation by providing structured repositories that bolster large language models' (LLMs) reasoning capabilities. Integrating KGs into retrieval systems leverages structured knowledge to improve accuracy and contextual relevance, facilitating effective data retrieval and reasoning. Constructing KGs where nodes represent passages and document structures, and edges denote semantic and structural relationships, fosters better contextual understanding and retrieval efficiency [26]. In the medical domain, integrating KGs with ranking techniques significantly improves question-answering task accuracy [27]. This integration is crucial for addressing Knowledge Base Question Answering (KBQA) challenges, where extensive search space and disconnection between retrieval and reasoning processes necessitate innovative solutions [22]. KGs' structured representation helps overcome traditional limitations such as inefficiencies and error accumulation in natural language processing tasks [28]. Innovative methodologies in KG integration focus on designing foundation models capable of learning transferable representations for inference on any graph, addressing the need for adaptable and efficient knowledge graph models [29]. Selective downsampling of over-represented biomedical concepts within KGs enhances relevant information retrieval, demonstrating KGs' potential to refine and optimize data generation processes [13]. KG integration into retrieval systems enhances LLM reasoning capabilities and reduces computational costs by providing relevant external knowledge supporting more accurate and contextually relevant responses [30]. Organizing current methods into stages such as knowledge-augmented language modeling and symbolic reasoning enhancement addresses existing method limitations and advances retrieval-augmented generation [5]. KGs' structure and integration optimize retrieval-augmented generation processes by effectively capturing long-tail knowledge, accommodating document structures, and enhancing coherent and contextually relevant information retrieval, as evidenced by advancements in biomedical research, interdisciplinary science, and knowledge graph link prediction frameworks [31,13,14,12,32]. By addressing information overload challenges and ensuring effective access to relevant knowledge, KGs significantly contribute to generating more accurate and contextually relevant data, advancing retrieval systems' capabilities. Evolution and Current State of Technologies The evolution of graph neural networks (GNNs), knowledge graphs (KGs), and information retrieval technologies has been marked by significant advancements and persistent challenges, shaping retrieval-augmented generation systems. GNNs have evolved from basic models to sophisticated architectures capable of managing complex data structures, enhancing retrieval processes. Despite advancements, existing methods struggle to efficiently retrieve and reason over relevant information from dense KG subgraphs, limiting effectiveness in answering multi-hop and multi-entity questions [33]. Integrating large language models (LLMs) with Graph Machine Learning (Graph ML) aims to improve generalization, transferability, and few-shot learning capabilities while addressing challenges like graph heterophily and out-of-distribution (OOD) generalization [10]. Knowledge graphs are integral to retrieval systems, providing structured repositories that enhance reasoning capabilities and data retrieval accuracy. A core issue in using KGs is answering complex natural language questions using structured information, necessitating intricate reasoning and data retrieval mechanisms [6]. Existing benchmarks' limitations highlight the need for computationally expensive custom knowledge source indexing, revealing a gap in evaluating LLM performance on diverse graph-related tasks [9]. Information retrieval technologies have improved, particularly in open-domain question answering tasks. Conventional Retrieval-Augmented Generation (RAG) methods are inadequate in domains like pharmaceutical regulatory compliance due to inherent structural issues [34]. Static LLM limitations, especially their inability to incorporate real-time external information, can lead to potentially inaccurate or outdated responses [8]. The inefficiency of methods like BERT and RoBERTa in processing large sentence collections for semantic similarity due to high computational costs underscores the need for methodological advancements [35]. Current technologies reveal limitations in existing dropout methods, less effective on self-attention-based models, relevant to understanding retrieval-augmented generation methodologies' evolution [36]. These advancements reflect a trajectory of increasing complexity and capability, essential for addressing existing systems' limitations and enhancing retrieval-augmented generation, paving the way for more accurate and contextually relevant data generation. Graph Neural Networks in Retrieval-Augmented Generation Graph Neural Networks (GNNs) are integral to retrieval-augmented generation, enhancing information retrieval efficiency and effectiveness. This section delves into frameworks and architectures utilizing GNNs, highlighting their role in integrating graph-based knowledge into generative models. illustrates the hierarchical structure and integration of GNNs within retrieval-augmented generation systems. It categorizes the frameworks and architectures, methodologies for integration, and enhancements in question answering, thereby showcasing the innovative approaches and advanced methods employed to optimize retrieval systems and enhance generative capabilities. This visual representation not only complements the textual discussion but also reinforces the significance of GNNs in the evolving landscape of information retrieval. Frameworks and Architectures GNNs are integrated into retrieval systems through diverse frameworks, each leveraging external knowledge sources to enrich generative processes [37]. Graph Convolutional Networks (GCNs) are pivotal, performing convolution operations on graph data to derive node representations from node features and graph connectivity [38]. This architecture is essential for robust graph-based information integration. Innovative approaches like ENGINE enhance textual graph processing by combining a large language model encoder with a GNN [39]. Hierarchical Graph Attention Networks (HGAN) introduce hierarchical structures to improve information aggregation, addressing graph bottlenecks [40]. Graph Attention Networks (GATs) optimize retrieval systems by enabling nodes to weigh neighboring features differently, maximizing graph-based information utilization [41]. Graph transformers are categorized by depth, scalability, and pre-training strategies, offering a structured application approach [42]. This taxonomy advances retrieval-augmented generation by producing accurate and contextually relevant information while overcoming traditional retrieval system limitations. Additionally, organizing methods by retriever techniques, retrieval fusion strategies, and evaluation benchmarks underscores a structured enhancement approach [43]. Frameworks categorizing Med-LLMs by foundational technology, applications, and ethical considerations provide insights into GNNs' domain-specific integration [44]. These methodologies are organized by application areas and model structures, guiding implementation across translation, dialogue systems, and knowledge-intensive tasks. This comprehensive categorization enhances retrieval systems by effectively incorporating GNNs, advancing retrieval-augmented generation across domains. As illustrated in , the categorization of frameworks and architectures relevant to Graph Neural Networks, Graph Attention Networks, and Retrieval-Augmented Generation techniques is highlighted, showcasing key methodologies such as GCNs, ENGINE, HGAN, GATs, and Med-LLMs. Methodologies for Integration GNN integration into retrieval-augmented generation systems employs diverse methodologies to optimize interactions between language models and structured knowledge sources. Sentence-BERT (SBERT) modifies the pretrained BERT network using siamese and triplet structures, generating efficient sentence embeddings for semantic matching [35]. This methodology is crucial for optimizing retrieval systems. Fine-tuning language models with human feedback enhances retrieval-augmented generation by aligning models with user intent and relevance [2]. KG-Agent exemplifies an autonomous framework integrating an LLM with a multifunctional toolbox, a KG-based executor, and knowledge memory, facilitating complex reasoning over knowledge graphs [4]. This integration underscores structured reasoning's importance in optimizing generative model performance. Keqing aids LLMs in retrieving and reasoning about structured information from knowledge graphs to address complex queries [45]. This methodology emphasizes seamless retrieval and reasoning integration, enhancing generative capabilities in intricate scenarios. These methodologies illustrate diverse strategies for GNN integration into retrieval-augmented generation systems, enhancing generative models through improved structured knowledge interactions. The adaptability and versatility of these strategies significantly advance retrieval-augmented generation, incorporating effective information retrieval processes and addressing challenges like knowledge updating and long-tail data handling. Structure-aware retrieval models further enhance accuracy and contextual relevance, particularly in interdisciplinary scientific tasks, by considering document structures and relationships [46,32]. Enhancements in Question Answering GNNs have significantly advanced question answering systems by integrating sophisticated reasoning capabilities and optimizing retrieval-augmented generation processes. The Multi-Hop Graph Relation Network (MHGRN) exemplifies this advancement by enhancing complex question answering tasks through multi-hop relational reasoning modules in pre-trained language models [47]. This integration is vital for deep reasoning tasks, enabling accurate and contextually relevant answers. Innovative methodologies like DecAF showcase joint reasoning effectiveness in question answering over knowledge bases, achieving state-of-the-art accuracy across benchmarks [48]. SBERT enhances performance by reducing computation time for similar sentence pair identification while maintaining semantic matching accuracy [35]. This efficiency is crucial for processing large-scale datasets and complex queries. The TIARA framework combines multi-grained retrieval with constrained decoding, improving Knowledge Base Question Answering (KBQA) model performance [25]. This approach addresses natural language ambiguity and variability challenges, often hindering KBQA systems [6]. RiddleSense strengthens commonsense reasoning evaluation, providing a focused dataset that enhances question answering systems in complex reasoning tasks [24]. Integrating GNNs into question answering systems marks a significant advancement in retrieval-augmented generation, enhancing the ability to identify and utilize relevant knowledge from large knowledge graphs and perform joint reasoning with pre-trained language models. Models like QA-GNN connect QA context with knowledge graphs, facilitating structured reasoning and interpretable responses, including handling negation in complex queries. Leveraging passage retrieval with generative models aggregates evidence from multiple sources, improving response accuracy and contextual relevance, as demonstrated by state-of-the-art results on open-domain benchmarks like Natural Questions and TriviaQA [1,49]. These methodologies highlight GNNs' potential to enhance reasoning processes and optimize interactions between language models and structured graph-based information, advancing question answering capabilities. Knowledge Graphs and Their Integration Innovative Integration Techniques Integrating knowledge graphs into retrieval systems has notably advanced retrieval-augmented generation by facilitating precise and context-rich data generation. The RoK framework exemplifies this by merging chain of thought reasoning with PageRank to efficiently retrieve subgraphs likely containing answers, optimizing retrieval processes [50]. In specialized domains like medicine, KG-Rank employs ranking techniques on medical knowledge graph triplets, enhancing answer accuracy through domain-specific integration [27]. ULTRA further contributes by enabling universal graph representation learning, adaptable across various knowledge graphs, addressing benchmark limitations [29]. Bridgingth enhances retrieval by filtering irrelevant subgraphs using a linearization strategy and interval attention mechanism [51]. UniKGQA improves multi-hop question handling over knowledge graphs, emphasizing seamless integration of retrieval and reasoning [22]. Think-on-Graph (ToG) optimizes knowledge graph integration through dynamic exploration and iterative beam search [17]. RAG4DyG employs context-aware contrastive learning to enhance retrieval-augmented generation by integrating historical contexts [18]. Keqing exemplifies advanced techniques by decomposing complex questions, retrieving relevant entities, and generating responses with interpretable reasoning paths [45]. This is further illustrated in , which categorizes these innovative integration techniques into frameworks for knowledge graph integration, methods for retrieval enhancement, and advanced reasoning techniques. These techniques underscore the transformative potential of knowledge graphs in retrieval-augmented generation systems, addressing traditional retrieval limitations and enhancing accuracy and contextual relevance, notably in biomedical and financial applications [13,15]. Leveraging Temporal and Contextual Information Incorporating temporal and contextual information within knowledge graphs enhances data generation by structuring dynamic knowledge representation. This is particularly beneficial for multi-hop question answering (MQA) tasks, where temporal contexts improve model performance [52]. Temporal knowledge integration allows retrieval-augmented systems to capture time-dependent nuances, enhancing accuracy and contextual relevance. By structuring temporal information, language models navigate complex temporal relationships, crucial for time-sensitive tasks, allowing effective discernment and leverage of temporal patterns [53,32,54,49]. Contextual information refinement ensures relevance during data generation, enhancing interaction between structured temporal data and generative processes. Frameworks like KnowledgeNavigator and GenTKGQA facilitate multi-hop reasoning and generative question answering on temporal knowledge graphs, navigating complex constraints for optimal path retrieval and structured knowledge integration [55,56]. The strategic incorporation of temporal and contextual information represents significant advancement in retrieval-augmented generation, producing outputs aligned with specific temporal and contextual nuances, utilizing dynamic memory decay mechanisms and context modeling to capture long-range semantic dependencies [31,13,18,32,54]. Commonsense Reasoning and Knowledge Integration Commonsense reasoning is crucial for integrating knowledge graphs with retrieval systems, enhancing generation accuracy and contextual relevance. QA-GNN exemplifies this by leveraging knowledge graphs to improve reasoning capabilities in question answering tasks [1]. Structured reasoning frameworks like DARA enhance commonsense reasoning integration, facilitating nuanced reasoning processes [57]. MHGRN advances integration by unifying path-based reasoning with graph neural networks, enabling effective multi-hop reasoning and improved interpretability [47]. DecAF demonstrates improved accuracy through joint generation of logical forms and answers, showcasing free-text retrieval effectiveness [48]. Mintaka introduces complex question types and multilingual approaches, enriching commonsense reasoning evaluation [58]. SubgraphRe enhances retrieval accuracy and reduces reasoning bias, providing robust solutions for multi-hop KBQA [59]. Integrating commonsense reasoning marks significant advancement in retrieval-augmented generation, enhancing long-tail knowledge capture, particularly in biomedical research, by leveraging structured commonsense knowledge graphs and novel retrieval methods [60,61,13]. This hybrid approach improves precision, recall, and transparency in complex question-answering tasks across domains. Information Retrieval Techniques Traditional Retrieval Methods Traditional retrieval methods are foundational in information retrieval systems, primarily using rule-based approaches and sparse representations for data extraction and query resolution. These methods involve entity span detection, entity disambiguation, and relation classification, which can lead to error propagation in complex reasoning scenarios [7]. Their limitations are evident in domain-specific question answering with large language models (LLMs), where challenges such as interpreting specialized jargon hinder retrieval accuracy [62]. A significant challenge is the reliance on direct semantic relationships, often neglecting nuanced and indirect relationships crucial for comprehensive data retrieval [63]. This dependency constrains retrieval processes, especially for long-tail queries where semantic gaps are prevalent [63]. Moreover, traditional methods often struggle to generate executable logical forms that are semantically and syntactically correct, a critical challenge in Knowledge Base Question Answering (KBQA) [25]. Despite these challenges, traditional retrieval methods are integral to the evolution of retrieval-augmented generation systems. Their integration with state-of-the-art generative models, such as Keqing, which utilizes KBQA datasets, underscores their ongoing relevance [45]. Innovative strategies like MHGRN perform multi-hop, multi-relational reasoning over subgraphs from external knowledge graphs, exemplifying advancements aimed at overcoming traditional methods' limitations [47]. Experiments with benchmarks such as WebQSP, FreebaseQA, and GrailQA highlight the necessity for improved verification mechanisms to optimize text generation [48]. Incorporating user feedback mechanisms, akin to those in InstructGPT, presents promising avenues for enhancing outputs to align more closely with user intent [2]. Evaluating these methods on datasets like HSGE further emphasizes their foundational role in retrieval systems [54]. While traditional methods provide essential capabilities for data extraction and query resolution, they require enhancements to meet modern information retrieval tasks' demands. Their integration with graph-based data structures and innovative retrieval strategies, such as HybridRAG and GRAG, offers promising opportunities for advancing retrieval-augmented generation systems. These approaches facilitate generating more accurate and contextually relevant information, effectively capturing long-tail knowledge, mitigating information overload, and enhancing question-answering capabilities across various domains, including biomedical and financial sectors [46,13,18,15,3]. Modern Retrieval Methods Modern retrieval methods have evolved to address the complexities of graph-based data, significantly enhancing retrieval-augmented generation processes. As illustrated in , these methods can be classified into three primary categories: Graph-based Techniques, Hybrid Approaches, and Innovative Techniques. Each category encompasses methods that enhance retrieval-augmented generation processes by integrating structured data, hybrid frameworks, and advanced tuning techniques. These methods utilize sophisticated techniques to integrate language models with structured graph-based information, improving data generation tasks' accuracy and contextual relevance. By combining Retrieval Augmented Generation (RAG) with knowledge graphs, these approaches tackle information overload in fields like biomedical research, capturing long-tail knowledge and surfacing new associations among entities such as drugs, genes, and diseases [64,13,65]. Temporal Knowledge Graph Question Answering (TKGQA) employs LLMs to extract temporal constraints and structural links from queries, optimizing the retrieval process [55]. The KG-to-Text method represents a significant advancement, transforming knowledge graph (KG) information into informative textual statements that LLMs can effectively utilize during question answering [66]. HybridRAG adapts techniques to manage the complexities of unstructured financial data, boosting retrieval accuracy and answer generation [15]. The KSL method further enhances knowledge retrieval capabilities [67]. In food testing, FoodGPT showcases modern retrieval methods adapted for structured knowledge and scanned documents [68]. StructGPT emphasizes structured frameworks in optimizing retrieval-augmented generation processes [69]. Modern retrieval methods also benefit from innovative dropout techniques like AttendOut, enhancing performance in self-attention models [36]. The KG-Agent method enables a small LLM to engage actively in reasoning by iteratively selecting tools and updating its memory [4]. Prefix-tuning allows large pretrained language models to adapt to specific tasks with minimal adjustments, improving efficiency in retrieval-augmented generation [70]. The KAPING method enhances zero-shot question answering by augmenting LLM inputs with relevant knowledge facts from a knowledge graph [30]. Modern retrieval methods have significantly advanced retrieval-augmented generation (RAG) by integrating sophisticated techniques, such as graph-based data retrieval, to address challenges like updating knowledge, handling long-tail data, and mitigating information overload. These advancements enhance AI-generated content's accuracy and robustness by combining large language models' intrinsic knowledge with dynamic external databases, enabling continuous knowledge updates and improved domain-specific information retrieval [46,13,71]. Performance Metrics and Evaluation Table provides a detailed overview of benchmarks employed in the evaluation of graph retrieval-augmented generation systems, highlighting their relevance in assessing model performance across different domains and task formats. Evaluating retrieval methods in graph retrieval-augmented generation systems is crucial for generating accurate and contextually relevant data. Performance metrics such as accuracy and F1-score assess models' effectiveness in utilizing graph-based knowledge to answer questions, providing insights into precision and recall capabilities. In knowledge-intensive tasks, particularly open-domain question answering and biomedical research, metrics evaluating the retrieval and generation of accurate responses are essential. Generative models benefit from integrating passage retrieval to enhance evidence aggregation. RAG methods and frameworks like KnowledGPT and KG-to-Text enhance LLMs by connecting them with external knowledge sources, addressing challenges like information overload and long-tail knowledge capture [31,13,49,66,72]. In evaluating GraphRAG, performance metrics focused on content richness and response variety highlight qualitative measures' importance in assessing answer quality [20]. The effectiveness of the Graph-Based Retriever was compared against traditional methods using precision and recall, underscoring the need for comprehensive evaluation techniques that account for retrieval accuracy and efficiency [13]. Comparative analysis of semantic parsing-based (SP-based) and information retrieval-based (IR-based) methods emphasizes their effectiveness in managing complex questions, with performance metrics guiding capability assessments [73]. Evaluating caching and dynamic early exit techniques in models like EfficientT156 involves analyzing model accuracy and training costs, highlighting trade-offs between performance and computational efficiency [39]. Accuracy is a critical metric in multiple-choice formats, as demonstrated in the RiddleSense benchmark, where it assesses model responses' correctness [24]. This metric is essential for evaluating models' performance in scenarios requiring precise and contextually relevant answers. Success rates in task-solving reasoning generation and improvements in feedback-augmented retrievers further illustrate comprehensive performance assessments' importance [23]. The selection of performance metrics and evaluation techniques is pivotal in advancing retrieval-augmented generation systems. By providing detailed insights into accuracy, efficiency, and contextual relevance, these metrics guide the development of more effective and reliable systems. They ensure generated data aligns with user expectations and task requirements, navigating challenges like information overload in biomedical research, leveraging passage retrieval for enhanced question answering, incorporating structural relationships in interdisciplinary scientific tasks, and optimizing similarity matching in patent phrase analysis [53,13,32,49]. Applications and Case Studies Applications in Complex Query Scenarios Graph retrieval-augmented generation systems significantly enhance complex query processing across diverse domains by integrating structured graph-based information to improve data retrieval and generation. These systems excel in multi-hop reasoning and intricate data retrieval, surpassing traditional methods in handling complex relationships within knowledge graphs [1]. In Knowledge Base Question Answering (KBQA), they enable precise responses to complex queries through structured knowledge graphs and advanced reasoning, facilitating efficient retrieval of relevant subgraphs for multi-entity and multi-hop questions, thereby improving accuracy and contextual relevance [22,47]. As illustrated in , the diverse applications of graph retrieval-augmented systems span various domains, underscoring their pivotal role in enhancing query processing, reasoning, and retrieval accuracy in complex scenarios such as knowledge base question answering, medical applications, e-commerce, and regulatory compliance. In medicine, these systems enhance query handling by efficiently navigating complex terminologies and relationships, thereby improving medical question answering accuracy [27]. E-commerce platforms utilize these systems for complex queries related to product recommendations and semantic matching, employing graph neural networks to capture intricate relationships within product databases, leading to more personalized recommendations [39]. Legal and regulatory compliance scenarios benefit from graph-based retrieval systems by retrieving relevant documents and guidelines, enhancing precision and contextual relevance [34]. The transformative potential of these systems is evident in their ability to integrate language models with structured graph-based information, enhancing the accuracy and contextual relevance of generated data across various domains. Techniques such as Retrieval Augmented Generation (RAG) and structure-aware retrieval effectively manage information overload and improve retrieval precision and recall, paving the way for more effective data generation and question-answering models across scientific disciplines [13,32]. Medical Domain Applications Graph retrieval-augmented generation systems hold significant promise in the medical domain by integrating structured graph-based information to enhance data retrieval and generation accuracy. The MedQA dataset is pivotal in advancing OpenQA systems, particularly in medical question answering, enabling systems to navigate complex medical terminologies and relationships, thereby improving response precision [74]. The MindMap method exemplifies practical applications in medical contexts, achieving notable improvements in inference accuracy and reasoning clarity through structured knowledge graphs [75]. DALK showcases the application of these systems in addressing specific medical conditions, such as Alzheimer's Disease, underscoring the versatility of graph-based retrieval systems in domain-specific queries [76]. KG-Rank highlights advancements in medical question answering by significantly improving ROUGE-L scores, reflecting its effectiveness in enhancing response accuracy [27]. The application of graph retrieval-augmented generation systems in the medical domain underscores their transformative potential. By integrating language models with structured graph-based retrieval methods, these systems markedly improve the accuracy and contextual relevance of generated data, addressing traditional retrieval limitations by capturing long-tail biomedical knowledge and managing information overload. The hybrid model combines embedding similarity and knowledge graph techniques, enhancing biomedical question-answering models and ensuring coherent and contextually relevant information retrieval. Incorporating document structure further improves the retrieval of interdisciplinary scientific content, facilitating more effective data generation processes in the medical field [13,32]. Knowledge Base Completion and Fact Verification Graph retrieval-augmented generation significantly enhances knowledge base completion and fact verification by leveraging structured graph-based information to improve accuracy and reliability. The KagNet framework exemplifies this advancement, achieving state-of-the-art performance on the CommonsenseQA dataset by utilizing structured commonsense knowledge for reasoning tasks [61]. This integration of graph-based reasoning enhances systems' capabilities to complete knowledge bases with accurate and contextually relevant information. FactKG further illustrates the potential of knowledge graphs in fact verification, providing a structured dataset that promotes the use of graph-based data for verifying facts [77]. This approach offers improvements in reliability and practicality, essential for ensuring accuracy in fact-checking scenarios. ChatKBQA achieves new state-of-the-art performance on standard KBQA datasets, showcasing its effectiveness in combining large language models (LLMs) with knowledge graphs for interpretable question answering that requires precise knowledge [78]. This integration emphasizes the importance of structured reasoning processes in optimizing generative model performance, particularly for tasks necessitating accurate fact verification and knowledge base completion. The application of graph retrieval-augmented generation in financial AI applications further highlights the versatility of these systems, stressing the necessity of selecting suitable LLM approaches tailored to specific tasks [79]. By leveraging structured graph-based information, these systems enhance the accuracy and contextual relevance of data generation processes, addressing traditional method limitations and paving the way for more effective knowledge base completion and fact verification. Challenges and Future Directions Advancements in graph retrieval-augmented generation systems confront several challenges that affect scalability and efficiency. As knowledge representation and retrieval techniques evolve, addressing these challenges is vital for developing robust systems. This section explores issues related to scalability and efficiency, focusing on constraints from knowledge graph quality, computational demands, and existing methodologies. Scalability and Efficiency Graph retrieval-augmented generation systems face scalability and efficiency challenges due to reliance on the quality and comprehensiveness of knowledge graphs, which are often incomplete or inaccurate [5]. This dependency impacts adaptability, especially for queries requiring extensive knowledge bases [3]. Computational overhead in identifying similar sentence pairs further hinders performance, with processing times reaching up to 65 hours for large datasets [35]. Such demands are pronounced in scenarios involving large knowledge graphs or complex queries, where existing methods struggle with efficiency and accuracy [25]. Moreover, large language models (LLMs) exhibit insufficient reasoning capabilities when interacting with knowledge graphs, limiting their effectiveness in complex tasks [4]. Pre-trained models like UniKGQA illustrate scalability issues, as their quality and size affect handling larger graphs [2]. Systems such as RAG4DyG show that the quality of retrieved examples can significantly impact performance, particularly when examples fail to represent the query context [45]. Long-tail queries further complicate scalability, requiring sophisticated methods to manage sparse semantic relationships effectively. Addressing these challenges involves refining graph construction mechanisms, enhancing error detection, and exploring new trends in knowledge representation [6]. Improving retrieval processes and reducing computational demands can broaden applicability and enhance performance. Ethical and Implementation Challenges Implementing graph retrieval-augmented generation systems presents ethical and operational challenges, mainly due to reliance on external knowledge sources and inherent biases. The quality of external knowledge graphs can compromise accuracy, raising ethical concerns about representing diverse cultural perspectives, as many frameworks reflect a Western-centric commonsense knowledge [80]. Training models like GreaseLM involve complexity and resource demands, presenting ethical implications regarding accessibility [81]. Deploying LLMs in educational contexts introduces data privacy risks and ethical concerns, necessitating strategies to mitigate these issues [11]. Integrating Med-LLMs poses challenges in ensuring fairness, accountability, privacy, and robustness, critical for acceptance in medical applications [44]. Benchmarks like Atomic2020 and CREAK face limitations in addressing commonsense reasoning comprehensively, potentially restricting broader applicability. Human evaluations introduce subjectivity, affecting performance assessment consistency [82]. Methods like TheWebasaKG depend on web information accuracy, influencing the quality of generated answers [72]. Addressing these challenges requires enhancing the quality and inclusivity of external knowledge sources. Integrating cultural differences, as demonstrated in the ATOMIC project, is one approach. Improving access to computational resources and developing robust evaluation frameworks incorporating diverse perspectives and ethical considerations are crucial. Insights from studies on generative AI in education emphasize fostering awareness and positive attitudes toward AI tools among educators, influencing integration into educational settings [83,80]. Future Research Directions Future research in graph retrieval-augmented generation should refine methodologies like Sentence-BERT (SBERT) to optimize semantic matching across natural language processing tasks [35]. Developing Large Knowledge Models (LKMs) that enhance cognitive alignment and integrate new knowledge representation methodologies offers significant potential [5]. Research initiatives should strengthen current methods for managing complex questions by exploring hybrid approaches combining semantic parsing-based and information retrieval-based methods [6]. Optimizing LLM interaction with complex graph structures through instruction fine-tuning is essential for enhancing scalability and system performance. Expanding datasets to include diverse cultural nuances and refining representation methods can advance the field, ensuring inclusivity and contextual relevance [5]. Enhancing frameworks like FABULA by integrating diverse data sources and enriching underlying knowledge graphs represents a promising avenue. Optimizing decomposition algorithms and reasoning techniques is crucial for improving retrieval-augmented generation (RAG) systems, addressing challenges like outdated knowledge, long-tail data handling, and data leakage while enhancing AI-generated content accuracy and robustness. Refining these algorithms can better integrate domain-specific information, reduce training and inference costs, and manage information overload, boosting RAG systems' performance and credibility across applications, including open-domain question answering and biomedical research [46,13,71,49]. Exploring novel retrieval techniques and enhancing AI-generated content applications will contribute to scalability and efficiency, particularly through advancements in embedding similarity techniques and optimized edge removal strategies. Conclusion The integration of graph neural networks (GNNs) and knowledge graphs (KGs) into information retrieval systems marks a pivotal advancement in enhancing data generation processes across diverse fields. This survey highlights how these integrations significantly improve the accuracy and contextual relevance of large language models (LLMs) in handling knowledge-intensive tasks, such as open-domain question answering and intricate query scenarios. The frameworks, exemplified by GRAG, demonstrate the superiority of retrieval-augmented generation methods by leveraging structured graph-based information. Innovative approaches, including the ENGINE framework, enhance training and inference efficiency, optimizing data generation through dynamic strategies. Additionally, methodologies like the KD-CoT method and TIARA framework underscore the importance of structured information in boosting model performance, particularly in reasoning generation and Knowledge Base Question Answering (KBQA). The adaptability of systems like RAG4DyG in dynamic graph modeling further substantiates their role in improving predictive accuracy and adaptability. The integration of KG-Agent showcases the advantages of utilizing knowledge graphs to enhance reasoning capabilities, surpassing existing methods and driving the development of retrieval-augmented generation systems. This survey underscores the transformative potential of combining GNNs and KGs with information retrieval systems, highlighting their capacity to improve accuracy, efficiency, and contextual relevance across a multitude of applications.",
  "reference": {
    "1": "2104.06378v5",
    "2": "2203.02155v1",
    "3": "2405.16506v3",
    "4": "2402.11163v1",
    "5": "2312.02706v2",
    "6": "2105.11644v1",
    "7": "2310.12836v1",
    "8": "2404.10981v2",
    "9": "2009.02252v4",
    "10": "2404.14928v2",
    "11": "2403.18105v2",
    "12": "2306.02871v1",
    "13": "2402.12352v1",
    "14": "2212.09724v3",
    "15": "2408.04948v1",
    "16": "1904.09537v1",
    "17": "2307.07697v6",
    "18": "2408.14523v2",
    "19": "2402.07630v3",
    "20": "2404.16130v2",
    "21": "1907.10903v4",
    "22": "2212.00959v2",
    "23": "2308.13259v2",
    "24": "2101.00376v2",
    "25": "2210.12925v1",
    "26": "2308.11730v3",
    "27": "2403.05881v3",
    "28": "2305.12416v1",
    "29": "2310.04562v2",
    "30": "2306.04136v1",
    "31": "2308.11761v1",
    "32": "2311.12289v1",
    "33": "2405.20139v1",
    "34": "2402.01717v1",
    "35": "1908.10084v1",
    "36": "1706.03762v7",
    "37": "2405.06211v3",
    "38": "1609.02907v4",
    "39": "2401.15569v2",
    "40": "2211.10991v1",
    "41": "1710.10903v3",
    "42": "2407.09777v2",
    "43": "2407.13193v3",
    "44": "2406.03712v2",
    "45": "2401.00426v1",
    "46": "2402.19473v6",
    "47": "2005.00646v2",
    "48": "2210.00063v2",
    "49": "2007.01282v2",
    "50": "2404.10384v1",
    "51": "2308.14436v1",
    "52": "2404.00492v1",
    "53": "2403.16265v1",
    "54": "2306.06872v1",
    "55": "2402.16568v2",
    "56": "2312.15880v2",
    "57": "2406.07080v1",
    "58": "2210.01613v1",
    "59": "2202.13296v2",
    "60": "2305.18742v1",
    "61": "1909.02151v1",
    "62": "2408.00798v1",
    "63": "2311.03758v3",
    "64": "2312.02783v4",
    "65": "2305.15066v2",
    "66": "2309.11206v2",
    "67": "2309.03118v1",
    "68": "2308.10173v1",
    "69": "2305.09645v2",
    "70": "2101.00190v1",
    "71": "2312.10997v5",
    "72": "1803.06643v1",
    "73": "2108.06688v5",
    "74": "2009.13081v1",
    "75": "2308.09729v5",
    "76": "2405.04819v4",
    "77": "2305.06590v2",
    "78": "2310.08975v3",
    "79": "2311.10723v2",
    "80": "1811.00146v3",
    "81": "2201.08860v1",
    "82": "2307.09288v2",
    "83": "2403.15586v1"
  },
  "chooseref": {
    "1": "2205.01841v1",
    "2": "2303.10395v1",
    "3": "2212.09724v3",
    "4": "2404.00579v2",
    "5": "2311.12399v4",
    "6": "2406.11903v1",
    "7": "2105.11644v1",
    "8": "2007.13069v1",
    "9": "2311.05232v2",
    "10": "2406.10303v2",
    "11": "2406.03712v2",
    "12": "2405.06211v3",
    "13": "2404.10981v2",
    "14": "2311.12289v1",
    "15": "1811.00146v3",
    "16": "2402.05952v1",
    "17": "2402.04978v2",
    "18": "2204.08109v3",
    "19": "2010.05953v2",
    "20": "1706.03762v7",
    "21": "1810.04805v2",
    "22": "2406.12608v2",
    "23": "2308.14436v1",
    "24": "2406.04744v2",
    "25": "2109.01653v1",
    "26": "2305.10037v3",
    "27": "1809.02789v1",
    "28": "2310.08975v3",
    "29": "1811.00937v2",
    "30": "2108.06688v5",
    "31": "2305.01157v3",
    "32": "2403.16265v1",
    "33": "1707.01476v6",
    "34": "2405.04819v4",
    "35": "2406.07080v1",
    "36": "2210.00063v2",
    "37": "2004.04906v3",
    "38": "2305.12416v1",
    "39": "1907.10903v4",
    "40": "2401.15569v2",
    "41": "2405.07437v2",
    "42": "1910.10683v4",
    "43": "2310.13848v2",
    "44": "2305.06590v2",
    "45": "2308.10173v1",
    "46": "2404.16130v2",
    "47": "2402.01717v1",
    "48": "2402.07630v3",
    "49": "2405.20139v1",
    "50": "2305.15066v2",
    "51": "2405.16506v3",
    "52": "2407.13193v3",
    "53": "2403.15586v1",
    "54": "1711.05851v2",
    "55": "2408.00798v1",
    "56": "2303.12320v2",
    "57": "1710.10903v3",
    "58": "2404.07103v3",
    "59": "2404.14928v2",
    "60": "2305.18742v1",
    "61": "2407.09777v2",
    "62": "2402.12352v1",
    "63": "2111.10541v4",
    "64": "2310.01089v1",
    "65": "2402.07197v4",
    "66": "2201.08860v1",
    "67": "2405.14831v3",
    "68": "2306.06872v1",
    "69": "1809.09600v1",
    "70": "2312.15883v2",
    "71": "2408.04948v1",
    "72": "2101.03737v2",
    "73": "1706.02216v4",
    "74": "2402.11163v1",
    "75": "2110.04330v2",
    "76": "2310.11220v1",
    "77": "2403.05881v3",
    "78": "2009.02252v4",
    "79": "1909.02151v1",
    "80": "1606.03126v2",
    "81": "2312.06185v5",
    "82": "2308.11761v1",
    "83": "2308.11730v3",
    "84": "2406.13862v1",
    "85": "2309.03118v1",
    "86": "2306.04136v1",
    "87": "2310.12836v1",
    "88": "2308.13259v2",
    "89": "2312.15880v2",
    "90": "2402.08170v3",
    "91": "2308.07134v5",
    "92": "2005.14165v4",
    "93": "2312.02706v2",
    "94": "2311.03758v3",
    "95": "2308.06374v1",
    "96": "2403.18105v2",
    "97": "2405.13055v1",
    "98": "2311.10723v2",
    "99": "2312.02783v4",
    "100": "1506.02075v1",
    "101": "2007.01282v2",
    "102": "2307.09288v2",
    "103": "2307.03172v3",
    "104": "2408.04187v2",
    "105": "2308.09729v5",
    "106": "2210.01613v1",
    "107": "2211.10991v1",
    "108": "2404.19234v1",
    "109": "2404.00492v1",
    "110": "2404.07677v2",
    "111": "1809.00782v1",
    "112": "1911.11641v1",
    "113": "2402.02216v3",
    "114": "2101.00190v1",
    "115": "1904.09537v1",
    "116": "2104.06378v5",
    "117": "2202.00120v2",
    "118": "2404.19543v2",
    "119": "2202.06129v1",
    "120": "2405.14431v1",
    "121": "2210.13650v1",
    "122": "2404.10384v1",
    "123": "2310.01061v2",
    "124": "2408.14523v2",
    "125": "2402.19473v6",
    "126": "2312.10997v5",
    "127": "2404.17723v2",
    "128": "2309.11206v2",
    "129": "2101.00376v2",
    "130": "2109.08678v2",
    "131": "1907.11692v1",
    "132": "2404.13207v3",
    "133": "2005.00646v2",
    "134": "1609.02907v4",
    "135": "1908.10084v1",
    "136": "2305.09645v2",
    "137": "2202.13296v2",
    "138": "2210.12925v1",
    "139": "2310.04560v1",
    "140": "2306.02871v1",
    "141": "2104.08691v2",
    "142": "1803.06643v1",
    "143": "2307.07697v6",
    "144": "2011.07743v6",
    "145": "2310.04562v2",
    "146": "2203.02155v1",
    "147": "1705.03551v2",
    "148": "2402.16568v2",
    "149": "2212.00959v2",
    "150": "2406.02110v1",
    "151": "2306.08302v3",
    "152": "1709.04071v5",
    "153": "2009.13081v1",
    "154": "1906.07348v1",
    "155": "2401.00426v1"
  }
}