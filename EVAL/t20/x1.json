{
  "survey": "Graph Retrieval-Augmented Generation represents a transformative approach in information retrieval, integrating graph neural networks (GNNs) and knowledge graphs (KGs) to enhance reasoning and inference capabilities. This survey comprehensively reviews the advancements in this domain, highlighting the significance of structured knowledge synthesis in overcoming the limitations of large language models (LLMs), particularly in complex queries requiring knowledge beyond their training data. The integration of GNNs and KGs is pivotal in domains such as biomedical research, where information overload is prevalent, and the need for accurate retrieval is critical. Innovative frameworks like MedGraphRAG and KagNet demonstrate superior performance across benchmarks, showcasing the potential of graph-based models in commonsense reasoning and dynamic graph modeling. Despite challenges in alignment, scalability, and the quality of knowledge graphs, the survey identifies promising research avenues, including hybrid integration strategies and interdisciplinary collaboration, to optimize retrieval processes. Future directions emphasize the importance of addressing hallucinations, enhancing cognitive alignment, and developing standards for hybrid knowledge representation. Ultimately, graph retrieval-augmented generation holds the promise of transforming information retrieval systems, offering robust, scalable, and adaptable solutions across diverse applications.\n\nIntroduction Significance of Graph Retrieval-Augmented Generation Graph retrieval-augmented generation marks a significant advancement in information retrieval by combining structured knowledge from knowledge graphs (KGs) with large language models (LLMs), thus enhancing reasoning capabilities across various natural language processing tasks [1]. This integration effectively addresses the limitations of LLMs, particularly in handling queries that require knowledge beyond their training data [2]. The role of structured knowledge is particularly critical in Knowledge Base Question Answering (KBQA), where accurate retrieval of factual information, such as entities and relations from Knowledge Bases (KBs), is essential. The impact of graph retrieval-augmented generation is especially pronounced in fields like biomedical research, where information overload is prevalent. The capability to retrieve significant yet rare knowledge through this approach is vital [3]. Moreover, combining passage retrieval with generative models enhances open-domain question answering by improving the understanding of logical associations among document contents and structures [4]. A core challenge remains the lack of transferable representations in knowledge graphs, which limits inference across diverse KGs with varying vocabularies of entities and relations. Addressing these limitations by incorporating graph structures into generative language modeling frameworks is crucial for improving retrieval outcomes, particularly in query-focused summarization (QFS) methods that struggle with large text corpora. Efficient modeling of rich textual and topological information in textual graphs is also vital for applications across various domains, including webpages, e-commerce, and academic articles [5]. The significance of graph retrieval-augmented generation extends to deep reasoning tasks, where integrating external knowledge profoundly influences LLM performance. In conversational KBQA, modeling context information is essential for managing long-range semantic dependencies in conversation history, a challenge often neglected by methods treating utterances independently. The History Semantic Graph Enhanced KBQA model (HSGE) exemplifies this by employing a context-aware encoder with dynamic memory decay, facilitating nuanced context modeling at various granularities. This approach is critical for adapting KBQA systems to specialized domains, particularly when labeled data is scarce. Furthermore, advancements in open-domain QA, such as the GRAFT-Net model, illustrate the effectiveness of combining knowledge bases with entity-linked text, highlighting the potential of context-aware models to operate efficiently without complete KBs. Generative models in open-domain QA also show promise by utilizing passage retrieval to enhance performance, emphasizing the importance of context aggregation in delivering accurate answers [6,7,8]. Graph retrieval-augmented generation represents a transformative advancement in information retrieval, with the potential to revolutionize applications by integrating structured knowledge with LLMs for more accurate and efficient retrieval systems across multiple domains. Motivation for the Survey This survey is motivated by the need to address critical gaps in graph retrieval-augmented generation, essential for enhancing the effectiveness of information retrieval systems across various applications. A significant gap exists in Knowledge Base Question Answering (KBQA), where current methodologies often fail due to inaccuracies when handling semantically or syntactically complex questions [9]. This survey aims to bridge this gap by investigating innovative approaches that integrate LLMs with knowledge graphs to improve reasoning accuracy and question answering capabilities [1]. Furthermore, inefficiencies in existing retrieval-augmented generation (RAG) methods, particularly in retrieving and integrating information from networked documents, necessitate a thorough investigation. These inefficiencies are especially evident in contexts involving complex relationships within textual subgraphs, requiring a comprehensive examination to optimize retrieval processes [4]. This survey also seeks to elucidate the reciprocal enhancement potential between LLMs and Graph Machine Learning (Graph ML), a critical area for the field's advancement [10]. Additionally, the survey addresses challenges faced by current query rewriting methods, which often struggle with optimizing long-tail queries and bridging the semantic gap. By proposing novel strategies for effective query handling, this survey aims to overcome these limitations [5]. The constraints of existing methods that narrowly focus on historical contexts, thus limiting adaptability to emerging patterns in dynamic graphs, further underscore the necessity for this comprehensive exploration [3]. Moreover, the survey aims to tackle the ongoing challenge of aligning LLMs with user intent, investigating strategies that better capture and reflect user needs [11]. The need for innovative approaches to enhance LLM reasoning capabilities over knowledge graphs highlights a significant gap in the literature that this survey intends to fill [12]. Ultimately, the survey aspires to provide a comprehensive understanding of the challenges and opportunities in integrating LLMs with knowledge graphs, emphasizing the development of more efficient, reliable, and transparent retrieval-augmented generation systems. This involves addressing LLM limitations, such as their tendency to overlook rare information in favor of frequently seen data, particularly in biomedical research where new discoveries are crucial. By leveraging knowledge graphs to downsample clusters of over-represented concepts, the survey aims to enhance retrieval performance, capturing the long-tail knowledge often missed by traditional RAG methods. Additionally, it explores the potential of combining embedding similarity and knowledge graph retrieval methods into hybrid models that exceed existing approaches, thereby improving biomedical question-answering systems and advancing knowledge representation through the hybridization of explicit and parametric knowledge [13,14]. Objectives of the Survey The primary objective of this survey is to propose a comprehensive framework, BEQUE, designed to bridge the semantic gap for long-tail queries, thereby enhancing retrieval processes in information retrieval systems [5]. This involves a detailed exploration of innovative approaches such as GRAG, which improves retrieval processes by considering the interconnected nature of documents, thereby enhancing multi-hop reasoning capabilities [4]. Additionally, the survey aims to outline objectives for enhancing the reasoning capabilities of LLMs when interacting with knowledge graphs to effectively answer complex queries [12]. A significant breakthrough is necessary to improve the effectiveness of existing methods in answering questions using pre-trained language models and knowledge graphs, which this survey aims to address [15]. The survey also seeks to explore methods for better aligning language models with user intent, focusing on innovative strategies like fine-tuning using human feedback [11]. The integration of symbolic knowledge with LLMs to create LKMs is proposed as a primary improvement, contrasting with previous methods that primarily focused on LLMs alone, thereby enhancing retrieval accuracy and reasoning capabilities [2]. Furthermore, the survey investigates methods such as the Knowledge-based Question Answering (Keqing) framework, which assists LLMs in retrieving relevant information and reasoning through complex questions [1]. Ultimately, the survey aspires to contribute to the development of advanced retrieval-augmented generation systems that are efficient, reliable, and capable of addressing the complexities of modern information retrieval tasks. Structure of the Survey The survey is systematically organized to explore the multifaceted domain of graph retrieval-augmented generation. It begins with an Introduction that elucidates the significance, motivation, and objectives of the survey, followed by an overview of the paper's organization. The Background and Core Concepts section provides foundational insights into graph neural networks, knowledge graphs, and their integration in information retrieval, defining key terms and concepts crucial for understanding subsequent sections. The survey then delves into Graph Neural Networks in Information Retrieval, discussing their applications, methods, techniques, and inherent challenges in processing graph-structured data [3]. This is complemented by the Knowledge Graphs and Their Integration section, which examines the structure, function, and integration challenges of knowledge graphs within retrieval processes [4]. The section on Retrieval-Augmented Generation Techniques explores techniques leveraging graph data to enhance information generation, focusing on state-of-the-art applications and methods for improvement [5]. The Evaluation and Benchmarking section highlights frameworks and benchmarks for assessing system performance, comparing them with baseline methods [11]. Finally, the survey addresses Challenges and Future Directions, identifying current integration challenges and proposing research avenues for interdisciplinary collaboration and standards development [12]. The survey concludes by summarizing key findings and emphasizing the transformative potential of integrating graph neural networks and knowledge graphs in information retrieval systems.The following sections are organized as shown in . Background and Core Concepts Fundamentals of Graph Neural Networks Graph Neural Networks (GNNs) are crucial for processing graph-structured data, capturing dependencies among nodes and edges to improve information retrieval. Central to GNNs are Graph Convolutional Networks (GCNs), which use convolutional layers to extract features from graph data [16]. Innovations like DropEdge address overfitting and over-smoothing in deep GCNs, enhancing model performance. The inductive framework of GraphSAGE expands GNN capabilities by generating node embeddings through sampling and aggregating features from local neighborhoods, improving scalability and applicability across domains [10]. This approach mitigates conventional GNN limitations, enhancing node representation in link prediction tasks. Attention mechanisms in GNN architectures, such as the Graph Attention Network (GAT), enable nodes to focus on neighbors' features through dynamically learned weights, improving reasoning and prediction accuracy [17]. The AttendOut method further refines these mechanisms within transformer architectures. The synthesis pipeline introduced by STaRK generates realistic queries that blend relational information with complex textual properties, emphasizing the need for diverse data types in GNN training [18]. BERT's deep bidirectional representations have laid the groundwork for merging textual and graph data [19]. Techniques like the answer-sensitive KG-to-Text approach improve Knowledge Base Question Answering (KGQA) by converting knowledge graph data into textual statements, enhancing retrieval outcomes. This highlights the importance of combining structured graph data with advanced language models for optimized information retrieval. Advancements in model capabilities, particularly in medical contexts [20], demonstrate GNNs' transformative potential in information retrieval. By leveraging graph structures and attention mechanisms, GNNs provide a robust framework for tackling complex retrieval tasks, enhancing the generation of relevant information. The interplay between ranking and generation processes further supports the effectiveness of these methods in addressing retrieval challenges [21]. Introduction to Knowledge Graphs Knowledge Graphs (KGs) enhance information retrieval systems by providing a structured framework for complex reasoning across domains. Constructed around entities and relations, KGs offer a rich source of factual information that enhances large language models (LLMs). Their structured nature facilitates the inference of indirect facts, crucial for tasks like question answering [22]. In Knowledge Base Question Answering (KBQA), KGs provide the factual backbone necessary for accurately answering natural language questions, integrating implicit knowledge alongside explicit structured data for sophisticated reasoning tasks [12]. KGs mitigate limitations of incomplete knowledge bases by synthesizing existing information to infer valid facts, demonstrated in retrieving relevant subgraphs for classification tasks [6,23]. Despite advantages, integrating KGs in information retrieval faces challenges, such as inefficiency in traditional fact retrieval processes, necessitating innovative optimization strategies [23]. Existing methods often lack mechanisms for LLMs to actively engage in reasoning, highlighting the need for dynamic integration approaches [12]. Information Retrieval and Its Challenges Traditional information retrieval (IR) systems face challenges, particularly amid complex data environments demanding accuracy and relevance. Generating factually incorrect responses due to inaccuracies and outdated knowledge within language models is a primary issue [24]. This is exacerbated by models' inability to comprehend and apply user instructions, resulting in misleading outputs [11]. The semantic gap leads to suboptimal performance in query rewriting methods and low recall for long-tail queries [5]. Excessive computational overhead from models like BERT and RoBERTa limits scalability and efficiency [25]. Traditional IR processes struggle to assess generative models' integration with passage retrieval due to insufficient benchmarks, constraining optimization [8]. This limitation is evident in addressing complex questions requiring commonsense reasoning, inadequately evaluated by current benchmarks [26]. Challenges related to natural language ambiguity and complex queries existing KBQA methods struggle to handle underscore the need for advanced retrieval techniques [9]. These challenges highlight the need for innovative methodologies and robust frameworks enhancing scalability, adaptability, and reliability of traditional IR processes. Generative models for open-domain question answering show promise but require significant computational resources, indicating a need for efficient passage retrieval methods. Advancements in semantic parsing and IR-based techniques are necessary to address KBQA complexities. The emergence of Retrieval-Augmented Generation (RAG) represents a paradigm shift, integrating retrieval processes to enhance AI-generated content while addressing issues like knowledge updates and data handling. These advancements underscore the necessity for frameworks leveraging external knowledge bases and managing computational costs, paving the way for accurate and robust information retrieval systems [27,28,29,8,9]. Integration of Graph Neural Networks and Knowledge Graphs Integrating Graph Neural Networks (GNNs) and Knowledge Graphs (KGs) enhances retrieval processes by synthesizing structured and relational data, improving inference and reasoning capabilities. This integration optimizes information quality and relevance through the combination of graph data with large language models (LLMs). The UniKGQA model exemplifies this by employing a unified architecture incorporating semantic matching and information propagation modules, enhancing retrieval and reasoning processes [30,6,31,32]. GraphRAG utilizes LLMs to construct entity knowledge graphs, emphasizing dynamic entity graphs for improved retrieval outcomes [4]. PullNet advances integration by constructing question-specific subgraphs and using graph convolutional networks to bolster retrieval and reasoning [15]. The Graph-Based Retriever (GBR) method combines knowledge graph retrieval with embedding similarity, enhancing biomedical information retrieval [10]. ENGINE introduces a tunable side structure integrating LLMs and GNNs, enhancing performance and efficiency [3]. Categorizing Retrieval-Augmented Generation (RAG) into pre-retrieval, retrieval, post-retrieval, and generation phases provides a framework for understanding GNN and KG integration [2]. KILT emphasizes task-agnostic memory architectures, improving efficiency and performance in knowledge retrieval [19]. Research in this domain is categorized into semantic parsing-based and information retrieval-based methods, offering a structured view of diverse approaches [9]. Integrating GNNs and KGs provides a robust framework for advancing retrieval processes, enabling sophisticated reasoning and information extraction capabilities. Innovative integration strategies addressing existing challenges significantly enhance retrieval-augmented generation (RAG) systems' accuracy, efficiency, and reliability. RAG systems combine retrieval methods with generative models, tackling challenges like knowledge updating and data leakage, improving performance by retrieving relevant information from external databases. This integration allows dynamic updates and domain-specific information incorporation, crucial for knowledge-intensive tasks. RAG systems offer cost-effective solutions by efficiently aggregating evidence from multiple sources, improving performance with increased retrieval. Organizing RAG into categories provides a framework for advancing RAG systems, highlighting their adaptability and potential across modalities and tasks [33,28,34,29,8]. Defining Key Terms and Concepts Graph retrieval-augmented generation encompasses complex terms and concepts essential for understanding methodologies and innovations discussed in this survey. These include overcoming naive retrieval methods' limitations through integrating textual and topological information from networked documents, enhancing biomedical question-answering models via hybrid approaches combining embedding similarity and knowledge graph retrieval, and employing efficient strategies for textual subgraph retrieval to improve multi-hop reasoning capabilities in large language models [4,13]. Graph Neural Networks (GNNs): GNNs process graph-structured data, capturing dependencies and interactions among nodes and edges for sophisticated representations and predictions. They are pivotal in processing relational data and enhancing information retrieval through architectures like Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs) [35]. Knowledge Graphs (KGs): KGs are structured knowledge representations consisting of entities, relations, and facts serving as a backbone for reasoning and retrieval tasks. They enable synthesis of existing information to infer valid facts, addressing incomplete datasets challenges and enhancing language model reasoning capabilities [36]. Retrieval-Augmented Generation (RAG): RAG integrates retrieval processes with generative models to improve relevant and accurate information generation, categorizing retrieval processes into pre-retrieval, retrieval, post-retrieval, and generation phases, optimizing structured and relational data synthesis for enhanced inference and reasoning [37]. Hyperparameter Tuning and Data Size: Hyperparameter tuning and data size are emphasized in language model pretraining, where optimal configurations and sufficient data are vital for enhancing model performance and generalization capabilities [35]. Commonsense Knowledge and Cultural Differences: The ATOMIC method underscores the significance of gathering and analyzing commonsense knowledge while considering cultural differences across national groups, highlighting the need for diverse and inclusive data representations in information retrieval [38]. These foundational terms and concepts provide a framework for investigating innovative methodologies and integration strategies enhancing graph retrieval-augmented generation systems' effectiveness and reliability. By leveraging advancements like graph-based retrievers to address biomedical research information overload, RAG techniques to improve AI-generated content, and graph representation learning to enrich contextual understanding, the survey explores how these systems capture long-tail knowledge, ensure accuracy, and facilitate query-focused summarization. It highlights knowledge graph integration to refine retrieval processes and suggests future research directions to optimize interaction between large language models and external knowledge sources, advancing retrieval-augmented generation systems' capabilities across domains [28,39,40,13,41]. In recent years, the intersection of Graph Neural Networks (GNNs) and Information Retrieval has garnered significant attention within the academic community. This integration is not only pivotal for advancing retrieval techniques but also for enhancing the capabilities of Large Language Models (LLMs). As illustrated in , the hierarchical structure of GNNs is depicted, showcasing various frameworks and applications. The figure further delineates the diverse methods and techniques employed in this domain, while also addressing the challenges and limitations faced by researchers. Such a comprehensive overview aids in understanding the complex interplay between these technologies and sets the stage for future exploration in the field. Graph Neural Networks in Information Retrieval Introduction to Graph Neural Networks in Information Retrieval Graph Neural Networks (GNNs) are pivotal in transforming information retrieval by offering sophisticated mechanisms for processing graph-structured data, which traditional methods often fail to address effectively. By integrating large language models (LLMs) with external knowledge sources like knowledge bases and graphs, GNNs enhance the reasoning and accuracy of LLM-generated responses, tackling issues of completeness, timeliness, and adaptability. Retrieval-augmented generation (RAG) techniques further enable these models to access reliable and current information, reducing risks associated with hallucinations and outdated knowledge, thereby improving performance in tasks requiring extensive world knowledge and long-tail information [42,14,43,32,13]. GNNs contribute to a more structured semantic understanding and contextual relevance in information retrieval systems. Applications such as the GRAG framework demonstrate how GNNs retrieve optimal subgraph structures for integration into LLMs, enhancing tasks that involve complex relationships [4]. The QA-GNN framework leverages language models' strengths in understanding alongside structured knowledge from graphs, optimizing retrieval and reasoning capabilities [15]. The RAG4DyG framework showcases GNNs' adaptability in dynamic graph modeling, using broader contextual information to improve predictions across various applications [3]. Additionally, the Keqing framework aids LLMs in retrieving structured knowledge from graphs for logical reasoning in complex queries [1]. The BEQUE framework illustrates GNNs' role in optimizing long-tail query rewriting by bridging semantic gaps through structured approaches involving fine-tuning, feedback, and alignment, enhancing retrieval processes [5]. Integrating GNNs with LLM-based frameworks, such as KG-Agent, further augments LLMs' reasoning capabilities over knowledge graphs, highlighting GNNs' potential to enhance language models [12]. Methods and Techniques GNNs employ diverse methods to enhance information retrieval, leveraging graph data's structured nature to improve reasoning and prediction capabilities. The Graph-augmented Learning to Rank (GALR) method partitions retrieved knowledge subgraphs and applies a learning-to-rank strategy to optimize answer selection from large-scale graphs, emphasizing efficient graph data organization [44]. Graph Attention Networks (GATs) refine node representations using masked self-attention layers, allowing nodes to assign attention weights to neighboring features, addressing limitations of traditional graph convolutions. GATs compute attention scores to aggregate features from neighbors without costly matrix operations, demonstrating state-of-the-art performance [45,46,47,48]. Layer stacking enhances deeper representation learning, improving interpretability and effectiveness in retrieval tasks. The GraphBridge method synthesizes diverse data sources to enhance retrieval outcomes through a multi-granularity approach in text-attributed graphs [49]. Graph Convolutional Networks (GCNs) use localized first-order approximations of spectral graph convolutions to learn node representations, enhancing computational efficiency and expressive power in large-scale applications [45,30,40,49]. Inductive representation techniques, such as GraphSAGE, involve sampling and aggregating neighboring node features to generate embeddings, significantly enhancing scalability and adaptability in dynamic data environments [45,3]. Methods like prefix-tuning and soft prompt learning enable efficient adaptation of language models to specific tasks, optimizing continuous vectors or learning soft prompts to guide model responses, enhancing GNN integration with language models [5]. Convolutional operations on entity and relation embeddings predict missing links within graph data, advancing GNN capabilities in retrieval [25]. The DARA method combines high-level iterative task decomposition with low-level task grounding to enhance question parsing into formal queries, significantly improving retrieval processes by ensuring precise interpretation and reasoning [23,22,34,50,51]. These methods illustrate diverse strategies employed by GNNs to optimize information retrieval, integrating structured graph data with advanced language models to address challenges such as information overload and long-tail knowledge capture, particularly in biomedical research. This integration enhances retrieval accuracy and efficiency by leveraging dense, structured representations of knowledge graphs, improving precision and recall, and enabling effective question-answering and link prediction capabilities [30,45,52,13,53]. Challenges and Limitations Despite GNNs' advancements in information retrieval, several challenges and limitations affect their performance and scalability. A primary challenge is the reliance on high-quality graph structures and local features, which can hinder performance if these elements are insufficiently informative or if graph representations are suboptimal [3]. Constructing effective graph vocabularies that capture necessary invariances is another challenge, impacting GNNs' ability to represent and process diverse graph structures accurately, affecting scalability across domains. The extraction of relevant subgraphs is crucial yet challenging, directly impacting reasoning processes and retrieval effectiveness [4]. Existing methods often struggle to adapt to new patterns in dynamic graphs, focusing narrowly on historical contexts. This limitation restricts GNNs' adaptability to evolving data environments, necessitating innovative approaches to accommodate dynamic data [3]. Moreover, integrating large language models (LLMs) with GNNs is often hampered by their inability to autonomously manage reasoning processes, limiting effectiveness in utilizing knowledge graphs [12]. The reliance on structured data and external interfaces for reasoning can restrict the flexibility and effectiveness of methods like Keqing, which depend heavily on the quality and completeness of the used knowledge graph, affecting the accuracy of generated answers [1]. Additionally, the quality of sentence embeddings in methods like SBERT may involve trade-offs, particularly for nuanced or complex sentence pairs [25]. Substantial computational resources required during the pre-training phase of models like BERT present another challenge, impacting GNNs' practical applications in retrieval. This is particularly evident in large-scale knowledge graphs, where conventional GNNs often suffer from excessive computation and over-smoothing, limiting their expressive power. Novel frameworks such as the retrieve-and-read approach and hybrid models that combine embedding similarity with knowledge graph retrieval aim to optimize computational efficiency and improve retrieval, enhancing GNNs' potential in biomedical research and link prediction [45,42,13]. Efficient computational strategies are crucial for managing resource-intensive processes, ensuring GNNs operate effectively in real-world scenarios. Knowledge Graphs and Their Integration Structure and Function of Knowledge Graphs Knowledge graphs (KGs) are pivotal for organizing relational data, significantly enhancing information retrieval across diverse domains. Their structure, comprising nodes representing entities and edges denoting relationships, facilitates the synthesis and inference of complex knowledge [18]. This interconnected framework is crucial for enabling accurate multi-hop reasoning in large language models (LLMs), as demonstrated by improvements in performance with KnowledgeNavigator [54]. KGs adeptly represent temporal data, addressing queries involving temporal sequences and changes [55]. This feature is particularly beneficial in finance, where LLM solutions leverage structured knowledge representation [56]. Integration of KGs with language models involves aligning textual data with KG structures, emphasizing components in pipeline models [30]. Innovative subgraph retrieval methods, such as chain of thought (CoT) and page rank, enhance integration by efficiently identifying promising reasoning paths [57]. Techniques like ConvE exemplify parameter efficiency, achieving competitive performance with fewer parameters than traditional methods [58]. A novel taxonomy categorizes models into primary components, including knowledge extractors and organizers, and operational techniques such as integration and training strategies, providing a structured framework for current research [40]. This taxonomy is complemented by frameworks categorizing medical LLM research based on training methodologies and application contexts, showcasing KGs' versatility across various fields [59]. KGs enhance information retrieval by offering a sophisticated framework for organizing relational data, significantly boosting reasoning capabilities in complex retrieval tasks. Recent advancements, including retrieve-and-read frameworks and graph reasoning methods, demonstrate how targeted retrieval of relevant subgraph contexts and triplet reranking optimize inference and question answering. These methods leverage graph neural networks and Transformer-based models to focus on salient information, addressing computational expenses and knowledge constraints. Empirical results across datasets highlight the competitive advantage of these approaches in improving retrieval accuracy and reasoning depth [45,54,51]. Integration with Large Language Models Integrating knowledge graphs (KGs) with large language models (LLMs) significantly advances retrieval capabilities, enhancing reasoning and information extraction processes. This integration leverages the structured nature of KGs to augment LLMs' contextual understanding and reasoning abilities, improving performance on complex retrieval tasks. The CRAG dataset exemplifies this integration by simulating web and KG searches, providing diverse question-answer pairs that capture entity popularity and temporal dynamics [60]. GreaseLM showcases improved performance on reasoning tasks by incorporating structured knowledge from KGs, highlighting the potential of merging explicit and implicit knowledge [61]. This alignment allows LLMs to utilize relational information within KGs, facilitating accurate and contextually relevant information retrieval. The integration process involves aligning textual data with KG structures, enabling LLMs to leverage relational information for enhanced reasoning capabilities. Techniques such as subgraph retrieval and reasoning path identification enhance integration, allowing LLMs to navigate and reason within complex knowledge structures effectively. Methods like CoT and page rank optimize reasoning paths, mitigating challenges like hallucinations and information overload, thereby improving the reliability of knowledge-based reasoning and enhancing precision and recall in domain-specific applications, evidenced by improvements in datasets like QALD10 and GenMedGPT-5k [57,40,62,13]. Integrating KGs with LLMs represents a transformative approach in advancing retrieval processes by combining explicit and parametric knowledge, enhancing reasoning and contextual understanding. This hybrid approach effectively addresses information overload and neglect of rare but important data, particularly in biomedical research, utilizing Retrieval Augmented Generation (RAG) and innovative graph-based methods to capture long-tail knowledge, improving precision and recall in information retrieval [13,14]. Challenges in Knowledge Graph Integration Integrating knowledge graphs (KGs) with technologies like large language models (LLMs) and graph neural networks (GNNs) presents challenges that must be addressed to optimize retrieval processes and enhance reasoning capabilities. A primary challenge is aligning diverse vocabularies and representations within KGs, which often hampers seamless integration with LLMs [12]. The heterogeneity of KGs, where entities and relations vary across domains, impacts inference and reasoning capabilities of integrated systems. Scalability is another significant challenge, as KGs can be vast and complex, requiring efficient methodologies for managing and processing large-scale data [3]. The computational demands of integrating KGs with advanced models like LLMs and GNNs are substantial, necessitating innovative approaches to optimize resource usage and improve efficiency. Extracting relevant subgraphs for reasoning tasks further complicates this challenge, demanding sophisticated techniques to identify and utilize pertinent information from KGs [4]. The dynamic nature of KGs, continuously evolving with new information, poses challenges in maintaining up-to-date and accurate representations within integrated systems [2]. This requires ongoing adaptation and updating of KG structures to ensure reliability and relevance of retrieved information. The challenge of integrating KGs with LLMs is underscored by the need for models to autonomously manage reasoning processes, often limited by static methodologies [12]. Additionally, the quality and completeness of KGs significantly influence integration effectiveness. Incomplete or inaccurate KGs can result in erroneous reasoning and retrieval outcomes, highlighting the necessity for robust and comprehensive knowledge bases [1]. Reliance on structured data and external interfaces for reasoning may restrict flexibility and effectiveness of integrated systems, necessitating innovative strategies to enhance adaptability and performance. Addressing these challenges is crucial for advancing retrieval processes and enhancing reasoning capabilities of LLMs and GNNs. Integration enables hybrid representation of explicit and parametric knowledge, facilitating accurate and interpretable multi-hop reasoning. By optimizing retrieval of relevant triplets and leveraging frameworks like KnowledgeNavigator, we can enhance question answering performance, reduce inaccuracies and hallucinations, and achieve superior results compared to traditional methods [54,51,14]. Developing scalable architectures, improving data quality, and enhancing evaluation frameworks can significantly optimize integration of KGs with other technologies, leading to more accurate and efficient information retrieval systems across diverse domains. Retrieval-Augmented Generation Techniques Foundational Components of RAG Retrieval-Augmented Generation (RAG) systems integrate retrieval processes with generative mechanisms to enhance reasoning and information synthesis. Central to RAG systems is the retrieval component, which extracts data from structured and unstructured sources. The GRAG framework employs a divide-and-conquer strategy, retrieving optimal subgraph structures and integrating them into large language models (LLMs) through text and graph views, thereby improving contextual information generation [4]. The KG-Agent framework enhances reasoning over knowledge graphs by integrating a multifunctional toolbox, a KG-based executor, and knowledge memory, highlighting the importance of structured integration in RAG systems [12]. The Keqing framework emphasizes decomposing complex questions, retrieving candidate entities from knowledge graphs, and generating responses incorporating reasoning paths, which is vital for ensuring output reliability [1]. Strategies for addressing complex Knowledge Base Question Answering (KBQA) challenges focus on optimizing retrieval processes and enhancing the integration of language models with knowledge graphs to improve reasoning accuracy [9]. These components establish a framework for advancing information retrieval, enabling sophisticated reasoning and synthesis across diverse applications. By integrating advanced retrieval, generation, and augmentation techniques, RAG systems enhance accuracy, efficiency, and reliability. They address challenges like outdated knowledge and data leakage through external databases and dynamic knowledge sources, improving robustness and credibility. Particularly effective in knowledge-intensive tasks, RAG systems facilitate continuous knowledge updates and domain-specific information integration. Despite complexities in evaluating RAG systems due to their hybrid structure, ongoing research offers benchmarks and evaluation metrics that highlight advancements and future directions [28,29,63]. Knowledge Graph Augmentation Techniques Knowledge graph augmentation techniques enhance retrieval-augmented generation by integrating structured knowledge with natural language processing tasks. The KG-Rank method leverages a medical knowledge graph and advanced ranking techniques to improve answer accuracy in medical question-answering systems [64], underscoring the role of domain-specific knowledge graphs in augmenting retrieval processes. The Graph-Based Retriever enhances performance by downsampling clusters of over-represented concepts within knowledge graphs, emphasizing balanced concept representation [13]. TIARA refines augmentation by improving question answering accuracy over large knowledge bases, enhancing retrieval processes through better integration of structured data with language models [50]. The multilingual QALD-9-plus dataset, offering translations of questions into eight languages, enhances applicability in diverse linguistic contexts. This dataset extends the QALD-9 benchmark by incorporating languages considered endangered by UNESCO and improves usability by transferring SPARQL queries from DBpedia to Wikidata, addressing multilingual accessibility challenges in Knowledge Graph Question Answering (KGQA) systems [32,65]. Knowledge graph augmentation techniques advance retrieval-augmented generation by providing structured frameworks that enhance reasoning and synthesis capabilities. They address limitations in existing methods, such as insufficient knowledge retrieval and computational inefficiencies, by leveraging graph neural networks and frameworks like the Hypothesis Knowledge Graph Enhanced (HyKGE) system. Empirical results demonstrate significant performance improvements across applications including link prediction, question answering, and customer service, underscoring their effectiveness in enhancing retrieval accuracy [66,45,67,51,41]. State-of-the-Art Applications State-of-the-art applications in retrieval-augmented generation (RAG) demonstrate the transformative potential of integrating advanced retrieval mechanisms with generative models to enhance reasoning and synthesis across domains. The Mintaka benchmark exemplifies this integration, achieving notable performance metrics such as 38\\ Enhancing Retrieval-Augmented Generation Techniques Enhancing retrieval-augmented generation (RAG) techniques involves developing methodologies that leverage the strengths of both large language models (LLMs) and graph-based frameworks to improve accuracy, efficiency, and reliability of information retrieval systems. The Prefix-Tuning method optimizes LLMs for low-data scenarios, improving adaptability and efficiency in retrieval processes [68]. This highlights the significance of fine-tuning strategies that enhance contextual information integration, particularly in data-limited contexts. The Key-Value Memory Networks method improves document reading and question answering directly, addressing limitations of traditional knowledge base (KB)-based methods [69]. This underscores the importance of efficient document processing and retrieval strategies in optimizing synthesis and reasoning capabilities. The Knowledge Graph Passage (KGP) method constructs a graph representing document passages and their relationships, enhancing context quality for accurate question answering [70]. This technique emphasizes the role of structured data in augmenting LLM retrieval capabilities, facilitating precise and relevant information generation. Future research should focus on enhancing method adaptability to complex question types, exploring emerging trends like pre-trained language models, and addressing gaps in methodologies [71]. The integration of reflection-based question augmentation steps, as proposed in the Golden-Retriever method, improves query clarity and context, optimizing retrieval [72]. The Knowledge-Driven Chain-of-Thought (KD-CoT) framework aims to enhance LLM reasoning by integrating external knowledge through a structured multi-round QA format [73]. This underscores the importance of dynamic reasoning strategies that enhance adaptability and performance of RAG systems. Moreover, future research should enhance evaluation frameworks, explore new retrieval strategies, and investigate RAG adaptability in non-text domains [34]. Exploring emerging trends suggests a focus on developing sophisticated models that leverage the strengths of both LLMs and graphs [10]. Further optimizations of architectures like SBERT and their applicability to other natural language processing tasks could also be pursued [25]. Enhancing RAG techniques addresses challenges such as knowledge updating, long-tail data handling, and data leakage mitigation, while optimizing integration strategies to merge retrieval methods with LLMs. This approach advances information retrieval by improving accuracy, robustness, and credibility of AI-generated content, allowing for continuous updates and dynamic domain-specific integration. By categorizing RAG paradigms and evaluating components, researchers can better understand limitations and potential future research directions, facilitating effective engineering and implementation across various modalities and tasks [28,34,29,63]. Leveraging strengths of graph-based frameworks and LLMs enables RAG systems to enhance accuracy, efficiency, and reliability across diverse applications. Evaluation and Benchmarking Evaluating retrieval-augmented generation (RAG) systems necessitates a robust framework to assess performance against established benchmarks. This section explores the evaluation frameworks and benchmarks that enable systematic analysis of RAG capabilities, ensuring comprehensive insights into their effectiveness and efficiency. The following subsection delves into key evaluation frameworks and benchmarks, emphasizing their role in facilitating meaningful comparisons and advancements in retrieval methodologies. Evaluation Frameworks and Benchmarks Evaluation frameworks and benchmarks are critical for assessing the performance of retrieval-augmented generation (RAG) systems, providing structured methodologies to evaluate capabilities across diverse applications. These frameworks address RAG's hybrid architecture and reliance on dynamic knowledge sources by analyzing metrics such as relevance, accuracy, and faithfulness. RAG systems enhance large language models' accuracy, especially in knowledge-intensive tasks, by leveraging external information retrieval. The evaluation process encompasses various datasets and metrics, addressing current benchmark limitations and suggesting potential advancements. Frameworks categorize RAG paradigms into components—pre-retrieval, retrieval, post-retrieval, and generation—offering insights into their evolution and technological foundations, thereby broadening large language models' adaptability [28,34,29,63]. Empirical assessments typically utilize benchmark datasets, focusing on retrieval metrics like Mean Reciprocal Rank (MRR), Recall@K, and Normalized Discounted Cumulative Gain (NDCG@K), alongside text generation metrics such as BLEU, ROUGE, and METEOR, essential for evaluating RAG systems' contextual response accuracy. Table provides a detailed summary of benchmark datasets employed in the evaluation of retrieval-augmented generation systems, illustrating their significance in measuring system performance across diverse domains and task formats. Experiments on Knowledge Base Question Answering (KBQA) datasets assess methods like Subgraph Retrieval (SR) against baseline approaches, emphasizing retrieval accuracy and question answering performance. The Subgraph Retrieval Enhanced Model, by decoupling retrieval from reasoning, shows significant improvements by reducing reasoning bias and enhancing precision. Additionally, methods like graph reasoning and graph-augmented learning to rank advance KBQA by effectively managing subgraph sizes and integrating relevant knowledge from large-scale knowledge graphs [27,30,74,67,51]. Evaluations using the WebQSP dataset measure Semantic Knowledge Propagation (SKP) performance against baseline methods, underscoring the importance of dataset-specific metrics for assessing advanced retrieval capabilities. Extensive experiments on benchmark datasets validate methods like DropEdge, comparing them against various baselines, highlighting comprehensive benchmarking's significance for understanding RAG systems' scalability and adaptability. The experimental setup for GraphRAG involves datasets in the million-token range, emphasizing generated answers' diversity. This setup underscores scalability's critical role in assessing RAG systems, which must seamlessly integrate dynamic information retrieval with generative models to enhance accuracy and domain-specific knowledge application while managing challenges such as knowledge updates and cost-effective operations [28,29,63]. The Graph-Based Retriever's performance is evaluated against traditional embedding similarity methods using precision and recall metrics, highlighting their importance in understanding graph-based retrieval capabilities. Evaluations of Golden-Retriever, employing three open-source large language models on domain-specific question-answer datasets, demonstrate superior performance in generating accurate responses through a reflection-based question augmentation process that clarifies domain-specific jargon and context [59,72]. Metrics such as accuracy and F1-score evaluate model performance, showcasing graph-augmented reasoning's effectiveness in answering knowledge-intensive questions by optimizing subgraph retrieval and enhancing fact verification processes. These approaches achieve up to 4.6 Keqing's performance was assessed through its accuracy in responding to questions and analyzing logical reasoning paths using KBQA datasets [1], highlighting logical reasoning's role in enhancing generated outputs' reliability. These evaluation frameworks and benchmarks are vital for optimizing retrieval-augmented generation systems, ensuring accuracy, efficiency, and reliability across diverse applications. Comprehensive methodologies address the unique challenges associated with RAG's hybrid structure and dynamic knowledge sources, enabling continuous improvement to meet evolving information retrieval task demands. This includes examining and comparing metrics such as relevance, accuracy, and faithfulness while leveraging state-of-the-art technologies in retrieval, generation, and augmentation. Furthermore, integrating up-to-date external information enhances RAG systems' accuracy and reliability, especially in knowledge-intensive tasks, facilitating continuous updates and domain-specific information integration. This approach addresses limitations like hallucination and outdated knowledge in large language models, broadening adaptability and applications [34,29,63]. Comparison with Baseline Methods Comparing graph retrieval-augmented generation systems with baseline methods is essential for understanding their performance across various information retrieval tasks. The QA-RAG framework demonstrated its superiority over conventional methods, evidenced by improved precision, recall, and F1-score metrics, highlighting its effectiveness in optimizing retrieval processes [75]. Similarly, the TEMPLE-MQA model's performance against baseline models revealed significant improvements in accuracy and contextual understanding, showcasing its ability to handle complex multi-hop queries effectively [76]. The KG-Agent framework was evaluated against state-of-the-art methods utilizing larger language models or extensive datasets, both in-domain and out-domain, underscoring its robustness and adaptability in various retrieval scenarios [12]. Additionally, the FABULA framework was assessed for relevance and coherence in generated reports, demonstrating its superiority over traditional report generation methods in content quality [77]. The feedback-augmented retriever within the Knowledge-Driven Chain-of-Thought (KD-CoT) framework was evaluated based on task-solving reasoning generation and retrieval performance, highlighting feedback mechanisms' importance in enhancing retrieval accuracy [73]. Performance was also measured through validation results based on MSE loss and Pearson correlation coefficients, providing insights into the models' ability to capture similarity effectively [78]. These comparisons with baseline methods are crucial for advancing the development and optimization of graph retrieval-augmented generation systems, ensuring accuracy, efficiency, and reliability across diverse applications. Integrating comprehensive evaluation methodologies, such as those employed in Retrieval-Augmented Generation (RAG), allows these systems to continuously refine and address unique challenges posed by their hybrid structure and dynamic knowledge sources, better meeting evolving information retrieval task demands, including accurate long-tail knowledge capture and improving output relevance, accuracy, and faithfulness in fields like open-domain question answering and biomedical research [63,8,13]. Challenges and Future Directions Integration and Scalability Challenges Graph retrieval-augmented generation systems face integration and scalability challenges that impact their efficacy across diverse applications. The quality of retrieved examples, as seen in GRAG, is crucial, necessitating advanced retrieval mechanisms to synthesize graph data effectively and address complexities in long-tail biomedical knowledge and knowledge graph link prediction. Techniques like Retrieval Augmented Generation (RAG) and graph-based attention structures can mitigate information overload while enhancing precision and recall by incorporating diverse contextual information [45,13,51]. Disentangling knowledge from language models remains a challenge, complicating scalability and adaptability [2]. Efficient integration of graph data with language models is essential to maintain performance. Scalability is further constrained by existing methods' limitations in modeling multi-hop relations and managing computational costs associated with integrating external knowledge [50]. Optimizing computational resources is vital for preserving complex reasoning processes while ensuring scalability. The quality of knowledge graphs impacts systems like TIARA, which may struggle with adaptability if the knowledge base lacks comprehensiveness [50]. Diverse knowledge bases are needed to enhance the robustness and adaptability of retrieval-augmented generation systems. Future research should prioritize hybrid approaches merging semantic parsing and information retrieval, leveraging emerging trends in natural language processing to improve integration and scalability [9]. Innovative integration strategies and optimized computational efficiency can enhance adaptability and reliability, facilitating broader applications. Quality and Completeness of Knowledge Graphs Retrieval-augmented generation systems' performance is heavily influenced by the quality and completeness of knowledge graphs (KGs), directly impacting retrieval accuracy. The KG-Agent method relies on comprehensive and precise knowledge graphs for accurate answers in complex scenarios [12]. Similarly, the Keqing framework's success depends on high-quality facts retrieved from KGs, underscoring the importance of robust knowledge bases [1]. Incomplete or inaccurate KGs can lead to suboptimal performance, as seen in methods dependent on both knowledge graph and instruction dataset quality [12]. These challenges highlight the necessity for comprehensive, high-quality knowledge bases to enhance system robustness. Constructing and maintaining KGs for effective question answering involves challenges related to quality and completeness, such as reliance on historical data and potential test set leakage, necessitating rigorous data management practices [1]. Ensuring KG quality and completeness is vital for advancing integration with language models and graph neural networks. Addressing challenges like knowledge updating, managing long-tail data, and handling high training and inference costs can significantly enhance retrieval-augmented generation systems' accuracy, efficiency, and robustness across domains. This enables generative models to aggregate evidence effectively from multiple sources, improving performance on benchmarks like Natural Questions and TriviaQA, paving the way for advancements in AI-generated content [28,8]. Addressing Hallucinations and Reasoning Limitations Enhancing retrieval-augmented generation systems' reliability and accuracy requires addressing hallucinations and reasoning limitations. Hallucinations, characterized by generating incorrect or misleading information, pose significant challenges, especially in complex multi-hop reasoning scenarios [79]. The Think-on-Graph (ToG) framework identifies hallucination as a critical issue and proposes methods to enhance reasoning capabilities through structured graph data integration. The Knowledge-Driven Chain-of-Thought (KD-CoT) framework improves reasoning traces and incorporates external knowledge to mitigate hallucinations [73]. Robust techniques integrating external knowledge sources are essential for enhancing output reliability. Future research should focus on improving KG quality and developing sophisticated relevance scoring techniques to boost model performance, as suggested by the QA-GNN framework [15]. Enhancing cognitive alignment with human knowledge and refining integration processes are crucial, particularly in large knowledge integration contexts [2]. The Keqing framework could benefit from exploring additional reasoning strategies to improve performance in addressing hallucinations and reasoning limitations [1]. InstructGPT findings highlight the necessity for continuous refinement to enhance model outputs, emphasizing ongoing improvements in tackling these challenges [11]. Addressing hallucinations and reasoning limitations involves a multifaceted approach combining technical optimizations with innovative integration strategies, ensuring robust and reliable systems capable of handling complex information retrieval tasks. Future research could refine model architectures and explore novel approaches to improve graph comprehension, leveraging passage retrieval with generative models to efficiently aggregate evidence from multiple sources, as demonstrated by state-of-the-art results in open-domain question answering. Graph-based retrieval methods capturing long-tail biomedical knowledge could mitigate information overload, while a retrieve-and-read framework using high-capacity readers may optimize knowledge graph link prediction. Developing structure-aware retrieval-augmented language models could further enhance coherence and contextual relevance across scientific disciplines. Advancements in retrieval-augmented generation techniques could address challenges like knowledge updating and managing long-tail data, offering insights for enhancing AI-generated content systems [33,28,8,45,13]. Interdisciplinary Research and Standards Development Advancing graph retrieval-augmented generation (RAG) systems requires interdisciplinary research and standards development, particularly for integrating large language models (LLMs) with knowledge graphs. Future initiatives could focus on expanding datasets with diverse entity descriptions, assessing benchmark applicability across domains, and identifying interdisciplinary research opportunities [80]. Such expansions will enable the development of more robust and adaptable RAG systems capable of functioning across various modalities and applications [28]. The synergy between LLMs and knowledge graphs necessitates establishing standards for hybrid knowledge representation, driving sophisticated retrieval techniques that enhance adaptability in retrieval-augmented large language models (RA-LLMs) [81]. This synergy is crucial for addressing scalability challenges in knowledge integration and optimizing retrieval methods' integration with language models [8]. Future research should refine integration techniques and explore new operational strategies to enhance LLM efficacy in graph representation learning (GRL) [72]. This includes investigating novel retrieval techniques and applications across diverse regulatory domains, suggesting further interdisciplinary research avenues [75]. Improving knowledge update protocols and expanding benchmarks to include diverse domains are critical for future research initiatives. These efforts should aim to enhance retrieval quality and optimize computational efficiency, essential for effective integration of retrieval methods with language models [12]. Interdisciplinary research combining these advancements with transfer learning and other approaches will be instrumental in driving innovations in this rapidly evolving field. Collaboration among educators, researchers, and policymakers is vital to leverage LLM benefits and develop robust information retrieval systems capable of sophisticated reasoning and accurate data synthesis [81]. Conclusion Integrating graph neural networks and knowledge graphs into information retrieval systems represents a pivotal advancement in enhancing reasoning accuracy and inference capabilities. This survey highlights the transformative impact of such integrations, demonstrated by frameworks like MedGraphRAG, which consistently outperform existing models by ensuring generated responses are backed by credible sources and definitions. Innovations in dynamic graph modeling, as seen in the RAG4DyG model, underscore the ongoing need for advancement in retrieval-augmented generation techniques. The KagNet model's success in CommonsenseQA tasks showcases its effectiveness in addressing challenges like large language model hallucinations, while DARA's improvements in language agents for Knowledge Graph Question Answering facilitate more practical real-world applications. Incorporating cultural knowledge, exemplified by the ATOMIC framework, significantly enhances AI performance in commonsense reasoning, suggesting a shift towards more human-like understanding in natural language processing. This trend resonates with the positive reception of generative AI in educational contexts, indicating its potential to revolutionize teaching practices. The survey's findings emphasize the importance of new benchmarks in developing more effective question answering systems, crucial for scaling to complex reasoning tasks. Additionally, recognizing the transformative potential of Med-LLMs in healthcare, alongside ethical considerations, underscores the need for ongoing evaluation and development to ensure these technologies remain safe and reliable.",
  "reference": {
    "1": "2401.00426v1",
    "2": "2312.02706v2",
    "3": "2408.14523v2",
    "4": "2405.16506v3",
    "5": "2311.03758v3",
    "6": "1809.00782v1",
    "7": "2306.06872v1",
    "8": "2007.01282v2",
    "9": "2105.11644v1",
    "10": "2404.14928v2",
    "11": "2203.02155v1",
    "12": "2402.11163v1",
    "13": "2402.12352v1",
    "14": "2308.06374v1",
    "15": "2104.06378v5",
    "16": "1907.10903v4",
    "17": "1706.03762v7",
    "18": "2404.07103v3",
    "19": "2009.02252v4",
    "20": "2406.03712v2",
    "21": "2005.00646v2",
    "22": "2406.07080v1",
    "23": "2305.12416v1",
    "24": "2310.12836v1",
    "25": "1908.10084v1",
    "26": "2101.00376v2",
    "27": "2007.13069v1",
    "28": "2402.19473v6",
    "29": "2312.10997v5",
    "30": "2306.02871v1",
    "31": "2212.00959v2",
    "32": "2309.11206v2",
    "33": "2311.12289v1",
    "34": "2404.10981v2",
    "35": "1907.11692v1",
    "36": "2011.07743v6",
    "37": "2403.15586v1",
    "38": "1811.00146v3",
    "39": "2404.16130v2",
    "40": "2402.05952v1",
    "41": "2312.15883v2",
    "42": "2308.11761v1",
    "43": "2405.06211v3",
    "44": "2310.04562v2",
    "45": "2212.09724v3",
    "46": "1710.10903v3",
    "47": "1609.02907v4",
    "48": "2406.12608v2",
    "49": "2401.15569v2",
    "50": "2210.12925v1",
    "51": "2305.18742v1",
    "52": "2312.02783v4",
    "53": "2311.12399v4",
    "54": "2312.15880v2",
    "55": "2402.16568v2",
    "56": "2311.10723v2",
    "57": "2404.10384v1",
    "58": "1707.01476v6",
    "59": "2406.10303v2",
    "60": "2406.04744v2",
    "61": "2201.08860v1",
    "62": "2402.04978v2",
    "63": "2405.07437v2",
    "64": "2403.05881v3",
    "65": "2202.00120v2",
    "66": "2404.17723v2",
    "67": "2111.10541v4",
    "68": "2210.01613v1",
    "69": "2307.07697v6",
    "70": "2101.00190v1",
    "71": "1606.03126v2",
    "72": "2308.11730v3",
    "73": "2108.06688v5",
    "74": "2408.00798v1",
    "75": "2308.13259v2",
    "76": "2202.13296v2",
    "77": "2305.06590v2",
    "78": "2402.01717v1",
    "79": "2404.00492v1",
    "80": "2310.13848v2",
    "81": "2403.16265v1",
    "82": "1906.07348v1",
    "83": "2403.18105v2"
  },
  "chooseref": {
    "1": "2205.01841v1",
    "2": "2303.10395v1",
    "3": "2212.09724v3",
    "4": "2404.00579v2",
    "5": "2311.12399v4",
    "6": "2406.11903v1",
    "7": "2105.11644v1",
    "8": "2007.13069v1",
    "9": "2311.05232v2",
    "10": "2406.10303v2",
    "11": "2406.03712v2",
    "12": "2405.06211v3",
    "13": "2404.10981v2",
    "14": "2311.12289v1",
    "15": "1811.00146v3",
    "16": "2402.05952v1",
    "17": "2402.04978v2",
    "18": "2204.08109v3",
    "19": "2010.05953v2",
    "20": "1706.03762v7",
    "21": "1810.04805v2",
    "22": "2406.12608v2",
    "23": "2308.14436v1",
    "24": "2406.04744v2",
    "25": "2109.01653v1",
    "26": "2305.10037v3",
    "27": "1809.02789v1",
    "28": "2310.08975v3",
    "29": "1811.00937v2",
    "30": "2108.06688v5",
    "31": "2305.01157v3",
    "32": "2403.16265v1",
    "33": "1707.01476v6",
    "34": "2405.04819v4",
    "35": "2406.07080v1",
    "36": "2210.00063v2",
    "37": "2004.04906v3",
    "38": "2305.12416v1",
    "39": "1907.10903v4",
    "40": "2401.15569v2",
    "41": "2405.07437v2",
    "42": "1910.10683v4",
    "43": "2310.13848v2",
    "44": "2305.06590v2",
    "45": "2308.10173v1",
    "46": "2404.16130v2",
    "47": "2402.01717v1",
    "48": "2402.07630v3",
    "49": "2405.20139v1",
    "50": "2305.15066v2",
    "51": "2405.16506v3",
    "52": "2407.13193v3",
    "53": "2403.15586v1",
    "54": "1711.05851v2",
    "55": "2408.00798v1",
    "56": "2303.12320v2",
    "57": "1710.10903v3",
    "58": "2404.07103v3",
    "59": "2404.14928v2",
    "60": "2305.18742v1",
    "61": "2407.09777v2",
    "62": "2402.12352v1",
    "63": "2111.10541v4",
    "64": "2310.01089v1",
    "65": "2402.07197v4",
    "66": "2201.08860v1",
    "67": "2405.14831v3",
    "68": "2306.06872v1",
    "69": "1809.09600v1",
    "70": "2312.15883v2",
    "71": "2408.04948v1",
    "72": "2101.03737v2",
    "73": "1706.02216v4",
    "74": "2402.11163v1",
    "75": "2110.04330v2",
    "76": "2310.11220v1",
    "77": "2403.05881v3",
    "78": "2009.02252v4",
    "79": "1909.02151v1",
    "80": "1606.03126v2",
    "81": "2312.06185v5",
    "82": "2308.11761v1",
    "83": "2308.11730v3",
    "84": "2406.13862v1",
    "85": "2309.03118v1",
    "86": "2306.04136v1",
    "87": "2310.12836v1",
    "88": "2308.13259v2",
    "89": "2312.15880v2",
    "90": "2402.08170v3",
    "91": "2308.07134v5",
    "92": "2005.14165v4",
    "93": "2312.02706v2",
    "94": "2311.03758v3",
    "95": "2308.06374v1",
    "96": "2403.18105v2",
    "97": "2405.13055v1",
    "98": "2311.10723v2",
    "99": "2312.02783v4",
    "100": "1506.02075v1",
    "101": "2007.01282v2",
    "102": "2307.09288v2",
    "103": "2307.03172v3",
    "104": "2408.04187v2",
    "105": "2308.09729v5",
    "106": "2210.01613v1",
    "107": "2211.10991v1",
    "108": "2404.19234v1",
    "109": "2404.00492v1",
    "110": "2404.07677v2",
    "111": "1809.00782v1",
    "112": "1911.11641v1",
    "113": "2402.02216v3",
    "114": "2101.00190v1",
    "115": "1904.09537v1",
    "116": "2104.06378v5",
    "117": "2202.00120v2",
    "118": "2404.19543v2",
    "119": "2202.06129v1",
    "120": "2405.14431v1",
    "121": "2210.13650v1",
    "122": "2404.10384v1",
    "123": "2310.01061v2",
    "124": "2408.14523v2",
    "125": "2402.19473v6",
    "126": "2312.10997v5",
    "127": "2404.17723v2",
    "128": "2309.11206v2",
    "129": "2101.00376v2",
    "130": "2109.08678v2",
    "131": "1907.11692v1",
    "132": "2404.13207v3",
    "133": "2005.00646v2",
    "134": "1609.02907v4",
    "135": "1908.10084v1",
    "136": "2305.09645v2",
    "137": "2202.13296v2",
    "138": "2210.12925v1",
    "139": "2310.04560v1",
    "140": "2306.02871v1",
    "141": "2104.08691v2",
    "142": "1803.06643v1",
    "143": "2307.07697v6",
    "144": "2011.07743v6",
    "145": "2310.04562v2",
    "146": "2203.02155v1",
    "147": "1705.03551v2",
    "148": "2402.16568v2",
    "149": "2212.00959v2",
    "150": "2406.02110v1",
    "151": "2306.08302v3",
    "152": "1709.04071v5",
    "153": "2009.13081v1",
    "154": "1906.07348v1",
    "155": "2401.00426v1"
  }
}